Geopolitical amp

import io, requests, zipfile
import pandas as pd
from plotly.offline import download_plotlyjs, init_notebook_mode, iplot
import plotly.graph_objs as go

import warnings
warnings.filterwarnings("ignore")


init_notebook_mode()

def get_data(msa_code, var_dict, para_dict):
    r = requests.get('http://api.census.gov/data/bds/firms?get='
                     + ','.join(var_dict.keys()) ## catenate keys using str.join() method.
                     + '&for=metropolitan+statistical+area:' + str(msa_code),
                    params=para_dict)
    
    ## when url returns empty content, return None
    if r.content is b'': 
        return None
    else:
        ## read in data
        data = pd.DataFrame(r.json())
        
        ## get columns names from first row and map them to the given names in var_dict
        columns = data.iloc[0,:-len(para_dict)].map(var_dict)
        
        ## data we are interested in 
        data = data.iloc[1:,:-len(para_dict)]
        
        ## rename dataframe columns
        data.columns = columns
        
        return data

## request data via https
r = requests.get('https://www2.census.gov/econ/susb/data/msa_codes_2007_to_2011.txt').content

## read and parse data
msa_code = pd.read_table(io.StringIO(r.decode('utf-8')), header=3, sep='   ') 

## rename columns
msa_code.columns = ['code','name'] 

## get rid of micropolitan statistical areas
# msa_code = msa_code[msa_code['name'].str.contains('Metropolitan', case = False)]

## clean up names
msa_code['name'] = msa_code['name'].str.replace(' Metropolitan Statistical Area', '') 

## function to clean up MSA names, only keep the fist city and fist state
def name_clean(s):
    s_list = s.split(', ')
    cities = s_list[0]
    states = s_list[-1]
    return ' '.join([cities.split('-')[0], states.split('-')[0]])

## map the name_clean function to all MSA
msa_code['name'] = msa_code['name'].map(name_clean) 

msa_code

## draw down zip file, unzip, read in txt with specified encoding
r = requests.get("http://www2.census.gov/geo/docs/maps-data/data/gazetteer/2017_Gazetteer/2017_Gaz_cbsa_national.zip")
z = zipfile.ZipFile(io.BytesIO(r.content))
geo = pd.read_table(z.open('2017_Gaz_cbsa_national.txt'), encoding = "ISO-8859-1")

# geo
geo.to_csv('geographical_data_msa.csv')

## clean the columns names and change to lower case
geo.columns = [field.rstrip().lower() for field in geo.columns]

## get rid of micropolitan statistical areas and clean the names the same as msa_code 
# geo = geo[geo['name'].str.contains('Metro', case = False)]
geo['name'] = geo['name'].str.replace(' Metro Area', '')
geo['name'] = geo['name'].map(name_clean)

geo

## http://www.census.gov/popest/data/metro/totals/2015/index.html -> "Metropolitan Statistical Area; and for Puerto Rico"

## read in data with specified encoding
# pop = pd.read_csv("http://www.census.gov/popest/data/metro/totals/2015/files/CBSA-EST2015-alldata.csv", 
#                   encoding = "ISO-8859-1")
# pop = pop[pop['LSAD']=='Metropolitan Statistical Area']
# pop = pop[['CBSA','POPESTIMATE2015']]
# pop.columns = ['geoid', 'population']

msa_data=pd.read_excel('E:\\CBL_COL\\Cost of Living\\New Calculation\\Compare_COLI_Housing_MSA.xlsx',
                       sheet_name='MSA_Level_new')

msa_data_for_plot=msa_data.drop(['Unnamed: 5','For Difference','Unnamed: 7','Diffrence'],axis=1)
msa_data_for_plot.columns=['geoid', 'MSA_Name', 'COL_Index_M2','COL_Index_M1']
pop=msa_data_for_plot

pop

## join to geographic location data
geo = geo.merge(pop, how='inner', left_on='geoid', right_on='geoid')

#Merge msa_code to geo
msa_code = msa_code.merge(geo[['name','intptlat','intptlong','COL_Index_M2','COL_Index_M1']],how='left', left_on='name', right_on='name')
msa_code = msa_code.dropna()

geo_ids=[29780,35620,38900,41740,41860]

df=msa_code
# df['Difference']=abs(df['COL_Index_M2']-df['COL_Index_M1'])
df['Difference']=0.51

df.columns=['code', 'name', 'lat', 'lon', 'COL_Index_M2', 'COL_Index_M1','Difference']

# df[df['A'].isin([3, 6])]
df_outlier=df[df['code'].isin(geo_ids)]

df=df_outlier

df['Difference']=0.1

def map_plot(size_field, color_field):
    
    ## value to scale down bubble size
    scale = df[size_field].max()/4e2
    
    ## setting quantiles
    bins = [0, 0.2, 0.4, 0.6, 0.8, 0.9, 1]
    
    ## setting colors
    colors = ['#8c510a', '#d8b365', '#f6e8c3', '#c7eae5', '#5ab4ac', '#01665e']
    
    ## place holder for msa traces 
    msas = []
    
    ## text to show when mouse move over
    df['text'] = (df['name'] 
        + '<br>Difference: ' + (df['Difference']).map(lambda x: '%2.1f' % x) + ' unit'
        + '<br>' + size_field + ': ' + df[size_field].map(lambda x: '{:,}'.format(x))
        + '<br>' + color_field + ': ' + df[color_field].map(lambda x: '%2.2f' % x) + '%')
    
    ## calculate the corresponding values for each quantile
    qs = df[color_field].quantile(bins).values
    
    ## iterate through each group
    for lower, upper, color in zip(qs[:-1], qs[1:], colors):
        
        ## handling lower bound
        if color==colors[0]: 
            df_sub = df[(df[color_field]<upper)]
            
            ## format the value for display
            name = '< {0:.2f}%'.format(upper)
            
        ## handling upper bound
        elif color==colors[-1]: 
            df_sub = df[(df[color_field]>lower)]
            name = '> {0:.2f}%'.format(lower)
        ## other groups    
        else: 
            df_sub = df[(df[color_field]>lower)&(df[color_field]<=upper)]
            name = '{0:.2f}% - {1:.2f}%'.format(lower,upper)
        
        ## put data into a dictionary in plotly format
        msa = dict(
            type = 'scattergeo',
            locationmode = 'USA-states',
            lon = df_sub['lon'],
            lat = df_sub['lat'],
            text = df_sub['text'],
            marker = dict(
                size = df_sub[size_field]/scale,
                color = color,
                line = dict(width=0.5, color='rgb(40,40,40)'),
                sizemode = 'area'
            ),
            name = name )
        
        ## append current data to placeholder
        msas.append(msa)
    
    ## setting figure title and layout
    layout = dict(
        title = size_field+' created in 2008, grouped by '+color_field,
        showlegend = True,
        geo = dict(
            scope='usa',
            projection=dict( type='albers usa' ),
            showland = True,
            landcolor = 'white',
            subunitwidth=0.5,
            countrywidth=0.5,
            subunitcolor="gray",
            countrycolor="gray"
        ),
    )

    fig = dict( data=msas, layout=layout )
    iplot(fig)

map_plot( 'Difference','COL_Index_M2')

map_plot( 'Difference','COL_Index_M1')

## specify starting year of analysis
start_year = 2008

## letters indicating firm age
fage4_values = ['a', 'b', 'c', 'd', 'e', 'f'] 

## deisred variables
var_dict = {'firms': 'firms',
            'emp': 'jobs'} 

## empty dataframe as placeholder

## empty dataframe as placeholder
# df = pd.DataFrame(columns = ['name', 'population', 'lat', 'lon', '5-year firm survival', 
#                              '5-year job survival', 'number of jobs', 'number of firms'])

df = pd.DataFrame(columns = ['Row Labels','MSA_Name','Average of COL Index_New',
                             'Average of COL Index_Old (MSA Level)','Diffrence'])

print('Fetching data for...')
## iterate through every MSA with a population bigger than 250,000
for idx, row in msa_code.iterrows():
    
    ## code and name of current MSA
    code = row['code']
    print('    '+row['name'])
    
    ## place holder for results
    result = []
    
    ## iterate through age 0 - 5
    for i in range(6):
        para_dict = {'fage4': fage4_values[i], 'time': start_year + i, 'key': api_key}
        result.append(get_data(code, var_dict, para_dict))

    ## check for empty results
    if any([d is None for d in result]):
        continue
        
    #The code was returning an error as not all variables were integer friendly (e.g. there was a phantom column of letters)
    #Added in a drop statement to keep only variables 0:4 
    df0 = pd.concat(result).ix[:, 0:3].astype(int)
    df0.index = range(start_year,start_year+len(fage4_values))

    #Calculate point survival rate
    #Step 1: Create denominator dataframe
    #Shift rows up 1
    df1 = df0.shift(1)
    
    #Replace blank row with 
    df1.iloc[[0]] = df0.iloc[[0]]
    
    #Step 2: Divide numerator (df) by denominator (df2)
    df2 = df0/df1
    

    #Step 3: Calculate cumulative product on instantaneous survival rate table, keep only year 5
    df3 = df2.cumprod()*100
    
    ## copy the initial number of jobs and firms
    df.loc[code, ['number of jobs', 'number of firms']] = df0.iloc[[0]][['jobs', 'firms']].values

     ## copy the initial survival probs
    df.loc[code, ['5-year firm survival', '5-year job survival']] = df3.iloc[[5]][[ 'firms','jobs']].values

    ## copy the namem population and location of MSA
    df.loc[code, ['name', 'population', 'lat', 'lon']] = row[['name', 'population','intptlat','intptlong']].values 


############# Scrape tables############################
import requests
web_url=requests.get("https://www.move.org/which-states-pay-most-utilities/").text

from bs4 import BeautifulSoup

soup=BeautifulSoup(web_url,'lxml')

print(soup.prettify())

my_table=soup.find_all('table')
my_table

my_table[1]

class HTMLTableParser:
       
    def parse_url(self, url):
            response = requests.get(url)
            soup = BeautifulSoup(response.text, 'lxml')
            return [(table['id'],self.parse_html_table(table))\
                    for table in soup.find_all('table')]  

    def parse_html_table(self, table):
                n_columns = 0
                n_rows=0
                column_names = []

                # Find number of rows and columns
                # we also find the column titles if we can
                for row in table.find_all('tr'):

                    # Determine the number of rows in the table
                    td_tags = row.find_all('td')
                    if len(td_tags) > 0:
                        n_rows+=1
                        if n_columns == 0:
                            # Set the number of columns for our table
                            n_columns = len(td_tags)

                    # Handle column names if we find them
                    th_tags = row.find_all('th') 
                    if len(th_tags) > 0 and len(column_names) == 0:
                        for th in th_tags:
                            column_names.append(th.get_text())

                # Safeguard on Column Titles
                if len(column_names) > 0 and len(column_names) != n_columns:
                    raise Exception("Column titles do not match the number of columns")

                columns = column_names if len(column_names) > 0 else range(0,n_columns)
                df = pd.DataFrame(columns = columns,
                                  index= range(0,n_rows))
                row_marker = 0
                for row in table.find_all('tr'):
                    column_marker = 0
                    columns = row.find_all('td')
                    for column in columns:
                        df.iat[row_marker,column_marker] = column.get_text()
                        column_marker += 1
                    if len(columns) > 0:
                        row_marker += 1

                # Convert to float if possible
                for col in df:
                    try:
                        df[col] = df[col].astype(float)
                    except ValueError:
                        pass

                return df

hp = HTMLTableParser()
table = hp.parse_url(web_url)[0][0] # Grabbing the table from the tuple
table.head()

#################################### Automation 1 ################################

import numpy as np 
import pandas as pd 
import openpyxl
from openpyxl import load_workbook

import warnings
warnings.filterwarnings("ignore")

file_path= "C:\\Users\\10920\\Desktop\\Automation\\Total Tables by Occasion - Q2 US.xlsx"
wb = load_workbook(file_path)

Indent_level_all= pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Indent_level_all.xlsx",
                                             sheet_name="Indent"))

Mapping_for_row_info= pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Mapping_for_row_info.xlsx",
                                             sheet_name="Master_Sheet"))

#Display name and tool name mapping Tool to Check 
Tool_name_map = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Tool to Check Table Mapping File 18_09_2019_1.xlsx",
                                             sheet_name="Sheet1"))

#Attribute id and the value for the rows of the selection
Attribute_name_map = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Sample Automation Test Cases with output 19_09_2019.xlsx",
                                             sheet_name="AttributeType"))

#Creating the tool display name and table name map
Tool_name_map_map=Tool_name_map[['Burke Display Name','Display Name']]
Tool_name_map_map.columns=['Burke_Display_Name','Display_Name']

Tool_name_map_map = Tool_name_map_map.dropna()
Tool_name_map_map=Tool_name_map_map.reset_index(drop=True)

Tool_name_map_dict = dict(zip(Tool_name_map_map['Burke_Display_Name'], Tool_name_map_map['Display_Name']))

# Tool_name_map_map=Tool_name_map[['Burke Display Name','MetricName']]
# Tool_name_map_map.columns=['Burke_Display_Name','MetricName']

# Tool_name_map_map = Tool_name_map_map.dropna()
# Tool_name_map_map=Tool_name_map_map.reset_index(drop=True)

# Tool_name_map_dict = dict(zip(Tool_name_map_map['Burke_Display_Name'], Tool_name_map_map['MetricName']))

Mapping_for_row_info.columns=['MetricId', 'MetricName', 'Display_Name', 'MetricParentName','ParentId', 'AttributetypeId']

list_tables=wb.sheetnames
list_tables.remove('Table of Contents')

#To store all the tables
Table_dict={}

# To find:: Table Name, Table header,Base, Filter
Table_Name_used=[]
Table_header=[]
Base_used=[]
Filter_used=[]

for table_number in list_tables:
    data=pd.DataFrame(wb[table_number].values)
#     print(data.shape)
    
    data['Indent']=Indent_level_all[table_number]
    
#     print(data.shape)
    

    Table_Name=data.loc[0][0]
    Table_Name_used.append(Table_Name)

#                 print('Table Name :  ', Table_Name)

    Table_Question=data.loc[1][0]
    Table_header.append(Table_Question)
#                 print('Table header :  ',Table_Question)

    Table_Question=Table_Question.splitlines()
    
    if len(Table_Question)>=3:
        Filter=Table_Question[len(Table_Question)-1]
    else:
        Filter="No Filter"

    Filter_used.append(Filter)
#                 print('Filter Used : ',Filter)

    data_index=data.index.tolist()
    data_column=len(data.columns)

    data_1=data

    for i in data_index:
        for j in range(0,data_column-1):
            if data_1.loc[i,j]=='Client Confidential':
                temp=i
            else:
                continue   
                
    temp,data.shape,data_1.shape

    for i in range(temp-2,len(data_index)):
                data_1=data_1.drop(i)

    data.shape,data_1.shape

    # data_1.head(10)

    for i in range(0,data_1.shape[0]):
        if data_1.iloc[i][1]=='Total':
            j=i
        else:
            continue

    for i in range(0,j):
        data_1=data_1.drop(i)

    data_1=data_1.reset_index(drop=True)
    # data_1

    for i in range(1,len(data_1.index)):
        if type(data_1.iloc[i,0])==type(None):
            data_1.iloc[i,0]=data_1.iloc[i-1,0] +str('%')
        else:
            continue

    # data_1.head(15)

    data_1[0][0]='Row_Names'
    data_1.columns=data_1.loc[0].tolist()
    data_1=data_1.rename(columns = {data_1.columns[len(data_1.columns)-1]:'Indent'})
   

    data_1=data_1.drop(0)
    data_1=data_1.reset_index(drop=True)
    # data_1

    for i in range(0,len(data_1.index)):
        temp=data_1['Row_Names'][i]
        
        if type(temp)==type(None):            
            continue 
        else:
            if (temp.find('Base ') != -1):
                where=i 
            else:
                continue    

    data_1['Row_Names']=data_1['Row_Names'].map(Tool_name_map_dict).fillna(data_1['Row_Names'])
    
    Base=''
    Base=data_1['Row_Names'][where]
    Base=Base.replace('Base - ','',1)

    Base_used.append(Base)
    
    data_table_name = 'data_table'+str('_')+str(Table_Question[0])+str('_')
    
       
    Table_dict[data_table_name]=data_1

# # Table Info
# for Table_Number___ in Tables_to_be_checked_first_round:
# #     print('Table_Name:"\n"',Table_Name_used[Table_Number___-1])
# #     print('Table_header:"\n"',Table_header[Table_Number___-1])
# #     print('Base_used:"\n"',Base_used[Table_Number___-1])
#     print('Filter_used:"\n"',Filter_used[Table_Number___-1])

Tables_to_be_checked_first_round=[2,3,4,6,8,10,11,12,13,40,41,42,43,44,45,46,47,48,49,50,51,108,109,110,111,112,114,115,
                                  116,117,119,120,121,122,124,125,126,127,129,130,131,132,134,135,136,137,139,140,141,142,
                                  144,145,146,147,149,150,151,152,154,155,156,157,159,160,161,162,164,165,166,167,169,170,
                                  171,172,174,175,176,177,179,180,181,182,184,185,186,187,189,190,191,192,195,197,199,200,
                                  201,202,203,204,205,206,207,212,213,215]

#To store all the syntax for tables
Table_row_category_dict={}
Table_row_demog_dict={}
Table_row_5w_dict={}
Table_row_syntax_dict={}
Table_row_parent_prefix_dict={}
Table_output_file_data_dict={}
file_path='C:\\Users\\10920\\Desktop\\Automation\\Output_tables\\Round_1\\'

for table_number in Tables_to_be_checked_first_round:
    data_table_name = 'data_table_Table: '+str(table_number)+str('_')

    data_2=Table_dict[data_table_name]

    Indent=data_2[['Row_Names','Indent']]

    Indent=data_2[['Row_Names','Indent']]
    Indent.columns=['table_row_name','indent_row_level']

#Creating the Indent data to find the zero level indented rows for selection

    for i in range(0,len(Indent.index)):
        if (Indent['table_row_name'][i].find('%') != -1):
            Indent=Indent.drop(i)
        else:
            continue
    Indent=Indent.reset_index(drop=True) 

    counter=0

    for i in range(3,len(Indent.index)):
        if ('Total' in Indent['table_row_name'][i]):
            counter=i
            break        
        else:
            continue

    if counter!=0:
        for x in range(counter,len(Indent.index)):
            Indent=Indent.drop(x)
    Indent=Indent.reset_index(drop=True)

    Indent['table_row_name']=Indent['table_row_name'].map(Tool_name_map_dict).fillna(Indent['table_row_name'])

#Finding the row selection for 0 level Indent
    indent_selection_all =pd.DataFrame(columns=['table','syntax' ])

    key=0
    temp_0="Junk"

    for x in range(2,len(Indent.index)):    

        if Indent['indent_row_level'][x]==1:
            indent_selection_all.loc[key,'table']='table_number'
            indent_selection_all.loc[key,'syntax']=temp_0        
            key += 1
            temp_0=Indent['table_row_name'][x]
            temp_0 = temp_0+str('|')       

        else:
            continue

    indent_selection_all.loc[key,'table']='table_number'
    indent_selection_all.loc[key,'syntax']=temp_0 


    row_level_syntax=''
    row_level_syntax_1=''

    for x in indent_selection_all['syntax']:
        row_level_syntax=x
        row_level_syntax_1=row_level_syntax_1+row_level_syntax 

    row_level_syntax_1=row_level_syntax_1.replace('Junk','')

    row_level_syntax_1=row_level_syntax_1[0:len(row_level_syntax_1)-1]
    Table_row_syntax_dict[table_number]=row_level_syntax_1

# Finding the parent prefix

    for x in range(2,len(Indent.index)):   
        temp_row_value=''     
        if Indent['indent_row_level'][x]==1:
            temp_row_value=Indent['table_row_name'][x]
            break
        else:
            continue       

    row_parent_name=''
    row_parent_id=0
    parent_list=[]

    for x in range(0,len(Mapping_for_row_info['Display_Name'])):
        if Mapping_for_row_info['Display_Name'][x]==temp_row_value:
            row_parent_name=Mapping_for_row_info['MetricParentName'][x]
            row_parent_id=Mapping_for_row_info['ParentId'][x]
        else:
            continue

    parent_list.append(row_parent_name)
    

    while(row_parent_id!=0):
        temp_id=Mapping_for_row_info['ParentId'][Mapping_for_row_info['MetricId']==row_parent_id].values[0]
        parent_list.append(Mapping_for_row_info['MetricParentName'][Mapping_for_row_info['ParentId']==temp_id].values[0])  
        row_parent_id=temp_id

    parent_list.remove(parent_list[len(parent_list)-1])
    
    parent_length=len(parent_list)    

    Parent_prefix=''
    for x in range(0,len(parent_list)):
        if (x==len(parent_list)-1):
                    Parent_prefix=str('Row')+str('^')+Parent_prefix
                    Parent_prefix=parent_list[x]+str('^')+Parent_prefix
        else:
            Parent_prefix=parent_list[x]+str('^')+Parent_prefix  
    
    Table_row_parent_prefix_dict[table_number]=Parent_prefix
    

# Finding the Row for the selection
    temp_1_row_value='' 
    for x in range(4,len(Indent.index)):
        if Indent['indent_row_level'][x]==0:
            temp_1_row_value=Indent['table_row_name'][x]
            break
        else:
            continue   


    for x in range(0,len(Mapping_for_row_info.index)):
        if Mapping_for_row_info['Display_Name'][x]==temp_1_row_value:
            attribute_id=Mapping_for_row_info['AttributetypeId'][x]
        else:
            continue   


    Row_name_list=[]
    Row_name=''

    if attribute_id in [38,39,40]:
        Row_name_list=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_id]['AttributeType']        
        Row_name=Row_name_list[Row_name_list.index[0]]
    else:
        if len(parent_list)!=0:
            Row_name=parent_list[len(parent_list)-1]
    
    if Row_name=='Category/Brand/Item' or Row_name=='Item' or Row_name=='Brand' or Row_name=='Category':
        Table_row_category_dict[table_number]=Row_name
    elif Row_name=='Demographics':
        Table_row_demog_dict[table_number]=Row_name
    elif Row_name=='5Ws':
        Table_row_5w_dict[table_number]=Row_name
    else:
        Table_row_category_dict[table_number]='NA'
        Table_row_demog_dict[table_number]='NA'
        Table_row_5w_dict[table_number]='NA'
    

    # # Finding the Row Nesting value for the selection
    #     # Finding the parent list

    # temp_2_row_value='' 
    # for x in range(2,len(Indent.index)):
    #     if Indent['indent_row_level'][x]==1:
    #         temp_2_row_value=Indent['table_row_name'][x]
    #         break
    #     else:
    #         continue   

    # temp_2_row_value

    # row_parent_name_nest=''
    # row_parent_nest_id=0
    # parent__nest_list=[]

    # for x in range(0,len(Mapping_for_row_info['Display_Name'])):
    #     if Mapping_for_row_info['Display_Name'][x]==temp_2_row_value:
    #         row_parent_name_nest=Mapping_for_row_info['MetricParentName'][x]
    #         row_parent_nest_id=Mapping_for_row_info['ParentId'][x]
    #     else:
    #         continue

    # parent__nest_list.append(row_parent_name_nest)

    # while(row_parent_nest_id!=0):
    #     temp_id=Mapping_for_row_info['ParentId'][Mapping_for_row_info['MetricId']==row_parent_nest_id].values[0]
    #     parent__nest_list.append(Mapping_for_row_info['MetricParentName'][Mapping_for_row_info['ParentId']==temp_id].values[0])
    #     row_parent_nest_id=temp_id

    # parent__nest_list.remove(parent__nest_list[len(parent__nest_list)-1])


    # for x in range(0,len(Mapping_for_row_info.index)):
    #     if Mapping_for_row_info['Display_Name'][x]==temp_2_row_value:
    #         attribute_id_1=Mapping_for_row_info['AttributetypeId'][x]
    #     else:
    #         continue   


    # Row_nest_list=[]
    # Row_nest_name=''

    # if attribute_id in [38,39,40]:
    #     Row_nest_list=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_id_1]['AttributeType']
    #     Row_nest_name=Row_nest_list[Row_nest_list.index[0]]
    # else:
    #     if len(parent__nest_list)!=0:
    #         Row_nest_name=parent__nest_list[len(parent__nest_list)-1]
    #     else:
    #         Row_nest_name='NA'  

#generating the output files
    data_for_output_result=data_2
    for x in range(0,len(data_2.index)):
        if data_2['Indent'][x]!=0:
            data_for_output_result=data_for_output_result.drop(x)
        else:
            continue

    data_for_output_result=data_for_output_result.reset_index(drop=True)
    
    for x in range(4,len(data_for_output_result.index)):
        if (data_for_output_result['Row_Names'][x].find('%') != -1):
            continue
        else:
            data_for_output_result=data_for_output_result.drop(x)

    data_for_output_result=data_for_output_result.reset_index(drop=True)
    
    Unweighted_base=data_for_output_result[:1]

    Unweighted_base=Unweighted_base.melt(id_vars =['Row_Names'], value_vars =['Total', 'Early Morning Bite', 
                                                     'Breakfast For One','Family Breakfast', 
                                                     'Breakfast @ Work / School', 'Mid Morning Snack','Lunch', 
                                                     'Lunch Alternative', 'Afternoon Snack','After Work / School Bite', 
                                                     'Dinner', 'Dinner Alternative','Evening Me', 'Evening We',
                                                     'Bedtime / Late Night Snack'],var_name ='Occasions')

    Weighted_base_nummber=data_for_output_result[2:3]

    Weighted_base_nummber=Weighted_base_nummber.melt(id_vars =['Row_Names'], value_vars =['Total', 'Early Morning Bite', 
                                                     'Breakfast For One','Family Breakfast', 
                                                     'Breakfast @ Work / School', 'Mid Morning Snack','Lunch', 
                                                     'Lunch Alternative', 'Afternoon Snack','After Work / School Bite', 
                                                     'Dinner', 'Dinner Alternative','Evening Me', 'Evening We',
                                                     'Bedtime / Late Night Snack'],var_name ='Occasions')

    Weighted_base_percentage=data_for_output_result[3:4]

    Weighted_base_percentage=Weighted_base_percentage.melt(id_vars =['Row_Names'], value_vars =['Total', 'Early Morning Bite', 
                                                     'Breakfast For One','Family Breakfast', 
                                                     'Breakfast @ Work / School', 'Mid Morning Snack','Lunch', 
                                                     'Lunch Alternative', 'Afternoon Snack','After Work / School Bite', 
                                                     'Dinner', 'Dinner Alternative','Evening Me', 'Evening We',
                                                     'Bedtime / Late Night Snack'],var_name ='Occasions')

    rest_of_table=data_for_output_result[4:].melt(id_vars =['Row_Names'], value_vars =['Total', 'Early Morning Bite', 
                                                     'Breakfast For One','Family Breakfast', 
                                                     'Breakfast @ Work / School', 'Mid Morning Snack','Lunch', 
                                                     'Lunch Alternative', 'Afternoon Snack','After Work / School Bite', 
                                                     'Dinner', 'Dinner Alternative','Evening Me', 'Evening We',
                                                     'Bedtime / Late Night Snack'],var_name ='Occasions')

    Unweighted_base_dict = dict(zip(Unweighted_base['Occasions'], Unweighted_base['value']))
    Weighted_base_nummber_dict = dict(zip(Weighted_base_nummber['Occasions'], Weighted_base_nummber['value']))

    rest_of_table['Unweighted_base']=rest_of_table['Occasions']
    rest_of_table['Unweighted_base']=rest_of_table.Occasions.map(Unweighted_base_dict)

    rest_of_table['Weighted_base']=rest_of_table['Occasions']
    rest_of_table['Weighted_base']=rest_of_table.Occasions.map(Weighted_base_nummber_dict)
    rest_of_table

    # Weighted_base_percentage
    Weighted_base_percentage['Unweighted_base']=Weighted_base_percentage['Occasions']
    Weighted_base_percentage['Unweighted_base']=Weighted_base_percentage.Occasions.map(Unweighted_base_dict)

    Weighted_base_percentage['Weighted_base']=Weighted_base_percentage['Occasions']
    Weighted_base_percentage['Weighted_base']=Weighted_base_percentage.Occasions.map(Weighted_base_nummber_dict)

    Table_output=Weighted_base_percentage.append(rest_of_table)

    Table_output=Table_output.reset_index(drop=True)

    uper_level_name=[]
    y=''
    for x in Table_output['Row_Names']:
        y=find_prefix(x,data_2)
        uper_level_name.append(y)

    Table_output['New_Row_Names']=uper_level_name

    for x in range(0,len(Table_output.index)):    
        if (Table_output['New_Row_Names'][x].find('Base ') != -1):
            Table_output['New_Row_Names'][x]='Base'
        else:
            continue

    for x in range(0,len(Table_output.index)):    
        if (Table_output['New_Row_Names'][x].find('%') != -1):
            Table_output['New_Row_Names'][x]=Table_output['New_Row_Names'][x].replace('%','')
        else:
            continue
            
    Table_output['New_Row_Names']=Table_output['New_Row_Names'].map(Tool_name_map_dict).fillna(Table_output['New_Row_Names'])

    Table_output['New_Row_Names']=Table_output['New_Row_Names']+str('|')+Table_output['Occasions']

    Table_output_final=Table_output[['New_Row_Names','value', 'Weighted_base', 'Unweighted_base']]
    Table_output_final.columns=['Distinct','Percentage_value','WEIGHTED_Base','UNWEIGHTED_Base']
    Table_output_final['Test_Case_number']=table_number
    
    Table_output_file_data_dict[table_number]=Table_output_final
    
#     data_table_name_table=str('Table')+str(table_number)+str('.csv')
#     Table_output_final.to_csv(file_path+data_table_name_table,index=False)

def find_prefix(name,data_2):
    indent_for_value=0
    return_value=''
    return_value_1=[]
    return_value_2=''    
    for x in range(0, len(data_2.index)):
        if data_2['Row_Names'][x]==name:
            indent_for_value=data_2['Indent'][x]
            if indent_for_value==0:
                return_value=name
            elif indent_for_value==1:
                for i in range(x,-1,-1):
                    if data_2['Indent'][i]==0:
                        return_value=data_2['Row_Names'][i]
                        break
                    else:
                        continue
            elif indent_for_value==2:
                for i in range(x,-1,-1):
                    if data_2['Indent'][i]==2:
                        continue                        
                    elif data_2['Indent'][i]==1:
                        return_value_1.append(data_2['Row_Names'][i])                        
                    elif data_2['Indent'][i]==0:
                        return_value_2=data_2['Row_Names'][i]
                        break
                    else:
                        continue
                return_value=return_value_2+str('|')+return_value_1[0]
    return return_value

# Creating Table Filter
prefix_filter={}
# Table_Number___=43

for Table_Number___ in Tables_to_be_checked_first_round:
    data_table_name = 'data_table_Table: '+str(Table_Number___)+str('_')
    data_2=Table_dict[data_table_name]
    filter_used=Filter_used[Table_Number___]

    Indent=data_2[['Row_Names','Indent']]
    Indent=data_2[['Row_Names','Indent']]
    Indent.columns=['table_row_name','indent_row_level']

    #Creating the Indent data to find the zero level indented rows for selection

    for i in range(0,len(Indent.index)):
        if (Indent['table_row_name'][i].find('%') != -1):
            Indent=Indent.drop(i)
        else:
            continue
    Indent=Indent.reset_index(drop=True) 

    counter=0

    for i in range(3,len(Indent.index)):
        if ('Total' in Indent['table_row_name'][i]):
            counter=i
            break        
        else:
            continue

    if counter!=0:
        for x in range(counter,len(Indent.index)):
            Indent=Indent.drop(x)
    Indent=Indent.reset_index(drop=True)

    Indent['table_row_name']=Indent['table_row_name'].map(Tool_name_map_dict).fillna(Indent['table_row_name']) 

    temp_row_value=filter_used        

    row_parent_name=''
    row_parent_id=0
    parent_list=[]

    for x in range(0,len(Mapping_for_row_info['Display_Name'])):
        if Mapping_for_row_info['Display_Name'][x]==temp_row_value:
            row_parent_name=Mapping_for_row_info['MetricParentName'][x]
            row_parent_id=Mapping_for_row_info['ParentId'][x]
        else:
            continue

    parent_list.append(row_parent_name)

    while(row_parent_id!=0):
        temp_id=Mapping_for_row_info['ParentId'][Mapping_for_row_info['MetricId']==row_parent_id].values[0]
        parent_list.append(Mapping_for_row_info['MetricParentName'][Mapping_for_row_info['ParentId']==temp_id].values[0])  
        row_parent_id=temp_id

    parent_list.remove(parent_list[len(parent_list)-1])

    Parent_prefix=''
    for x in range(0,len(parent_list)):
        if (x==len(parent_list)-1):
                    Parent_prefix=str('Row')+str('^')+Parent_prefix
                    Parent_prefix=parent_list[x]+str('^')+Parent_prefix
        else:
            Parent_prefix=parent_list[x]+str('^')+Parent_prefix  

    prefix_filter[Table_Number___]=Parent_prefix+filter_used

All_table_info=pd.DataFrame({'row_category':pd.Series(Table_row_category_dict),'row_demog':pd.Series(Table_row_demog_dict),
                             'row_5w':pd.Series(Table_row_5w_dict),'row_syntax':pd.Series(Table_row_syntax_dict),
                             'row_parent':pd.Series(Table_row_parent_prefix_dict),'row_filter':pd.Series(prefix_filter)})

All_table_info.to_csv('All_table_info.csv')

test_table=191
data_table_name = 'data_table_Table: '+str(test_table)+str('_')

test_table_data=Table_dict[data_table_name]

test_table_data

data_2=test_table_data

Indent=data_2[['Row_Names','Indent']]

Indent=data_2[['Row_Names','Indent']]
Indent.columns=['table_row_name','indent_row_level']

#Creating the Indent data to find the zero level indented rows for selection

for i in range(0,len(Indent.index)):
    if (Indent['table_row_name'][i].find('%') != -1):
        Indent=Indent.drop(i)
    else:
        continue
Indent=Indent.reset_index(drop=True) 

counter=0

for i in range(3,len(Indent.index)):
    if ('Total' in Indent['table_row_name'][i]):
        counter=i
        break        
    else:
        continue

if counter!=0:
    for x in range(counter,len(Indent.index)):
        Indent=Indent.drop(x)
Indent=Indent.reset_index(drop=True)

Indent['table_row_name']=Indent['table_row_name'].map(Tool_name_map_dict).fillna(Indent['table_row_name'])

#Finding the row selection for 0 level Indent
indent_selection_all =pd.DataFrame(columns=['table','syntax' ])

key=0
temp_0="Junk"

for x in range(2,len(Indent.index)):    

    if Indent['indent_row_level'][x]==0:
        indent_selection_all.loc[key,'table']='table_number'
        indent_selection_all.loc[key,'syntax']=temp_0        
        key += 1
        temp_0=Indent['table_row_name'][x]
        temp_0 = temp_0+str('|')       

    else:
        continue

indent_selection_all.loc[key,'table']='table_number'
indent_selection_all.loc[key,'syntax']=temp_0 


row_level_syntax=''
row_level_syntax_1=''

for x in indent_selection_all['syntax']:
    row_level_syntax=x
    row_level_syntax_1=row_level_syntax_1+row_level_syntax 

row_level_syntax_1=row_level_syntax_1.replace('Junk','')

row_level_syntax_1=row_level_syntax_1[0:len(row_level_syntax_1)-1]
# Table_row_syntax_dict[table_number]=row_level_syntax_1

# Finding the parent prefix

for x in range(2,len(Indent.index)):   
    temp_row_value=''     
    if Indent['indent_row_level'][x]==0:
        temp_row_value=Indent['table_row_name'][x]
        break
    else:
        continue       

row_parent_name=''
row_parent_id=0
parent_list=[]

for x in range(0,len(Mapping_for_row_info['Display_Name'])):
    if Mapping_for_row_info['Display_Name'][x]==temp_row_value:
        row_parent_name=Mapping_for_row_info['MetricParentName'][x]
        row_parent_id=Mapping_for_row_info['ParentId'][x]
    else:
        continue

parent_list.append(row_parent_name)

while(row_parent_id!=0):
    temp_id=Mapping_for_row_info['ParentId'][Mapping_for_row_info['MetricId']==row_parent_id].values[0]
    parent_list.append(Mapping_for_row_info['MetricParentName'][Mapping_for_row_info['ParentId']==temp_id].values[0])  
    row_parent_id=temp_id

parent_list.remove(parent_list[len(parent_list)-1])

Parent_prefix=''
for x in range(0,len(parent_list)):
    if (x==len(parent_list)-1):
                Parent_prefix=str('Row')+str('^')+Parent_prefix
                Parent_prefix=parent_list[x]+str('^')+Parent_prefix
    else:
        Parent_prefix=parent_list[x]+str('^')+Parent_prefix  

# Table_row_parent_prefix_dict[table_number]=Parent_prefix

# row_parent_id
# len(Mapping_for_row_info['Display_Name'])
# temp_row_value
parent_list,Parent_prefix

for x in range(0,len(Mapping_for_row_info['Display_Name'])):
    if Mapping_for_row_info['Display_Name'][x]==temp_row_value:
#         row_parent_name=Mapping_for_row_info['MetricParentName'][x]
#         row_parent_id=Mapping_for_row_info['ParentId'][x]
          print(temp_row_value)
    else:
        continue

# parent_list.append(row_parent_name)


# Finding the Row for the selection
temp_1_row_value='' 
for x in range(4,len(Indent.index)):
    if Indent['indent_row_level'][x]==0:
        temp_1_row_value=Indent['table_row_name'][x]
        break
    else:
        continue   

temp_1_row_value

for x in range(0,len(Mapping_for_row_info.index)):
    if Mapping_for_row_info['Display_Name'][x]==temp_1_row_value:
        attribute_id=Mapping_for_row_info['AttributetypeId'][x]
    else:
        continue   


Row_name_list=[]
Row_name=''

if attribute_id in [38,39,40]:
    Row_name_list=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_id]['AttributeType']        
    Row_name=Row_name_list[Row_name_list.index[0]]
else:
    if len(parent_list)!=0:
        Row_name=parent_list[len(parent_list)-1]

if Row_name=='Category/Brand/Item' or Row_name=='Item' or Row_name=='Brand' or Row_name=='Category':
    Table_row_category_dict[table_number]=Row_name
elif Row_name=='Demographics':
    Table_row_demog_dict[table_number]=Row_name
elif Row_name=='5Ws':
    Table_row_5w_dict[table_number]=Row_name
else:
    Table_row_category_dict[table_number]='NA'
    Table_row_demog_dict[table_number]='NA'
    Table_row_5w_dict[table_number]='NA'

# Midnight to just before 6:00 AM
    
Table_Number___=43    
data_table_name_1 = 'data_table_Table: '+str(Table_Number___)+str('_')
data_test=Table_dict[data_table_name]
find_prefix('Midnight to just before 6:00 AM',data_test)

prefix_filter[42]

parent_list

Filter_used[13]

Output_table=pd.DataFrame()
for key in Table_output_file_data_dict.keys():
    Output_table=Output_table.append(Table_output_file_data_dict[key])
    
    

Output_table.shape

Output_table.to_csv('Output_table.csv')

Table_dict['data_table_Table: 1_']

len(Filter_used),len(Table_dict)

# Filter_used[]

########################## Automation 2 ###################################

import numpy as np 
import pandas as pd 
import openpyxl
from openpyxl import load_workbook

import warnings
warnings.filterwarnings("ignore")

#Tables for test
file_path= "C:\\Users\\10920\\Desktop\\Automation\\Total Tables by Occasion - Q2 US.xlsx"
wb = load_workbook(file_path)

#Indent level for Tables
Indent_level_all= pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Indent_level_all.xlsx",
                                             sheet_name="Indent"))

#Display Name and Table row name mapping 
Mapping_for_row_info= pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Mapping_for_row_info.xlsx",
                                             sheet_name="Master_Sheet"))

#Display name and tool name mapping Tool to Check 
Tool_name_map = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Tool to Check Table Mapping File 18_09_2019_1.xlsx",
                                             sheet_name="Sheet1"))

#Attribute id and the value for the rows of the selection
Attribute_name_map = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Sample Automation Test Cases with output 19_09_2019.xlsx",
                                             sheet_name="AttributeType"))

#Creating the tool display name and table name map
Tool_name_map_map=Tool_name_map[['Burke Display Name','Display Name']]
Tool_name_map_map.columns=['Burke_Display_Name','Display_Name']

Tool_name_map_map = Tool_name_map_map.dropna()
Tool_name_map_map=Tool_name_map_map.reset_index(drop=True)

Tool_name_map_dict = dict(zip(Tool_name_map_map['Burke_Display_Name'], Tool_name_map_map['Display_Name']))

#Store sheet names
list_tables=wb.sheetnames
list_tables.remove('Table of Contents')

#To store all the tables
Table_dict={}

# To find:: Table Name, Table header,Base, Filter
Table_Name_used=[]
Table_header=[]
Base_used=[]
Filter_used=[]

for table_number in list_tables:
    data=pd.DataFrame(wb[table_number].values)
#     print(data.shape)
    
    data['Indent']=Indent_level_all[table_number]
    
#     print(data.shape)
    

    Table_Name=data.loc[0][0]
    Table_Name_used.append(Table_Name)

#                 print('Table Name :  ', Table_Name)

    Table_Question=data.loc[1][0]
    Table_header.append(Table_Question)
#                 print('Table header :  ',Table_Question)

    Table_Question=Table_Question.splitlines()
    
    if len(Table_Question)>=3:
        Filter=Table_Question[len(Table_Question)-1]
    else:
        Filter="No Filter"

    Filter_used.append(Filter)
#                 print('Filter Used : ',Filter)

    data_index=data.index.tolist()
    data_column=len(data.columns)

    data_1=data

    for i in data_index:
        for j in range(0,data_column-1):
            if data_1.loc[i,j]=='Client Confidential':
                temp=i
            else:
                continue   
                
    temp,data.shape,data_1.shape

    for i in range(temp-2,len(data_index)):
                data_1=data_1.drop(i)

    data.shape,data_1.shape

    # data_1.head(10)

    for i in range(0,data_1.shape[0]):
        if data_1.iloc[i][1]=='Total':
            j=i
        else:
            continue

    for i in range(0,j):
        data_1=data_1.drop(i)

    data_1=data_1.reset_index(drop=True)
    # data_1

    for i in range(1,len(data_1.index)):
        if type(data_1.iloc[i,0])==type(None):
            data_1.iloc[i,0]=data_1.iloc[i-1,0] +str('%')
        else:
            continue

    # data_1.head(15)

    data_1[0][0]='Row_Names'
    data_1.columns=data_1.loc[0].tolist()
    data_1=data_1.rename(columns = {data_1.columns[len(data_1.columns)-1]:'Indent'})
   

    data_1=data_1.drop(0)
    data_1=data_1.reset_index(drop=True)
    # data_1

    for i in range(0,len(data_1.index)):
        temp=data_1['Row_Names'][i]
        
        if type(temp)==type(None):            
            continue 
        else:
            if (temp.find('Base ') != -1):
                where=i 
            else:
                continue

    data_1.Row_Names.map(Tool_name_map_dict)
    
    
    Base=''
    Base=data_1['Row_Names'][where].replace('Base -','').replace('%','',1)
    Base_used.append(Base)
        
    
    data_table_name = 'data_table'+str('_')+str(Table_Question[0])+str('_')
        
    Table_dict[data_table_name]=data_1

#working on tables # base used
Base_Used_all_Tables=[]
for x in Base_used:
    temp=x.replace('%','',1)
    Base_Used_all_Tables.append(temp)
#For example    
print(Base_Used_all_Tables[0])

#filter used
#For example
print(Filter_used[0])

#To store all the syntax for tables
Table_row_syntax_dict={}
Table_row_nesting_syntax_dict={}

for table_number in range(1,len(Table_dict)+1):
        
        Table_in_dict_name = ('data_table_Table: {}_'.format(table_number))
        
        Table_Data=Table_dict[Table_in_dict_name]


#To find the level of indented of rows for row nesting

        Indent=Table_Data[['Row_Names','Indent']]

        Indent.columns=['table_row_name','indent_row_level']

#Removing the duplicates with %       
        for i in range(0,len(Indent.index)):
            if (Indent['table_row_name'][i].find('%') != -1):
                Indent=Indent.drop(i)
            else:
                continue
        Indent=Indent.reset_index(drop=True) 

#Removing the redundant lower rows
        counter=0

        for i in range(3,len(Indent.index)):
            if ('Total' in Indent['table_row_name'][i]):
                counter=i
                break        
            else:
                continue

        for x in range(counter,len(Indent.index)):
            Indent=Indent.drop(x)

        Indent=Indent.reset_index(drop=True)  

#storingng the 0 level indented rows

#end of data preperation for Indentation 

        indent_selection_all =pd.DataFrame(columns=['table_name','syntax' ])
    
        key=0
        temp_0="Junk"

        for x in range(2,len(Indent.index)):    

            if Indent['indent_row_level'][x]==0:
                indent_selection_all.loc[key,'table_number']=table_number
                indent_selection_all.loc[key,'syntax']=temp_0        
                key += 1
                temp_0=Indent['table_row_name'][x]
                temp_0 = temp_0+str('|')       

            else:
                continue

# for the last one the number 0 in the list is Junk so list starts from 1 
        indent_selection_all.loc[key,'table_name']=table_number
        indent_selection_all.loc[key,'syntax']=temp_0 

#creating the first part for synatx (Category/5W/Demog) the one irrespective of nesting
        row_level_syntax=''
        row_level_syntax_1=''

        for x in indent_selection_all['syntax']:
            row_level_syntax=x
            row_level_syntax_1=row_level_syntax_1+row_level_syntax 

#Removing the Junk and last trailing pipe            
        row_level_syntax_1=row_level_syntax_1.replace('Junk','')
        row_level_syntax_1=row_level_syntax_1[0:len(row_level_syntax_1)-1]
        
        Table_row_syntax_dict[table_number]=row_level_syntax_1

        indent_selection =pd.DataFrame(columns=['table','syntax' ])

        key=0
        temp_0="Junk"

        for x in range(2,len(Indent.index)):    

            if Indent['indent_row_level'][x]==0:
                indent_selection.loc[key,'table']='table_number'
                indent_selection.loc[key,'syntax']=temp_0        
                key += 1
                temp_0=Indent['table_row_name'][x]
                temp_0 = temp_0+str('^')

            elif Indent['indent_row_level'][x]==1:        

                temp_0 = temp_0+Indent['table_row_name'][x]+str('%')

            elif Indent['indent_row_level'][x]==2: 
                temp_0 = temp_0+Indent['table_row_name'][x]+str('|')
            else:
                continue

        indent_selection.loc[key,'table']='table_number'
        indent_selection.loc[key,'syntax']=temp_0        
# print(key)

        row_nest_syntax=''
        row_nest_syntax_1=''

        for x in indent_selection['syntax']:

            row_nest_syntax=x[0:len(x)-1]
            row_nest_syntax_1=row_nest_syntax_1+row_nest_syntax+str('$') 
        #      print(x)

        row_nest_syntax_1=row_nest_syntax_1.replace('Jun','')
        row_nest_syntax_1=row_nest_syntax_1[0:len(row_nest_syntax_1)-1]
        row_nest_syntax_1=row_nest_syntax_1[1:len(row_nest_syntax_1)+1]
        row_nest_syntax_1
        Table_row_nesting_syntax_dict[table_number]=row_nest_syntax_1

# Finding the parent prefix

for x in range(2,len(Indent.index)):   
    temp_row_value=''     
    if Indent['indent_row_level'][x]==0:
        temp_row_value=Indent['table_row_name'][x]
        break
    else:
        continue       

# temp_row_value='Employment Status'

row_parent_name=''
row_parent_id=0
parent_list=[]

for x in range(0,len(Mapping_for_row_info['Display Name'])):
    if Mapping_for_row_info['Display Name'][x]==temp_row_value:
        row_parent_name=Mapping_for_row_info['MetricParentName'][x]
        row_parent_id=Mapping_for_row_info['ParentId'][x]
    else:
        continue

parent_list.append(row_parent_name)

while(row_parent_id!=0):
    temp_id=Mapping_for_row_info['ParentId'][Mapping_for_row_info['MetricId']==row_parent_id].values[0]
    parent_list.append(Mapping_for_row_info['MetricParentName'][Mapping_for_row_info['ParentId']==temp_id].values[0])    
    row_parent_id=temp_id

parent_list.remove(parent_list[len(parent_list)-1])
# parent_list

Parent_prefix=''
for x in range(0,len(parent_list)):
    if (x==len(parent_list)-1):
                Parent_prefix=str('Row')+str('^')+Parent_prefix
                Parent_prefix=parent_list[x]+str('^')+Parent_prefix
    else:
        Parent_prefix=parent_list[x]+str('^')+Parent_prefix  

Parent_prefix

# Table Info
Table_Number___=597

print('Table_Name:"\n"',Table_Name_used[Table_Number___-1])
print('Table_header:"\n"',Table_header[Table_Number___-1])
print('Base_used:"\n"',Base_Used_all_Tables[Table_Number___-1])
print('Filter_used:"\n"',Filter_used[Table_Number___-1])
print('Row 0 Indent:"\n"',Table_row_syntax_dict[Table_Number___])
print('Row nesting:"\n"',Table_row_nesting_syntax_dict[Table_Number___])

######################## Automation 3 ##################################################

import numpy as np 
import pandas as pd 
import openpyxl
from openpyxl import load_workbook

import warnings
warnings.filterwarnings("ignore")

#Left Panel mapping file for parent prefix
Mapping_for_row_info= pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\LeftPanel_Hierarchy 10112019 (wo OSP).xlsx",
                                             sheet_name="LeftPanel_Hierarchy 10112019 (w"))

#Display name and tool name mapping Tool to Check 
Tool_name_map = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Burke to Tool Mapping File 09272019.xlsx",
                                             sheet_name="In Tool"))

#Attribute id and the value for the rows of the selection
Attribute_name_map = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Sample Automation Test Cases with output 19_09_2019.xlsx",
                                             sheet_name="AttributeType"))

#Read Tables
file_path_US_Q2= "C:\\Users\\10920\\Desktop\\Automation\\Total Tables by Occasion - Q2 US.xlsx"
wb_us_q2 = load_workbook(file_path_US_Q2)

wb=wb_us_q2

#read Indent Level for files
Indent_level_us_q2= pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Indent_level_all.xlsx",
                                             sheet_name="Indent"))
Indent_level_all=Indent_level_us_q2

Mapping_for_row_info.columns=['MetricId', 'MetricName', 'Display_Name', 'MetricParentName',
                               'ParentId', 'IsSelectable', 'AttributetypeId', 'AttributeId',
                               'IsItemLevel', 'IsLastLevel', 'ToolOrderby', 'IsSnapshot',
                               'SnapshotLastLevel', 'IsAllCountry', 'US', 'UK', 'France', 'Brazil',
                               'Mexico', 'Australia']

#Creating the tool display name and table name map
Tool_name_map_map=Tool_name_map[['Burke Display Name','Display Name']]
Tool_name_map_map.columns=['Burke_Display_Name','Display_Name']

Tool_name_map_map = Tool_name_map_map.dropna()
Tool_name_map_map=Tool_name_map_map.reset_index(drop=True)

Tool_name_map_dict = dict(zip(Tool_name_map_map['Burke_Display_Name'], Tool_name_map_map['Display_Name']))

Tool_name_map.columns=['MetricId', 'MetricName', 'Display_Name', 'Burke_Display_Name']

list_tables=wb.sheetnames
list_tables.remove('Table of Contents')

#To store all the tables
Table_dict={}

# To find:: Table Name, Table header,Base, Filter
Table_Name_used=[]
Table_header=[]
Base_used=[]
Filter_used=[]

for table_number in list_tables:
    data=pd.DataFrame(wb[table_number].values)
    
    data['Indent']=Indent_level_all[table_number]   

    Table_Name=data.loc[0][0]
    Table_Name_used.append(Table_Name)

    Table_Question=data.loc[1][0]
    Table_header.append(Table_Question)

    Table_Question=Table_Question.splitlines()
    
    if len(Table_Question)>=3:
        Filter=Table_Question[len(Table_Question)-1]
    else:
        Filter="No Filter"

    Filter_used.append(Filter)

    data_index=data.index.tolist()
    data_column=len(data.columns)

    data_1=data

    for i in data_index:
        for j in range(0,data_column-1):
            if data_1.loc[i,j]=='Client Confidential':
                temp=i
            else:
                continue            

    for i in range(temp-2,len(data_index)):
                data_1=data_1.drop(i)

    for i in range(0,data_1.shape[0]):
        if data_1.iloc[i][1]=='Total':
            j=i
        else:
            continue

    for i in range(0,j):
        data_1=data_1.drop(i)

    data_1=data_1.reset_index(drop=True)

#Filling the blank rows for merged cells
    for i in range(1,len(data_1.index)):
        if type(data_1.iloc[i,0])==type(None):
            data_1.iloc[i,0]=data_1.iloc[i-1,0] +str('%')
        else:
            continue

    data_1[0][0]='Row_Names'
    data_1.columns=data_1.loc[0].tolist()
    data_1=data_1.rename(columns = {data_1.columns[len(data_1.columns)-1]:'Indent'})   

    data_1=data_1.drop(0)
    data_1=data_1.reset_index(drop=True)

    for i in range(0,len(data_1.index)):
        temp=data_1['Row_Names'][i]
        
        if type(temp)==type(None):            
            continue 
        else:
            if (temp.find('Base ') != -1):
                where=i 
            else:
                continue    

#Using Burk's Mapping to convert row names to Display Names    
    data_1['Row_Names']=data_1['Row_Names'].map(Tool_name_map_dict).fillna(data_1['Row_Names'])
    
    Base=''
    Base=data_1['Row_Names'][where]
    Base=Base.replace('Base - ','',1)

    Base_used.append(Base)
    
    data_table_name = 'data_table'+str('_')+str(Table_Question[0])+str('_')
    
       
    Table_dict[data_table_name]=data_1

Tables_to_be_checked_first_round=[]
Tables_to_be_checked_first_round=[2,3,4,6,8,10,11,12,13,40,41,42,43,44,45,46,47,48,49,50,51,108,109,110,111,112,114,115,
                                  116,117,119,120,121,122,124,125,126,127,129,130,131,132,134,135,136,137,139,140,141,142,
                                  144,145,146,147,149,150,151,152,154,155,156,157,159,160,161,162,164,165,166,167,169,170,
                                  171,172,174,175,176,177,179,180,181,182,184,185,186,187,189,190,191,192,195,197,199,200,
                                  201,202,203,204,205,206,207,212,213,215]
Check_tables=[195]

#To store all the syntax for tables
Table_row_category_dict={}
Table_row_demog_dict={}
Table_row_5w_dict={}
Table_row_syntax_dict={}
Table_row_parent_prefix_dict={}
Table_output_file_data_dict={}
file_path='C:\\Users\\10920\\Desktop\\Automation\\Output_tables\\Round_1\\'

#finding all the selection syntax parameters for the table
for table_number in Tables_to_be_checked_first_round:
    data_table_name = 'data_table_Table: '+str(table_number)+str('_')

    data_2=Table_dict[data_table_name]

    Indent=data_2[['Row_Names','Indent']]

    Indent=data_2[['Row_Names','Indent']]
    Indent.columns=['table_row_name','indent_row_level']

#Creating the Indent data to find the zero level indented rows for selection

    for i in range(0,len(Indent.index)):
        if (Indent['table_row_name'][i].find('%') != -1):
            Indent=Indent.drop(i)
        else:
            continue
    Indent=Indent.reset_index(drop=True) 

    counter=0

    for i in range(3,len(Indent.index)):
        if ('Total' in Indent['table_row_name'][i]):
            counter=i
            break        
        else:
            continue

    if counter!=0:
        for x in range(counter,len(Indent.index)):
            Indent=Indent.drop(x)
    Indent=Indent.reset_index(drop=True)

    Indent['table_row_name']=Indent['table_row_name'].map(Tool_name_map_dict).fillna(Indent['table_row_name'])

#Finding the row selection for 0 level Indent
    indent_selection_all =pd.DataFrame(columns=['table','syntax' ])

    key=0
    temp_0="Junk"

    for x in range(2,len(Indent.index)):    

        if Indent['indent_row_level'][x]==0:
            indent_selection_all.loc[key,'table']=table_number
            indent_selection_all.loc[key,'syntax']=temp_0        
            key += 1
            temp_0=Indent['table_row_name'][x]
            temp_0 = str('>')+temp_0    
            
        elif Indent['indent_row_level'][x]==1:
            if Indent['indent_row_level'][x-1]==0:
                temp_0=temp_0+str('^')+Indent['table_row_name'][x]
            else:
                temp_0=temp_0+str('|')+Indent['table_row_name'][x]            
            
        elif Indent['indent_row_level'][x]==2:            
            temp_0=temp_0+str('^')+Indent['table_row_name'][x]

        else:
            continue

    indent_selection_all.loc[key,'table']='table_number'
    indent_selection_all.loc[key,'syntax']=temp_0 


    row_level_syntax=''
    row_level_syntax_1=''

    for x in indent_selection_all['syntax']:
        row_level_syntax=x
        row_level_syntax_1=row_level_syntax_1+row_level_syntax 

    row_level_syntax_1=row_level_syntax_1.replace('Junk','')

    row_level_syntax_1=row_level_syntax_1[1:len(row_level_syntax_1)]
    Table_row_syntax_dict[table_number]=row_level_syntax_1

# Finding the parent prefix by calling the find_parent_prefix function 
    flag=0
    for x in range(2,len(Indent.index)):   
        temp_row_value=''     
        if Indent['indent_row_level'][x]==0:
            temp_row_value=Indent['table_row_name'][x]
            flag=x
            break
        else:
            continue    

    Parent_prefix_for_row, parent_list=find_parent_prefix(temp_row_value)    
    
    attribute_iid=0
    for x in range(0,len(Mapping_for_row_info.index)):
        if Mapping_for_row_info['Display_Name'][x]==temp_row_value:
            attribute_iid=Mapping_for_row_info['AttributetypeId'][x]
        else:
            continue
    if attribute_iid in [38,39,40] and len(parent_list)==1:
        Row_name_list_1=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_iid]['AttributeType']        
        Row_name_1=Row_name_list_1[Row_name_list_1.index[0]]
        parent_list.append(Row_name_1)
        Parent_prefix_for_row=Parent_prefix_for_row
        
    if len(Parent_prefix_for_row)<=5 and flag<len(Indent.index):
        while len(Parent_prefix_for_row)<=5 and flag<len(Indent.index):
            Parent_prefix_for_row, parent_list=find_parent_prefix(Indent['table_row_name'][flag])
            flag=flag+1    
    
    Table_row_parent_prefix_dict[table_number]=Parent_prefix_for_row
    

# Finding the Row for the selection
    temp_1_row_value='' 
    for x in range(4,len(Indent.index)):
        if Indent['indent_row_level'][x]==0:
            temp_1_row_value=Indent['table_row_name'][x]
            break
        else:
            continue 
    if table_number==50:
        print(temp_1_row_value)
    
    metric_id=0
    for x in range(0,len(Tool_name_map.index)):
        if Tool_name_map['Display_Name'][x]==temp_1_row_value:
            metric_id=Tool_name_map['MetricId'][x]
        else:
            continue
            
    if table_number==50:
        print(metric_id)

    attribute_id=0
    for x in range(0,len(Mapping_for_row_info.index)):
        if Mapping_for_row_info['MetricId'][x]==metric_id:
            attribute_id=Mapping_for_row_info['AttributetypeId'][x]
        else:
            continue
            
    if table_number==50:
        print(attribute_id)

    Row_name_list=[]
    Row_name=''

    if attribute_id in [38,39,40]:
        Row_name_list=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_id]['AttributeType']        
        Row_name=Row_name_list[Row_name_list.index[0]]
    else:
        if len(parent_list)!=0:
            Row_name=parent_list[len(parent_list)-1]    
       
    if Row_name=='Item' or Row_name=='Brand' or Row_name=='Category':
        Table_row_category_dict[table_number]=Row_name
    elif Row_name=='Demographics':
        Table_row_demog_dict[table_number]=Row_name
    elif Row_name=='5Ws':
        Table_row_5w_dict[table_number]=Row_name
    else:
        Table_row_category_dict[table_number]='NA'
        Table_row_demog_dict[table_number]='NA'
        Table_row_5w_dict[table_number]='NA'

# Creating Table Filter
prefix_filter={}

for Table_Number___ in Tables_to_be_checked_first_round:
    data_table_name = 'data_table_Table: '+str(Table_Number___)+str('_')
    data_2=Table_dict[data_table_name]
    filter_used=Filter_used[Table_Number___-1]

    Indent=data_2[['Row_Names','Indent']]
    Indent=data_2[['Row_Names','Indent']]
    Indent.columns=['table_row_name','indent_row_level']

    #Creating the Indent data to find the zero level indented rows for selection

    for i in range(0,len(Indent.index)):
        if (Indent['table_row_name'][i].find('%') != -1):
            Indent=Indent.drop(i)
        else:
            continue
    Indent=Indent.reset_index(drop=True) 

    counter=0

    for i in range(3,len(Indent.index)):
        if ('Total' in Indent['table_row_name'][i]):
            counter=i
            break        
        else:
            continue

    if counter!=0:
        for x in range(counter,len(Indent.index)):
            Indent=Indent.drop(x)
    Indent=Indent.reset_index(drop=True)

    Indent['table_row_name']=Indent['table_row_name'].map(Tool_name_map_dict).fillna(Indent['table_row_name']) 

    temp_row_value=filter_used
    
    metric_iid=0
    for x in range(0,len(Tool_name_map['Burke_Display_Name'])):
        if Tool_name_map['Burke_Display_Name'][x]==temp_row_value:
            metric_iid=Tool_name_map['MetricId'][x]
        else:
            continue        

    row_parent_name=''
    row_parent_id=0
    parent_list=[]

    for x in range(0,len(Mapping_for_row_info['Display_Name'])):
        if Mapping_for_row_info['MetricId'][x]==metric_iid:
            row_parent_name=Mapping_for_row_info['MetricParentName'][x]
            row_parent_id=Mapping_for_row_info['ParentId'][x]
        else:
            continue

    parent_list.append(row_parent_name)

    while(row_parent_id!=0):
        temp_id=Mapping_for_row_info['ParentId'][Mapping_for_row_info['MetricId']==row_parent_id].values[0]
        parent_list.append(Mapping_for_row_info['MetricParentName'][Mapping_for_row_info['ParentId']==temp_id].values[0])  
        row_parent_id=temp_id

    parent_list.remove(parent_list[len(parent_list)-1])

    Parent_prefix=''
    for x in range(0,len(parent_list)):
        if (x==len(parent_list)-1):
                    Parent_prefix=str('Row')+str('^')+Parent_prefix
                    Parent_prefix=parent_list[x]+str('^')+Parent_prefix
        else:
            Parent_prefix=parent_list[x]+str('^')+Parent_prefix  

    prefix_filter[Table_Number___]=Parent_prefix+filter_used

All_table_info=pd.DataFrame({'row_category':pd.Series(Table_row_category_dict),'row_demog':pd.Series(Table_row_demog_dict),
                             'row_5w':pd.Series(Table_row_5w_dict),'row_syntax':pd.Series(Table_row_syntax_dict),
                             'row_parent':pd.Series(Table_row_parent_prefix_dict),'row_filter':pd.Series(prefix_filter)})

All_table_info.to_csv('All_table_info.csv')

#Finding the parent prefix for the row entries 

def find_parent_prefix(name):    
    
    metric_id=0
    for x in range(0,len(Tool_name_map.index)):
        if Tool_name_map['Display_Name'][x]==name:
            metric_id=Tool_name_map['MetricId'][x]
            break
        else:
            continue

    row_parent_name=''
    row_parent_iid=0
    parent_list=[]

    for x in range(0,len(Mapping_for_row_info['Display_Name'])):        
        if Mapping_for_row_info['MetricId'][x]==metric_id:
            row_parent_iid=Mapping_for_row_info['ParentId'][x]
            row_parent_metric_name=Mapping_for_row_info['MetricParentName'][x]
            row_parent_name=Mapping_for_row_info['Display_Name'][Mapping_for_row_info['MetricName']==row_parent_metric_name].values[0]
            break
        else:
            continue

    parent_list.append(row_parent_name)  

    while(row_parent_iid!=0):
        temp_iid=Mapping_for_row_info.loc[Mapping_for_row_info['MetricId']==row_parent_iid,'ParentId'].iloc[0]
        if temp_iid==0:
            break
        else:
            row_parent_metric_name_1=Mapping_for_row_info[Mapping_for_row_info['ParentId']==temp_iid]['MetricParentName'].iloc[0]
            row_parent_name_1=Mapping_for_row_info[Mapping_for_row_info['MetricName']==row_parent_metric_name_1]['Display_Name'].iloc[0]
        row_parent_iid=temp_iid
        
        parent_list.append(row_parent_name_1)            

    Parent_prefix=''
    for x in range(0,len(parent_list)):
        if (x==len(parent_list)-1):
                    Parent_prefix=str('Row')+str('^')+Parent_prefix
                    Parent_prefix=parent_list[x]+str('^')+Parent_prefix
        else:
            Parent_prefix=parent_list[x]+str('^')+Parent_prefix 
    return Parent_prefix , parent_list


#For output tables : Row names for selection

def find_prefix(name,data):
    indent_for_value=0
    return_value=''
    return_value_1=[]
    return_value_2=''    
    for x in range(0, len(data.index)):
        if data['Row_Names'][x]==name:
            indent_for_value=data['Indent'][x]
            if indent_for_value==0:
                return_value=name
            elif indent_for_value==1:
                for i in range(x,-1,-1):
                    if data['Indent'][i]==0:
                        return_value=data['Row_Names'][i]+str('|')+data['Row_Names'][x]
                        break
                    else:
                        continue
            elif indent_for_value==2:
                for i in range(x,-1,-1):
                    if data['Indent'][i]==2:
                        continue                        
                    elif data['Indent'][i]==1:
                        return_value_1.append(data['Row_Names'][i])                        
                    elif data['Indent'][i]==0:
                        return_value_2=data['Row_Names'][i]
                        break
                    else:
                        continue
                return_value=return_value_2+str('|')+return_value_1[0]
    return return_value

#generating the output files
for table_number in Tables_to_be_checked_first_round:
    data_table_name = 'data_table_Table: '+str(table_number)+str('_')

    Test_table=Table_dict[data_table_name]

    id_vars =['Row_Names']
    value_vars =['Total', 'Early Morning Bite','Breakfast For One','Family Breakfast','Breakfast @ Work / School', 
                          'Mid Morning Snack','Lunch','Lunch Alternative', 'Afternoon Snack','After Work / School Bite',
                           'Dinner', 'Dinner Alternative','Evening Me', 'Evening We','Bedtime / Late Night Snack']
    var_name =['Occasions']

    Unweighted_base=Test_table[:1]
    Unweighted_base=Unweighted_base.melt(id_vars, value_vars, var_name)
    Unweighted_base_dict = dict(zip(Unweighted_base['Occasions'], Unweighted_base['value']))


    Weight_test_table=pd.DataFrame()
    percentage_table=pd.DataFrame()

    Weight_test_table=Test_table[2:]
    percentage_table=Test_table[2:]
    Weight_test_table=Weight_test_table.reset_index(drop=True)
    percentage_table=percentage_table.reset_index(drop=True)

    for i in range(0,len(Weight_test_table.index)):
        if (Weight_test_table['Row_Names'][i].find('%') != -1):
            Weight_test_table=Weight_test_table.drop(i)
        else:
            continue
    Weight_test_table=Weight_test_table.reset_index(drop=True)

    for i in range(0,len(percentage_table.index)):
        if (percentage_table['Row_Names'][i].find('%') == -1):
            percentage_table=percentage_table.drop(i)
        else:
            continue
    percentage_table=percentage_table.reset_index(drop=True) 

    percentage_table=percentage_table.melt(id_vars,value_vars,var_name)

    for x in range(0,len(percentage_table.index)):
        row_name=percentage_table['Row_Names'][x]
        percentage_table['Row_Names'][x]=row_name[0:len(row_name)-1]   

    Weight_test_table=Weight_test_table.melt(id_vars , value_vars ,var_name )

    Table_output_1 = pd.merge(Weight_test_table,percentage_table,  how='left', left_on=['Row_Names','Occasions'],
                              right_on = ['Row_Names','Occasions'])

    Table_output_1.columns=['Row_Names','Occasions','WEIGHTED','Percentage_value']

    Table_output_1['UNWEIGHTED']=Table_output_1['Occasions']
    Table_output_1['UNWEIGHTED']=Table_output_1.Occasions.map(Unweighted_base_dict)

    for i in range(0,len(Table_output_1.index)):
        if (Table_output_1['Row_Names'][i].find('Total') != -1):
            if len(Table_output_1['Row_Names'][i])==5:
                   Table_output_1=Table_output_1.drop(i)
        else:
            continue
    Table_output_1=Table_output_1.reset_index(drop=True)

    uper_level_name=[]
    y=''
    for x in Table_output_1['Row_Names']:
        y=find_prefix(x,Test_table)
        uper_level_name.append(y)

    Table_output_1['New_Row_Names']=uper_level_name

    for x in range(0,len(Table_output_1.index)):    
            if (Table_output_1['New_Row_Names'][x].find('Base ') != -1):
                Table_output_1['New_Row_Names'][x]='Base'
            else:
                continue

    for x in range(0,len(Table_output_1.index)):    
        if (Table_output_1['New_Row_Names'][x].find('%') != -1):
            Table_output_1['New_Row_Names'][x]=Table_output_1['New_Row_Names'][x].replace('%','')
        else:
            continue

    Table_output_1['New_Row_Names']=Table_output_1['New_Row_Names'].map(Tool_name_map_dict).fillna(Table_output_1['New_Row_Names'])

    Table_output_1['New_Row_Names']=Table_output_1['New_Row_Names']+str('|')+Table_output_1['Occasions']
    Table_output_1['Test_Case_number']=table_number

    Table_output_final=Table_output_1[['Test_Case_number','New_Row_Names','Percentage_value', 'WEIGHTED', 'UNWEIGHTED']]
    Table_output_final.columns=['Test_Case_number','Distinct','Percentage_value','WEIGHTED','UNWEIGHTED']
    
    Table_output_file_data_dict[table_number]=Table_output_final

#Storing all the tables in a single dataframe
Output_table=pd.DataFrame()
for key in Table_output_file_data_dict.keys():
    Output_table=Output_table.append(Table_output_file_data_dict[key])

#Saving the table outputs in the appended format
Output_table.to_csv('New_Output_tables_round_1.csv')

# Tables_to_be_tested_1=[51]

#Finding there is Row Nesting in the Table or not 
Indent_level_sum={}
row_parent_all_row={}
row_parent_list_all_row={}

for table_number in Tables_to_be_checked_first_round:
    data_table_name = 'data_table_Table: '+str(table_number)+str('_')

    Test_table=Table_dict[data_table_name]
    
    Indent=Test_table[['Row_Names','Indent']]

    Indent=Test_table[['Row_Names','Indent']]
    Indent.columns=['table_row_name','indent_row_level']

#Creating the Indent data to find the zero level indented rows for selection

    for i in range(0,len(Indent.index)):
        if (Indent['table_row_name'][i].find('%') != -1):
            Indent=Indent.drop(i)
        else:
            continue
    Indent=Indent.reset_index(drop=True) 

    counter=0
    for i in range(3,len(Indent.index)):
        if ('Total' in Indent['table_row_name'][i]):
            counter=i
            break        
        else:
            continue

    if counter!=0:
        for x in range(counter,len(Indent.index)):
            Indent=Indent.drop(x)
    Indent=Indent.reset_index(drop=True)
    
    Indent_level_sum[table_number]=Indent['indent_row_level'].sum()
    
    
    for x in range(2,len(Indent.index)):
        row_parent_prefix_temp=''
        row_parent_list_temp=[]
        row_parent_prefix_temp,row_parent_list_temp=find_parent_prefix(Indent['table_row_name'][x])        
        if row_parent_prefix_temp=='^Row^':
            row_parent_prefix_temp,row_parent_list_temp=find_parent_prefix(Indent['table_row_name'][x].title())
#             print(Indent['table_row_name'][x].title())
        row_parent=str('row_parent_')+str(table_number)+str('_')+str(Indent['table_row_name'][x])
        parent_list=str('row_parent_list_')+str(table_number)+str('_')+str(Indent['table_row_name'][x])
        row_parent_all_row[row_parent]=row_parent_prefix_temp
        row_parent_list_all_row[parent_list]=row_parent_list_temp

All_table_row_info=pd.DataFrame({'row_parent':pd.Series(row_parent_all_row),
                                 'row_parent_list':pd.Series(row_parent_list_all_row)})

All_table_row_info.to_csv('All_table_row_parent_info.csv')

For Tables whith rows not in tool 

Tables_with_rows_not_in_tool=[3,4,10,108,109,110,114,115,116,119,120,121,124,125,126,129,130,131,134,135,
                              136,139,140,141,144,145,146,149,150,151,154,155,156,159,160,161,164,165,166,169,170,
                              171,174,175,176,179,180,181,184,185,186,195,197,213]
check_test_table=[110]

#To store all the syntax for tables
Table_row_category_dict={}
Table_row_demog_dict={}
Table_row_5w_dict={}
Table_row_syntax_dict={}
Table_row_parent_prefix_dict={}
Table_output_file_data_dict={}
file_path='C:\\Users\\10920\\Desktop\\Automation\\Output_tables\\Round_1\\'

#finding all the selection syntax parameters for the table
for table_number in check_test_table:
    data_table_name = 'data_table_Table: '+str(table_number)+str('_')

    data_2=Table_dict[data_table_name]

    Indent=data_2[['Row_Names','Indent']]

    Indent=data_2[['Row_Names','Indent']]
    Indent.columns=['table_row_name','indent_row_level']

#Creating the Indent data to find the zero level indented rows for selection

    for i in range(0,len(Indent.index)):
        if (Indent['table_row_name'][i].find('%') != -1):
            Indent=Indent.drop(i)
        else:
            continue
    Indent=Indent.reset_index(drop=True) 

    counter=0

    for i in range(3,len(Indent.index)):
        if ('Total' in Indent['table_row_name'][i]):
            counter=i
            break        
        else:
            continue

    if counter!=0:
        for x in range(counter,len(Indent.index)):
            Indent=Indent.drop(x)
    Indent=Indent.reset_index(drop=True)

    Indent['table_row_name']=Indent['table_row_name'].map(Tool_name_map_dict).fillna(Indent['table_row_name'])

#Finding the row selection
    indent_selection_all =pd.DataFrame(columns=['table','syntax' ])

    key=0
    flag_11=0
    flag_111=0
    flag_222=0
    flag_2222=0
    y_y=''
    temp_0="Junk"
    row_synatx_1=''
    temp_1=''
    temp_1_prefix=''
    temp_1_parent=[]
    temp_1_parent_name=''
    temp_11_prefix=''
    temp_11_parent=[]
    temp_11_parent_name=''
    loop_for_1=0
    loop_for_2=0
    temp_2_prefix=''
    temp_2_parent=[]
    temp_2_parent_1_name=''
    temp_2_parent_2_name=''
    temp_2_1=''
    row_synatx_2=''
    temp_22_prefix=''
    temp_22_parent=''
    temp_22_parent_1_name=''
    temp_22_parent_2_name=''
    row_parent_default=''
    row_parent_default_1=''
    
    
    
    
    
    
    for x in range(2,len(Indent.index)):    
        

#         if Indent['indent_row_level'][x]==0:
#             indent_selection_all.loc[key,'table']=table_number
#             indent_selection_all.loc[key,'syntax']=temp_0        
#             key += 1
#             temp_0=Indent['table_row_name'][x]
#             temp_0 = str('>')+temp_0    
            
#         if Indent['indent_row_level'][x]==1 and x>=loop_for_1:
#             loop_for_1=x+1
#             temp_1_prefix,temp_1_parent=find_parent_prefix(Indent['table_row_name'][x])           
#             if temp_1_prefix=='^Row^':
#                 continue
#             temp_1_parent_name=temp_1_parent[0]            
#             if flag_111==0:
#                 temp_1=temp_1_parent_name+str('^')+str(Indent['table_row_name'][x])
#                 flag_111=flag_111+1
#             elif y_y==temp_11_parent_name:
#                  temp_1=str(Indent['table_row_name'][x])
#             else:
#                 temp_1=temp_1_parent_name+str('^')+str(Indent['table_row_name'][x])

            
#             if loop_for_1<len(Indent.index):
#                 while Indent['indent_row_level'][loop_for_1]==1:
#                     temp_1=temp_1+str('|')+str(Indent['table_row_name'][loop_for_1])
#                     loop_for_1=loop_for_1+1
#                     if loop_for_1==len(Indent['indent_row_level']):
#                         break
#             for y in range(loop_for_1,len(Indent.index)):
#                    if Indent['indent_row_level'][y]==1:
#                         flag_11=y
#                         break
#             y_y=temp_1_parent_name
#             temp_11_prefix,temp_11_parent=find_parent_prefix(Indent['table_row_name'][flag_11])
#             temp_11_parent_name=temp_11_parent[0]
#             if temp_1_parent_name==temp_11_parent_name:
#                  row_synatx_1=row_synatx_1+temp_1+str('|')
#             else:
#                 row_synatx_1=row_synatx_1+temp_1+str('>')
            

        
        if Indent['indent_row_level'][x]==2 and x>=loop_for_2:
            loop_for_2=x+1
            Matched_metric_id = Tool_name_map['MetricId'][Tool_name_map['Display_Name']==Indent['table_row_name'][x]].tolist() 
            
            if len(Matched_metric_id)<=1:
                temp_2_prefix,temp_2_parent=find_parent_prefix(Indent['table_row_name'][x])
#                 print('parent from here',Indent['table_row_name'][x])
            elif len(Matched_metric_id)>1:
                for s in Matched_metric_id:
                    for a in range(0,len(Mapping_for_row_info.index)):
                        if Mapping_for_row_info['MetricId'][a]==s:
                            row_parent_default_1=Mapping_for_row_info['ParentId'][a]
                            row_parent_default=Mapping_for_row_info['Display_Name'][Mapping_for_row_info['MetricId']==row_parent_default_1]
#                             print(list(row_parent_default))
                            if len(row_parent_default)==1:
                                for k in range(x-1,-1,-1):
                                    if Indent['indent_row_level'][k]==1:
                                        if list(row_parent_default)[0]==Indent['table_row_name'][k]:
                                            temp_2_prefix,temp_2_parent=find_parent_prefix(list(Mapping_for_row_info['Display_Name'][Mapping_for_row_info['MetricId']==s])[0])
                                            temp_2_parent=Indent['table_row_name'][k]
                                            break
                        else:
                            temp_2_prefix=='^Row^'                                    
#             print(Indent['table_row_name'][x],str('--'),temp_2_prefix,str('--'),temp_2_parent)
            
            if temp_2_prefix=='^Row^':
                continue
            temp_2_parent_1_name=temp_2_parent[0]
            temp_2_parent_2_name=temp_2_parent[1]
            
            
            if flag_222==0:
                temp_2_1=temp_2_parent_2_name+str('^')+temp_2_parent_1_name+str('^')+str(Indent['table_row_name'][x])
                flag_222=flag_222+1
            elif y_1==temp_22_parent_2_name:
                temp_2_1=temp_2_parent_1_name+str('^')+str(Indent['table_row_name'][x])
            
            if loop_for_2<len(Indent.index):
                while Indent['indent_row_level'][loop_for_2]==2:
                    temp_2_1=temp_2_1+str('|')+str(Indent['table_row_name'][loop_for_2])
                    loop_for_2=loop_for_2+1
                    if loop_for_2==len(Indent['indent_row_level']):
                        break            
            y_2=temp_2_parent_2_name
            y_1=temp_2_parent_1_name            
            for z in range(loop_for_2,len(Indent.index)):
                if Indent['indent_row_level'][z]==2:
                    flag_2222=z
                    break            
            temp_22_prefix,temp_22_parent=find_parent_prefix(Indent['table_row_name'][flag_2222])
            if len(temp_22_parent)>=2:
                temp_22_parent_1_name=temp_22_parent[0]
                temp_22_parent_2_name=temp_22_parent[1]
                
            if temp_2_parent_2_name==temp_22_parent_2_name:
                 row_synatx_2=row_synatx_2+temp_2_1+str('|')
            else:
                row_synatx_2=row_synatx_2+temp_2_1+str('>')
        else:
            continue    

#     indent_selection_all.loc[key,'table']='table_number'
#     indent_selection_all.loc[key,'syntax']=temp_0 


#     row_level_syntax=''
#     row_level_syntax_1=''

#     for x in indent_selection_all['syntax']:
#         row_level_syntax=x
#         row_level_syntax_1=row_level_syntax_1+row_level_syntax 

#     row_level_syntax_1=row_level_syntax_1.replace('Junk','')

#     row_level_syntax_1=row_level_syntax_1[1:len(row_level_syntax_1)]
    Table_row_syntax_dict[table_number]=row_synatx_2

# Finding the parent prefix by calling the find_parent_prefix function 
    flag=0
    for x in range(2,len(Indent.index)):   
        temp_row_value=''     
        if Indent['indent_row_level'][x]==0:
            temp_row_value=Indent['table_row_name'][x]
            flag=x
            break
        else:
            continue    

    Parent_prefix_for_row, parent_list=find_parent_prefix(temp_row_value)    
    
    attribute_iid=0
    for x in range(0,len(Mapping_for_row_info.index)):
        if Mapping_for_row_info['Display_Name'][x]==temp_row_value:
            attribute_iid=Mapping_for_row_info['AttributetypeId'][x]
        else:
            continue
    if attribute_iid in [38,39,40] and len(parent_list)==1:
        Row_name_list_1=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_iid]['AttributeType']        
        Row_name_1=Row_name_list_1[Row_name_list_1.index[0]]
        parent_list.append(Row_name_1)
        Parent_prefix_for_row=Parent_prefix_for_row
        
    if len(Parent_prefix_for_row)<=5 and flag<len(Indent.index):
        while len(Parent_prefix_for_row)<=5 and flag<len(Indent.index):
            Parent_prefix_for_row, parent_list=find_parent_prefix(Indent['table_row_name'][flag])
            flag=flag+1    
    
    Table_row_parent_prefix_dict[table_number]=Parent_prefix_for_row
    

# Finding the Row for the selection
    temp_1_row_value='' 
    for x in range(4,len(Indent.index)):
        if Indent['indent_row_level'][x]==0:
            temp_1_row_value=Indent['table_row_name'][x]
            break
        else:
            continue 
    
    metric_id=0
    for x in range(0,len(Tool_name_map.index)):
        if Tool_name_map['Display_Name'][x]==temp_1_row_value:
            metric_id=Tool_name_map['MetricId'][x]
        else:
            continue
            
    attribute_id=0
    for x in range(0,len(Mapping_for_row_info.index)):
        if Mapping_for_row_info['MetricId'][x]==metric_id:
            attribute_id=Mapping_for_row_info['AttributetypeId'][x]
        else:
            continue

    Row_name_list=[]
    Row_name=''

    if attribute_id in [38,39,40]:
        Row_name_list=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_id]['AttributeType']        
        Row_name=Row_name_list[Row_name_list.index[0]]
    else:
        if len(parent_list)!=0:
            Row_name=parent_list[len(parent_list)-1]    
       
    if Row_name=='Item' or Row_name=='Brand' or Row_name=='Category':
        Table_row_category_dict[table_number]=Row_name
    elif Row_name=='Demographics':
        Table_row_demog_dict[table_number]=Row_name
    elif Row_name=='5Ws':
        Table_row_5w_dict[table_number]=Row_name
    else:
        Table_row_category_dict[table_number]='NA'
        Table_row_demog_dict[table_number]='NA'
        Table_row_5w_dict[table_number]='NA'

All_table_info=pd.DataFrame({'row_category':pd.Series(Table_row_category_dict),'row_demog':pd.Series(Table_row_demog_dict),
                             'row_5w':pd.Series(Table_row_5w_dict),'row_syntax':pd.Series(Table_row_syntax_dict),
                             'row_parent':pd.Series(Table_row_parent_prefix_dict)})

All_table_info.to_csv('Notfound_table_info_1.csv')

print(Table_row_parent_prefix_dict[110]),print(Table_row_syntax_dict[110])

find_parent_prefix('Coffee shop/cafe')

row_synatx_2

Mapping_for_row_info.columns

########################### Automation 4 #################################################

import numpy as np 
import pandas as pd 
import openpyxl
from openpyxl import load_workbook

import warnings
warnings.filterwarnings("ignore")

#Left Panel mapping file for parent prefix
Mapping_for_row_info= pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\LeftPanel_Hierarchy 10112019 (wo OSP).xlsx",
                                             sheet_name="LeftPanel_Hierarchy 10112019 (w"))

#Display name and tool name mapping Tool to Check 
Tool_name_map = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Burke to Tool Mapping File 09272019.xlsx",
                                             sheet_name="In Tool"))

#Attribute id and the value for the rows of the selection
Attribute_name_map = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Sample Automation Test Cases with output 19_09_2019.xlsx",
                                             sheet_name="AttributeType"))

#Read Tables
file_path_US_Q2= "C:\\Users\\10920\\Desktop\\Automation\\Total Tables by Occasion - Q2 US.xlsx"
wb_us_q2 = load_workbook(file_path_US_Q2)

wb=wb_us_q2

#read Indent Level for files
Indent_level_us_q2= pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Indent_level_all.xlsx",
                                             sheet_name="Indent"))
Indent_level_all=Indent_level_us_q2

Mapping_for_row_info.columns=['MetricId', 'MetricName', 'Display_Name', 'MetricParentName',
                               'ParentId', 'IsSelectable', 'AttributetypeId', 'AttributeId',
                               'IsItemLevel', 'IsLastLevel', 'ToolOrderby', 'IsSnapshot',
                               'SnapshotLastLevel', 'IsAllCountry', 'US', 'UK', 'France', 'Brazil',
                               'Mexico', 'Australia']

#Creating the tool display name and table name map
Tool_name_map_map=Tool_name_map[['Burke Display Name','Display Name']]
Tool_name_map_map.columns=['Burke_Display_Name','Display_Name']

Tool_name_map_map = Tool_name_map_map.dropna()
Tool_name_map_map=Tool_name_map_map.reset_index(drop=True)

Tool_name_map_dict = dict(zip(Tool_name_map_map['Burke_Display_Name'], Tool_name_map_map['Display_Name']))

Tool_name_map.columns=['MetricId', 'MetricName', 'Display_Name', 'Burke_Display_Name']

list_tables=wb.sheetnames
list_tables.remove('Table of Contents')

#To store all the tables
Table_dict={}

# To find:: Table Name, Table header,Base, Filter
Table_Name_used=[]
Table_header=[]
Base_used=[]
Filter_used=[]

for table_number in list_tables:
    data=pd.DataFrame(wb[table_number].values)
    
    data['Indent']=Indent_level_all[table_number]   

    Table_Name=data.loc[0][0]
    Table_Name_used.append(Table_Name)

    Table_Question=data.loc[1][0]
    Table_header.append(Table_Question)

    Table_Question=Table_Question.splitlines()
    
    if len(Table_Question)>=3:
        Filter=Table_Question[len(Table_Question)-1]
    else:
        Filter="No Filter"

    Filter_used.append(Filter)

    data_index=data.index.tolist()
    data_column=len(data.columns)

    data_1=data

    for i in data_index:
        for j in range(0,data_column-1):
            if data_1.loc[i,j]=='Client Confidential':
                temp=i
            else:
                continue            

    for i in range(temp-2,len(data_index)):
                data_1=data_1.drop(i)

    for i in range(0,data_1.shape[0]):
        if data_1.iloc[i][1]=='Total':
            j=i
        else:
            continue

    for i in range(0,j):
        data_1=data_1.drop(i)

    data_1=data_1.reset_index(drop=True)

#Filling the blank rows for merged cells
    for i in range(1,len(data_1.index)):
        if type(data_1.iloc[i,0])==type(None):
            data_1.iloc[i,0]=data_1.iloc[i-1,0] +str('%')
        else:
            continue

    data_1[0][0]='Row_Names'
    data_1.columns=data_1.loc[0].tolist()
    data_1=data_1.rename(columns = {data_1.columns[len(data_1.columns)-1]:'Indent'})   

    data_1=data_1.drop(0)
    data_1=data_1.reset_index(drop=True)

    for i in range(0,len(data_1.index)):
        temp=data_1['Row_Names'][i]
        
        if type(temp)==type(None):            
            continue 
        else:
            if (temp.find('Base ') != -1):
                where=i 
            else:
                continue    

#Using Burk's Mapping to convert row names to Display Names    
    data_1['Row_Names']=data_1['Row_Names'].map(Tool_name_map_dict).fillna(data_1['Row_Names'])
    
    Base=''
    Base=data_1['Row_Names'][where]
    Base=Base.replace('Base - ','',1)

    Base_used.append(Base)
    
    data_table_name = 'data_table'+str('_')+str(Table_Question[0])+str('_')
    
       
    Table_dict[data_table_name]=data_1

for key in Table_dict.keys():
    Table_dict[key].columns=['Row_Names', 'Total', 'Early Morning Bite', 'Breakfast For One',
       'Family Breakfast', 'Breakfast at Work/School', 'Mid Morning Snack',
       'Lunch', 'Lunch Alternative', 'Afternoon Snack',
       'After Work/School Bite', 'Dinner', 'Dinner Alternative',
       'Evening Me', 'Evening We', 'Bedtime/Late Night Snack', 'Indent']

#Finding the parent prefix for the row entries 

def find_parent_prefix(name):    
    
    metric_id=0
    for x in range(0,len(Tool_name_map.index)):
        if Tool_name_map['Display_Name'][x]==name:
            metric_id=Tool_name_map['MetricId'][x]
            break
        else:
            continue

    row_parent_name=''
    row_parent_iid=0
    parent_list=[]

    for x in range(0,len(Mapping_for_row_info['Display_Name'])):        
        if Mapping_for_row_info['MetricId'][x]==metric_id:
            row_parent_iid=Mapping_for_row_info['ParentId'][x]
            row_parent_metric_name=Mapping_for_row_info['MetricParentName'][x]
            row_parent_name=Mapping_for_row_info['Display_Name'][Mapping_for_row_info['MetricName']==row_parent_metric_name].values[0]
            break
        else:
            continue

    parent_list.append(row_parent_name)  

    while(row_parent_iid!=0):
        temp_iid=Mapping_for_row_info.loc[Mapping_for_row_info['MetricId']==row_parent_iid,'ParentId'].iloc[0]
        if temp_iid==0:
            break
        else:
            row_parent_metric_name_1=Mapping_for_row_info[Mapping_for_row_info['ParentId']==temp_iid]['MetricParentName'].iloc[0]
            row_parent_name_1=Mapping_for_row_info[Mapping_for_row_info['MetricName']==row_parent_metric_name_1]['Display_Name'].iloc[0]
        row_parent_iid=temp_iid
        
        parent_list.append(row_parent_name_1)            

    Parent_prefix=''
    for x in range(0,len(parent_list)):
        if (x==len(parent_list)-1):
                    Parent_prefix=str('Row')+str('^')+Parent_prefix
                    Parent_prefix=parent_list[x]+str('^')+Parent_prefix
        else:
            Parent_prefix=parent_list[x]+str('^')+Parent_prefix 
    return Parent_prefix , parent_list


#For output tables : Row names for selection

def find_prefix(name,data):
    indent_for_value=0
    return_value=''
    return_value_1=[]
    return_value_2=''    
    for x in range(0, len(data.index)):
        if data['Row_Names'][x]==name:
            indent_for_value=data['Indent'][x]
            if indent_for_value==0:
                return_value=name
            elif indent_for_value==1:
                for i in range(x,-1,-1):
                    if data['Indent'][i]==0:
                        return_value=data['Row_Names'][i]+str('|')+data['Row_Names'][x]
                        break
                    else:
                        continue
            elif indent_for_value==2:
                for i in range(x,-1,-1):
                    if data['Indent'][i]==2:
                        continue                        
                    elif data['Indent'][i]==1:
                        return_value_1.append(data['Row_Names'][i])                        
                    elif data['Indent'][i]==0:
                        return_value_2=data['Row_Names'][i]
                        break
                    else:
                        continue
                return_value=return_value_2+str('|')+return_value_1[0]
    return return_value

def find_parent_prefix_metric_id(metric_id):    
    row_parent_name=''
    row_parent_iid=0
    parent_list=[]

    for x in range(0,len(Mapping_for_row_info['Display_Name'])):        
        if Mapping_for_row_info['MetricId'][x]==metric_id:
            row_parent_iid=Mapping_for_row_info['ParentId'][x]
            row_parent_metric_name=Mapping_for_row_info['MetricParentName'][x]
            row_parent_name=Mapping_for_row_info['Display_Name'][Mapping_for_row_info['MetricName']==row_parent_metric_name].values[0]
            break
        else:
            continue

    parent_list.append(row_parent_name)  

    while(row_parent_iid!=0):
        temp_iid=Mapping_for_row_info.loc[Mapping_for_row_info['MetricId']==row_parent_iid,'ParentId'].iloc[0]
        if temp_iid==0:
            break
        else:
            row_parent_metric_name_1=Mapping_for_row_info[Mapping_for_row_info['ParentId']==temp_iid]['MetricParentName'].iloc[0]
            row_parent_name_1=Mapping_for_row_info[Mapping_for_row_info['MetricName']==row_parent_metric_name_1]['Display_Name'].iloc[0]
        row_parent_iid=temp_iid
        
        parent_list.append(row_parent_name_1)            

    Parent_prefix=''
    for x in range(0,len(parent_list)):
        if (x==len(parent_list)-1):
                    Parent_prefix=str('Row')+str('^')+Parent_prefix
                    Parent_prefix=parent_list[x]+str('^')+Parent_prefix
        else:
            Parent_prefix=parent_list[x]+str('^')+Parent_prefix 
    return Parent_prefix , parent_list

Tables_to_be_checked_first_round=[]
Tables_to_be_checked_first_round=[2,3,4,6,8,10,11,12,13,40,41,42,43,44,45,46,47,48,49,50,51,108,109,110,111,112,114,115,
                                  116,117,119,120,121,122,124,125,126,127,129,130,131,132,134,135,136,137,139,140,141,142,
                                  144,145,146,147,149,150,151,152,154,155,156,157,159,160,161,162,164,165,166,167,169,170,
                                  171,172,174,175,176,177,179,180,181,182,184,185,186,187,189,190,191,192,195,197,199,200,
                                  201,202,203,204,205,206,207,212,213,215]

#To store all the syntax for tables
Table_row_category_dict={}
Table_row_demog_dict={}
Table_row_5w_dict={}
row_parent_all_row={}
row_parent_list_all_row={}
Table_row_syntax_dict={}
Table_row_parent_prefix_dict={}
Table_output_file_data_dict={}
file_path='C:\\Users\\10920\\Desktop\\Automation\\Output_tables\\Round_1\\'

#finding all the selection syntax parameters for the table
for table_number in Tables_to_be_checked_first_round:
    data_table_name = 'data_table_Table: '+str(table_number)+str('_')

    data_2=Table_dict[data_table_name]

    Indent=data_2[['Row_Names','Indent']]

    Indent=data_2[['Row_Names','Indent']]
    Indent.columns=['table_row_name','indent_row_level']

#Creating the Indent data to find the zero level indented rows for selection

    for i in range(0,len(Indent.index)):
        if (Indent['table_row_name'][i].find('%') != -1):
            Indent=Indent.drop(i)
        else:
            continue
    Indent=Indent.reset_index(drop=True) 

    counter=0

    for i in range(3,len(Indent.index)):
        if ('Total' in Indent['table_row_name'][i]):
            counter=i
            break        
        else:
            continue

    if counter!=0:
        for x in range(counter,len(Indent.index)):
            Indent=Indent.drop(x)
    Indent=Indent.reset_index(drop=True)

    Indent['table_row_name']=Indent['table_row_name'].map(Tool_name_map_dict).fillna(Indent['table_row_name'])

#Finding the row selection for 0 level Indent
    indent_selection_all =pd.DataFrame(columns=['table','syntax' ])

    key=0
    temp_0="Junk"

    for x in range(2,len(Indent.index)):    

        if Indent['indent_row_level'][x]==0:
            indent_selection_all.loc[key,'table']=table_number
            indent_selection_all.loc[key,'syntax']=temp_0        
            key += 1
            temp_0=Indent['table_row_name'][x]
            temp_0 = str('>')+temp_0    
            
        elif Indent['indent_row_level'][x]==1:
            if Indent['indent_row_level'][x-1]==0:
                temp_0=temp_0+str('^')+Indent['table_row_name'][x]
            else:
                temp_0=temp_0+str('|')+Indent['table_row_name'][x]            
            
        elif Indent['indent_row_level'][x]==2:            
            temp_0=temp_0+str('^')+Indent['table_row_name'][x]

        else:
            continue

    indent_selection_all.loc[key,'table']='table_number'
    indent_selection_all.loc[key,'syntax']=temp_0 


    row_level_syntax=''
    row_level_syntax_1=''

    for x in indent_selection_all['syntax']:
        row_level_syntax=x
        row_level_syntax_1=row_level_syntax_1+row_level_syntax 

    row_level_syntax_1=row_level_syntax_1.replace('Junk','')

    row_level_syntax_1=row_level_syntax_1[1:len(row_level_syntax_1)]
    Table_row_syntax_dict[table_number]=row_level_syntax_1

# Finding the parent prefix by calling the find_parent_prefix function 
    flag=0
    for x in range(2,len(Indent.index)):   
        temp_row_value=''     
        if Indent['indent_row_level'][x]==0:
            temp_row_value=Indent['table_row_name'][x]
            flag=x
            break
        else:
            continue    

    Parent_prefix_for_row, parent_list=find_parent_prefix(temp_row_value)    
    
    attribute_iid=0
    for x in range(0,len(Mapping_for_row_info.index)):
        if Mapping_for_row_info['Display_Name'][x]==temp_row_value:
            attribute_iid=Mapping_for_row_info['AttributetypeId'][x]
        else:
            continue
    if attribute_iid in [38,39,40] and len(parent_list)==1:
        Row_name_list_1=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_iid]['AttributeType']        
        Row_name_1=Row_name_list_1[Row_name_list_1.index[0]]
        parent_list.append(Row_name_1)
        Parent_prefix_for_row=Parent_prefix_for_row
        
    if len(Parent_prefix_for_row)<=5 and flag<len(Indent.index):
        while len(Parent_prefix_for_row)<=5 and flag<len(Indent.index):
            Parent_prefix_for_row, parent_list=find_parent_prefix(Indent['table_row_name'][flag])
            flag=flag+1    
    
    Table_row_parent_prefix_dict[table_number]=Parent_prefix_for_row
    
    
    
    for x in range(2,len(Indent.index)):
        row_parent_prefix_temp=''
        row_parent_list_temp=[]
#         indent_level_for_row=Indent['indent_row_level'][x]
#         Matched_metric_id = Tool_name_map['MetricId'][Tool_name_map['Display_Name']==Indent['table_row_name'][x]].tolist() 
            
#         if len(Matched_metric_id)<=1:
#             row_parent_prefix_temp,row_parent_list_temp=find_parent_prefix(Indent['table_row_name'][x])
#         elif len(Matched_metric_id)>1:
#             for s in Matched_metric_id:
#                 for a in range(0,len(Mapping_for_row_info.index)):
#                     if Mapping_for_row_info['MetricId'][a]==s:
#                         row_parent_default_1=Mapping_for_row_info['ParentId'][a]
#                         row_parent_default=Mapping_for_row_info['Display_Name'][Mapping_for_row_info['MetricId']==row_parent_default_1]
#                         if len(row_parent_default)==1:
#                             for k in range(x-1,-1,-1):
#                                 if Indent['indent_row_level'][k]==indent_level_for_row:
#                                     if list(row_parent_default)[0]==Indent['table_row_name'][k]:
#                                         row_parent_prefix_temp,row_parent_list_temp=find_parent_prefix_metric_id(s)                                            
#                                         break
#                     else:
#                         row_parent_prefix_temp=='^Row^'     
        
        row_parent_prefix_temp,row_parent_list_temp=find_parent_prefix(Indent['table_row_name'][x])        
        if row_parent_prefix_temp=='^Row^':
            row_parent_prefix_temp,row_parent_list_temp=find_parent_prefix(Indent['table_row_name'][x].title())
        table_row_key=str('row_')+str(Indent['table_row_name'][x])+str('_')+str(table_number)+str('_')+str(x)
        #         parent_list=str('row_parent_list_')+str(table_number)+str('_')+str(Indent['table_row_name'][x])
        row_parent_all_row[table_row_key]=row_parent_prefix_temp+str(Indent['table_row_name'][x])
        row_parent_list_all_row[table_row_key]=row_parent_list_temp
        

# Finding the Row for the selection
    temp_1_row_value='' 
    for x in range(4,len(Indent.index)):
        if Indent['indent_row_level'][x]==0:
            temp_1_row_value=Indent['table_row_name'][x]
            break
        else:
            continue 
    if table_number==50:
        print(temp_1_row_value)
    
    metric_id=0
    for x in range(0,len(Tool_name_map.index)):
        if Tool_name_map['Display_Name'][x]==temp_1_row_value:
            metric_id=Tool_name_map['MetricId'][x]
        else:
            continue
            
    if table_number==50:
        print(metric_id)

    attribute_id=0
    for x in range(0,len(Mapping_for_row_info.index)):
        if Mapping_for_row_info['MetricId'][x]==metric_id:
            attribute_id=Mapping_for_row_info['AttributetypeId'][x]
        else:
            continue
            
    if table_number==50:
        print(attribute_id)

    Row_name_list=[]
    Row_name=''

    if attribute_id in [38,39,40]:
        Row_name_list=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_id]['AttributeType']        
        Row_name=Row_name_list[Row_name_list.index[0]]
    else:
        if len(parent_list)!=0:
            Row_name=parent_list[len(parent_list)-1]    
       
    if Row_name=='Item' or Row_name=='Brand' or Row_name=='Category':
        Table_row_category_dict[table_number]=Row_name
    elif Row_name=='Demographics':
        Table_row_demog_dict[table_number]=Row_name
    elif Row_name=='5Ws':
        Table_row_5w_dict[table_number]=Row_name
    else:
        Table_row_category_dict[table_number]='NA'
        Table_row_demog_dict[table_number]='NA'
        Table_row_5w_dict[table_number]='NA'

# Creating Table Filter
prefix_filter={}

for Table_Number___ in Tables_to_be_checked_first_round:
    data_table_name = 'data_table_Table: '+str(Table_Number___)+str('_')
    data_2=Table_dict[data_table_name]
    filter_used=Filter_used[Table_Number___-1]

    Indent=data_2[['Row_Names','Indent']]
    Indent=data_2[['Row_Names','Indent']]
    Indent.columns=['table_row_name','indent_row_level']

    #Creating the Indent data to find the zero level indented rows for selection

    for i in range(0,len(Indent.index)):
        if (Indent['table_row_name'][i].find('%') != -1):
            Indent=Indent.drop(i)
        else:
            continue
    Indent=Indent.reset_index(drop=True) 

    counter=0

    for i in range(3,len(Indent.index)):
        if ('Total' in Indent['table_row_name'][i]):
            counter=i
            break        
        else:
            continue

    if counter!=0:
        for x in range(counter,len(Indent.index)):
            Indent=Indent.drop(x)
    Indent=Indent.reset_index(drop=True)

    Indent['table_row_name']=Indent['table_row_name'].map(Tool_name_map_dict).fillna(Indent['table_row_name']) 

    temp_row_value=filter_used
    
    metric_iid=0
    for x in range(0,len(Tool_name_map['Burke_Display_Name'])):
        if Tool_name_map['Burke_Display_Name'][x]==temp_row_value:
            metric_iid=Tool_name_map['MetricId'][x]
        else:
            continue        

    row_parent_name=''
    row_parent_id=0
    parent_list=[]

    for x in range(0,len(Mapping_for_row_info['Display_Name'])):
        if Mapping_for_row_info['MetricId'][x]==metric_iid:
            row_parent_name=Mapping_for_row_info['MetricParentName'][x]
            row_parent_id=Mapping_for_row_info['ParentId'][x]
        else:
            continue

    parent_list.append(row_parent_name)

    while(row_parent_id!=0):
        temp_id=Mapping_for_row_info['ParentId'][Mapping_for_row_info['MetricId']==row_parent_id].values[0]
        parent_list.append(Mapping_for_row_info['MetricParentName'][Mapping_for_row_info['ParentId']==temp_id].values[0])  
        row_parent_id=temp_id

    parent_list.remove(parent_list[len(parent_list)-1])

    Parent_prefix=''
    for x in range(0,len(parent_list)):
        if (x==len(parent_list)-1):
                    Parent_prefix=str('Row')+str('^')+Parent_prefix
                    Parent_prefix=parent_list[x]+str('^')+Parent_prefix
        else:
            Parent_prefix=parent_list[x]+str('^')+Parent_prefix  

    prefix_filter[Table_Number___]=Parent_prefix+filter_used

All_table_info=pd.DataFrame({'row_category':pd.Series(Table_row_category_dict),'row_demog':pd.Series(Table_row_demog_dict),
                             'row_5w':pd.Series(Table_row_5w_dict),'row_filter':pd.Series(prefix_filter)})

All_table_info.to_csv('All_table_round_1_new.csv')

All_table_all_row_info=pd.DataFrame({'row_syntax':pd.Series(row_parent_all_row),
                                     'row_parent_list':pd.Series(row_parent_list_all_row)})

All_table_all_row_info.to_csv('All_table_all_row_info.csv')

check_list_table=[2]

#generating the output files
Table_output_file_data_dict={}
for table_number in check_list_table:
    data_table_name = 'data_table_Table: '+str(table_number)+str('_')

    Test_table=Table_dict[data_table_name]

    id_vars =['Row_Names']
    value_vars =['Total', 'Early Morning Bite', 'Breakfast For One', 'Family Breakfast', 'Breakfast at Work/School', 
                 'Mid Morning Snack', 'Lunch', 'Lunch Alternative', 'Afternoon Snack','After Work/School Bite', 
                 'Dinner', 'Dinner Alternative', 'Evening Me', 'Evening We', 'Bedtime/Late Night Snack'] 
    var_name =['Occasions']

    Unweighted_base=Test_table[:1]
    Unweighted_base=Unweighted_base.melt(id_vars, value_vars, var_name)
    Unweighted_base_dict = dict(zip(Unweighted_base['Occasions'], Unweighted_base['value']))


    Weight_test_table=pd.DataFrame()
    percentage_table=pd.DataFrame()

#     Weight_test_table=Test_table[2:]
#     percentage_table=Test_table[2:]
    Weight_test_table=Test_table
    percentage_table=Test_table
    Weight_test_table=Weight_test_table.reset_index(drop=True)
    percentage_table=percentage_table.reset_index(drop=True)

    for i in range(0,len(Weight_test_table.index)):
        if (Weight_test_table['Row_Names'][i].find('%') != -1):
            Weight_test_table=Weight_test_table.drop(i)
        else:
            continue
    Weight_test_table=Weight_test_table.reset_index(drop=True)

    for i in range(0,len(percentage_table.index)):
        if (percentage_table['Row_Names'][i].find('%') == -1):
            percentage_table=percentage_table.drop(i)
        else:
            continue
    percentage_table=percentage_table.reset_index(drop=True) 

#     percentage_table=percentage_table.melt(id_vars,value_vars,var_name)

    for x in range(1,len(percentage_table.index)):
        row_name=percentage_table['Row_Names'][x]
        percentage_table['Row_Names'][x]=row_name[0:len(row_name)-1]   
        
        
    created_each_row_wt_table=pd.DataFrame()
    created_each_row_per_table=pd.DataFrame()
    
    for z in range(0,len(percentage_table.index)):
        created_each_row_per_table=percentage_table[z:z+1]
        created_each_row_wt_table=Weight_test_table[z:z+1]
        created_each_row_wt_table=created_each_row_wt_table.melt(id_vars , value_vars ,var_name)
        created_each_row_per_table=created_each_row_per_table.melt(id_vars , value_vars ,var_name)
        Table_output_1 = pd.merge(created_each_row_per_table, created_each_row_wt_table, how='left', 
                                  left_on=['Row_Names','Occasions'],right_on = ['Row_Names','Occasions'])
        table_key=str(table_number)+str('_')+str(z)
        Table_output_1['Row_Names']=Table_output_1['Row_Names'].map(Tool_name_map_dict).fillna(Table_output_1['Row_Names'])
        
        for x in range(0,len(Table_output_1.index)):
            if (Table_output_1['Row_Names'][x].find('Base ') != -1):
                Table_output_1['Row_Names'][x]='Base'
            else:
                continue

        Table_output_1['UNWEIGHTED']=Table_output_1['Occasions']
        Table_output_1['UNWEIGHTED']=Table_output_1.Occasions.map(Unweighted_base_dict)        
        Table_output_1.columns=['Distinct', 'Occasions', 'Percentage value', 'WEIGHTED', 'UNWEIGHTED']
        Table_output_1['Distinct']=Table_output_1['Distinct']+str('|')+Table_output_1['Occasions'] 
        Table_output_1=Table_output_1.drop(['Occasions'],axis=1)      
        Table_output_1['Test_case_number']=table_key
        Table_output_1=Table_output_1[['Test_case_number','Distinct', 'Percentage value', 'WEIGHTED', 'UNWEIGHTED']]
        
        Table_output_file_data_dict[table_key]=Table_output_1

Table_output_file_data_dict['2_4']

# index_1=Test_table.index[Test_table['Row_Names'] == percentage_table['Row_Names'][2]].tolist()

# Table_output_file_data_dict['2_2']

#Storing all the tables in a single dataframe
Output_table=pd.DataFrame()
for key in Table_output_file_data_dict.keys():
    Output_table=Output_table.append(Table_output_file_data_dict[key])

#Saving the table outputs in the appended format
Output_table.to_csv('Output_tables_row_wise_table_2.csv')

Output_table

Weight_test_table

percentage_table

row_parent_all_row.keys()

Test_table[2:]

Test_table

########################### Automation 5 ##################################################

import numpy as np 
import pandas as pd 
import openpyxl
from openpyxl import load_workbook

import warnings
warnings.filterwarnings("ignore")

file_path= "C:\\Users\\10920\\Desktop\\Automation\\Total Tables by Occasion - Q2 US.xlsx"
wb = load_workbook(file_path)

Indent_level_all= pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Indent_level_all.xlsx",
                                             sheet_name="Indent"))

Mapping_for_row_info= pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Mapping_for_row_info.xlsx",
                                             sheet_name="Master_Sheet"))

#Display name and tool name mapping Tool to Check 
Tool_name_map = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Tool to Check Table Mapping File 18_09_2019_1.xlsx",
                                             sheet_name="Sheet1"))

#Attribute id and the value for the rows of the selection
Attribute_name_map = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Sample Automation Test Cases with output 19_09_2019.xlsx",
                                             sheet_name="AttributeType"))

#Creating the tool display name and table name map
Tool_name_map_map=Tool_name_map[['Burke Display Name','Display Name']]
Tool_name_map_map.columns=['Burke_Display_Name','Display_Name']

Tool_name_map_map = Tool_name_map_map.dropna()
Tool_name_map_map=Tool_name_map_map.reset_index(drop=True)

Tool_name_map_dict = dict(zip(Tool_name_map_map['Burke_Display_Name'], Tool_name_map_map['Display_Name']))

# Tool_name_map_map=Tool_name_map[['Burke Display Name','MetricName']]
# Tool_name_map_map.columns=['Burke_Display_Name','MetricName']

# Tool_name_map_map = Tool_name_map_map.dropna()
# Tool_name_map_map=Tool_name_map_map.reset_index(drop=True)

# Tool_name_map_dict = dict(zip(Tool_name_map_map['Burke_Display_Name'], Tool_name_map_map['MetricName']))

Mapping_for_row_info.columns=['MetricId', 'MetricName', 'Display_Name', 'MetricParentName','ParentId', 'AttributetypeId']

list_tables=wb.sheetnames
list_tables.remove('Table of Contents')

#To store all the tables
Table_dict={}

# To find:: Table Name, Table header,Base, Filter
Table_Name_used=[]
Table_header=[]
Base_used=[]
Filter_used=[]

for table_number in list_tables:
    data=pd.DataFrame(wb[table_number].values)
#     print(data.shape)
    
    data['Indent']=Indent_level_all[table_number]
    
#     print(data.shape)
    

    Table_Name=data.loc[0][0]
    Table_Name_used.append(Table_Name)

#                 print('Table Name :  ', Table_Name)

    Table_Question=data.loc[1][0]
    Table_header.append(Table_Question)
#                 print('Table header :  ',Table_Question)

    Table_Question=Table_Question.splitlines()
    
    if len(Table_Question)>=3:
        Filter=Table_Question[len(Table_Question)-1]
    else:
        Filter="No Filter"

    Filter_used.append(Filter)
#                 print('Filter Used : ',Filter)

    data_index=data.index.tolist()
    data_column=len(data.columns)

    data_1=data

    for i in data_index:
        for j in range(0,data_column-1):
            if data_1.loc[i,j]=='Client Confidential':
                temp=i
            else:
                continue   
                
    temp,data.shape,data_1.shape

    for i in range(temp-2,len(data_index)):
                data_1=data_1.drop(i)

    data.shape,data_1.shape

    # data_1.head(10)

    for i in range(0,data_1.shape[0]):
        if data_1.iloc[i][1]=='Total':
            j=i
        else:
            continue

    for i in range(0,j):
        data_1=data_1.drop(i)

    data_1=data_1.reset_index(drop=True)
    # data_1

    for i in range(1,len(data_1.index)):
        if type(data_1.iloc[i,0])==type(None):
            data_1.iloc[i,0]=data_1.iloc[i-1,0] +str('%')
        else:
            continue

    # data_1.head(15)

    data_1[0][0]='Row_Names'
    data_1.columns=data_1.loc[0].tolist()
    data_1=data_1.rename(columns = {data_1.columns[len(data_1.columns)-1]:'Indent'})
   

    data_1=data_1.drop(0)
    data_1=data_1.reset_index(drop=True)
    # data_1

    for i in range(0,len(data_1.index)):
        temp=data_1['Row_Names'][i]
        
        if type(temp)==type(None):            
            continue 
        else:
            if (temp.find('Base ') != -1):
                where=i 
            else:
                continue    

    data_1['Row_Names']=data_1['Row_Names'].map(Tool_name_map_dict).fillna(data_1['Row_Names'])
    
    Base=''
    Base=data_1['Row_Names'][where]
    Base=Base.replace('Base - ','',1)

    Base_used.append(Base)
    
    data_table_name = 'data_table'+str('_')+str(Table_Question[0])+str('_')
    
       
    Table_dict[data_table_name]=data_1

# # Table Info
# for Table_Number___ in Tables_to_be_checked_first_round:
# #     print('Table_Name:"\n"',Table_Name_used[Table_Number___-1])
# #     print('Table_header:"\n"',Table_header[Table_Number___-1])
# #     print('Base_used:"\n"',Base_used[Table_Number___-1])
#     print('Filter_used:"\n"',Filter_used[Table_Number___-1])

Tables_to_be_checked_first_round=[2,3,4,6,8,10,11,12,13,40,41,42,43,44,45,46,47,48,49,50,51,108,109,110,111,112,114,115,
                                  116,117,119,120,121,122,124,125,126,127,129,130,131,132,134,135,136,137,139,140,141,142,
                                  144,145,146,147,149,150,151,152,154,155,156,157,159,160,161,162,164,165,166,167,169,170,
                                  171,172,174,175,176,177,179,180,181,182,184,185,186,187,189,190,191,192,195,197,199,200,
                                  201,202,203,204,205,206,207,212,213,215]

#To store all the syntax for tables
Table_row_category_dict={}
Table_row_demog_dict={}
Table_row_5w_dict={}
Table_row_syntax_dict={}
Table_row_parent_prefix_dict={}
Table_output_file_data_dict={}
file_path='C:\\Users\\10920\\Desktop\\Automation\\Output_tables\\Round_1\\'

for table_number in Tables_to_be_checked_first_round:
    data_table_name = 'data_table_Table: '+str(table_number)+str('_')

    data_2=Table_dict[data_table_name]

    Indent=data_2[['Row_Names','Indent']]

    Indent=data_2[['Row_Names','Indent']]
    Indent.columns=['table_row_name','indent_row_level']

#Creating the Indent data to find the zero level indented rows for selection

    for i in range(0,len(Indent.index)):
        if (Indent['table_row_name'][i].find('%') != -1):
            Indent=Indent.drop(i)
        else:
            continue
    Indent=Indent.reset_index(drop=True) 

    counter=0

    for i in range(3,len(Indent.index)):
        if ('Total' in Indent['table_row_name'][i]):
            counter=i
            break        
        else:
            continue

    if counter!=0:
        for x in range(counter,len(Indent.index)):
            Indent=Indent.drop(x)
    Indent=Indent.reset_index(drop=True)

    Indent['table_row_name']=Indent['table_row_name'].map(Tool_name_map_dict).fillna(Indent['table_row_name'])

#Finding the row selection for 0 level Indent
    indent_selection_all =pd.DataFrame(columns=['table','syntax' ])

    key=0
    temp_0="Junk"

    for x in range(2,len(Indent.index)):    

        if Indent['indent_row_level'][x]==1:
            indent_selection_all.loc[key,'table']='table_number'
            indent_selection_all.loc[key,'syntax']=temp_0        
            key += 1
            temp_0=Indent['table_row_name'][x]
            temp_0 = temp_0+str('|')       

        else:
            continue

    indent_selection_all.loc[key,'table']='table_number'
    indent_selection_all.loc[key,'syntax']=temp_0 


    row_level_syntax=''
    row_level_syntax_1=''

    for x in indent_selection_all['syntax']:
        row_level_syntax=x
        row_level_syntax_1=row_level_syntax_1+row_level_syntax 

    row_level_syntax_1=row_level_syntax_1.replace('Junk','')

    row_level_syntax_1=row_level_syntax_1[0:len(row_level_syntax_1)-1]
    Table_row_syntax_dict[table_number]=row_level_syntax_1

# Finding the parent prefix

    for x in range(2,len(Indent.index)):   
        temp_row_value=''     
        if Indent['indent_row_level'][x]==1:
            temp_row_value=Indent['table_row_name'][x]
            break
        else:
            continue       

    row_parent_name=''
    row_parent_id=0
    parent_list=[]

    for x in range(0,len(Mapping_for_row_info['Display_Name'])):
        if Mapping_for_row_info['Display_Name'][x]==temp_row_value:
            row_parent_name=Mapping_for_row_info['MetricParentName'][x]
            row_parent_id=Mapping_for_row_info['ParentId'][x]
        else:
            continue

    parent_list.append(row_parent_name)
    

    while(row_parent_id!=0):
        temp_id=Mapping_for_row_info['ParentId'][Mapping_for_row_info['MetricId']==row_parent_id].values[0]
        parent_list.append(Mapping_for_row_info['MetricParentName'][Mapping_for_row_info['ParentId']==temp_id].values[0])  
        row_parent_id=temp_id

    parent_list.remove(parent_list[len(parent_list)-1])
    
    parent_length=len(parent_list)    

    Parent_prefix=''
    for x in range(0,len(parent_list)):
        if (x==len(parent_list)-1):
                    Parent_prefix=str('Row')+str('^')+Parent_prefix
                    Parent_prefix=parent_list[x]+str('^')+Parent_prefix
        else:
            Parent_prefix=parent_list[x]+str('^')+Parent_prefix  
    
    Table_row_parent_prefix_dict[table_number]=Parent_prefix
    

# Finding the Row for the selection
    temp_1_row_value='' 
    for x in range(4,len(Indent.index)):
        if Indent['indent_row_level'][x]==1:
            temp_1_row_value=Indent['table_row_name'][x]
            break
        else:
            continue   


    for x in range(0,len(Mapping_for_row_info.index)):
        if Mapping_for_row_info['Display_Name'][x]==temp_1_row_value:
            attribute_id=Mapping_for_row_info['AttributetypeId'][x]
        else:
            continue   


    Row_name_list=[]
    Row_name=''

    if attribute_id in [38,39,40]:
        Row_name_list=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_id]['AttributeType']        
        Row_name=Row_name_list[Row_name_list.index[0]]
    else:
        if len(parent_list)!=0:
            Row_name=parent_list[len(parent_list)-1]
    
    if Row_name=='Category/Brand/Item' or Row_name=='Item' or Row_name=='Brand' or Row_name=='Category':
        Table_row_category_dict[table_number]=Row_name
    elif Row_name=='Demographics':
        Table_row_demog_dict[table_number]=Row_name
    elif Row_name=='5Ws':
        Table_row_5w_dict[table_number]=Row_name
    else:
        Table_row_category_dict[table_number]='NA'
        Table_row_demog_dict[table_number]='NA'
        Table_row_5w_dict[table_number]='NA'
    

    # # Finding the Row Nesting value for the selection
    #     # Finding the parent list

    # temp_2_row_value='' 
    # for x in range(2,len(Indent.index)):
    #     if Indent['indent_row_level'][x]==1:
    #         temp_2_row_value=Indent['table_row_name'][x]
    #         break
    #     else:
    #         continue   

    # temp_2_row_value

    # row_parent_name_nest=''
    # row_parent_nest_id=0
    # parent__nest_list=[]

    # for x in range(0,len(Mapping_for_row_info['Display_Name'])):
    #     if Mapping_for_row_info['Display_Name'][x]==temp_2_row_value:
    #         row_parent_name_nest=Mapping_for_row_info['MetricParentName'][x]
    #         row_parent_nest_id=Mapping_for_row_info['ParentId'][x]
    #     else:
    #         continue

    # parent__nest_list.append(row_parent_name_nest)

    # while(row_parent_nest_id!=0):
    #     temp_id=Mapping_for_row_info['ParentId'][Mapping_for_row_info['MetricId']==row_parent_nest_id].values[0]
    #     parent__nest_list.append(Mapping_for_row_info['MetricParentName'][Mapping_for_row_info['ParentId']==temp_id].values[0])
    #     row_parent_nest_id=temp_id

    # parent__nest_list.remove(parent__nest_list[len(parent__nest_list)-1])


    # for x in range(0,len(Mapping_for_row_info.index)):
    #     if Mapping_for_row_info['Display_Name'][x]==temp_2_row_value:
    #         attribute_id_1=Mapping_for_row_info['AttributetypeId'][x]
    #     else:
    #         continue   


    # Row_nest_list=[]
    # Row_nest_name=''

    # if attribute_id in [38,39,40]:
    #     Row_nest_list=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_id_1]['AttributeType']
    #     Row_nest_name=Row_nest_list[Row_nest_list.index[0]]
    # else:
    #     if len(parent__nest_list)!=0:
    #         Row_nest_name=parent__nest_list[len(parent__nest_list)-1]
    #     else:
    #         Row_nest_name='NA'  

#generating the output files
    data_for_output_result=data_2    

    for i in range(4,len(data_for_output_result.index)):
        if ('Total' in data_for_output_result['Row_Names'][i]):
            data_for_output_result=data_for_output_result.drop(i)                    
        else:
            continue    
    data_for_output_result=data_for_output_result.reset_index(drop=True)
    
    
    
    for x in range(4,len(data_2.index)):
        if data_2['Indent'][x]!=1:
            if(x>=len(data_2.index)):
                data_for_output_result=data_for_output_result.drop(x)
        else:
            continue

    data_for_output_result=data_for_output_result.reset_index(drop=True)
    
    for x in range(4,len(data_for_output_result.index)):
        if (data_for_output_result['Row_Names'][x].find('%') != -1):
            continue
        else:
            data_for_output_result=data_for_output_result.drop(x)

    data_for_output_result=data_for_output_result.reset_index(drop=True)
    
    Unweighted_base=data_for_output_result[:1]

    Unweighted_base=Unweighted_base.melt(id_vars =['Row_Names'], value_vars =['Total', 'Early Morning Bite', 
                                                     'Breakfast For One','Family Breakfast', 
                                                     'Breakfast @ Work / School', 'Mid Morning Snack','Lunch', 
                                                     'Lunch Alternative', 'Afternoon Snack','After Work / School Bite', 
                                                     'Dinner', 'Dinner Alternative','Evening Me', 'Evening We',
                                                     'Bedtime / Late Night Snack'],var_name ='Occasions')

    Weighted_base_nummber=data_for_output_result[2:3]

    Weighted_base_nummber=Weighted_base_nummber.melt(id_vars =['Row_Names'], value_vars =['Total', 'Early Morning Bite', 
                                                     'Breakfast For One','Family Breakfast', 
                                                     'Breakfast @ Work / School', 'Mid Morning Snack','Lunch', 
                                                     'Lunch Alternative', 'Afternoon Snack','After Work / School Bite', 
                                                     'Dinner', 'Dinner Alternative','Evening Me', 'Evening We',
                                                     'Bedtime / Late Night Snack'],var_name ='Occasions')

    Weighted_base_percentage=data_for_output_result[3:4]

    Weighted_base_percentage=Weighted_base_percentage.melt(id_vars =['Row_Names'], value_vars =['Total', 'Early Morning Bite', 
                                                     'Breakfast For One','Family Breakfast', 
                                                     'Breakfast @ Work / School', 'Mid Morning Snack','Lunch', 
                                                     'Lunch Alternative', 'Afternoon Snack','After Work / School Bite', 
                                                     'Dinner', 'Dinner Alternative','Evening Me', 'Evening We',
                                                     'Bedtime / Late Night Snack'],var_name ='Occasions')

    rest_of_table=data_for_output_result[4:].melt(id_vars =['Row_Names'], value_vars =['Total', 'Early Morning Bite', 
                                                     'Breakfast For One','Family Breakfast', 
                                                     'Breakfast @ Work / School', 'Mid Morning Snack','Lunch', 
                                                     'Lunch Alternative', 'Afternoon Snack','After Work / School Bite', 
                                                     'Dinner', 'Dinner Alternative','Evening Me', 'Evening We',
                                                     'Bedtime / Late Night Snack'],var_name ='Occasions')

    Unweighted_base_dict = dict(zip(Unweighted_base['Occasions'], Unweighted_base['value']))
    Weighted_base_nummber_dict = dict(zip(Weighted_base_nummber['Occasions'], Weighted_base_nummber['value']))

    rest_of_table['Unweighted_base']=rest_of_table['Occasions']
    rest_of_table['Unweighted_base']=rest_of_table.Occasions.map(Unweighted_base_dict)

    rest_of_table['Weighted_base']=rest_of_table['Occasions']
    rest_of_table['Weighted_base']=rest_of_table.Occasions.map(Weighted_base_nummber_dict)
    rest_of_table

    # Weighted_base_percentage
    Weighted_base_percentage['Unweighted_base']=Weighted_base_percentage['Occasions']
    Weighted_base_percentage['Unweighted_base']=Weighted_base_percentage.Occasions.map(Unweighted_base_dict)

    Weighted_base_percentage['Weighted_base']=Weighted_base_percentage['Occasions']
    Weighted_base_percentage['Weighted_base']=Weighted_base_percentage.Occasions.map(Weighted_base_nummber_dict)

    Table_output=Weighted_base_percentage.append(rest_of_table)

    Table_output=Table_output.reset_index(drop=True)

    uper_level_name=[]
    y=''
    for x in Table_output['Row_Names']:
        y=find_prefix(x,data_2)
        uper_level_name.append(y)

    Table_output['New_Row_Names']=uper_level_name

    for x in range(0,len(Table_output.index)):    
        if (Table_output['New_Row_Names'][x].find('Base ') != -1):
            Table_output['New_Row_Names'][x]='Base'
        else:
            continue

    for x in range(0,len(Table_output.index)):    
        if (Table_output['New_Row_Names'][x].find('%') != -1):
            Table_output['New_Row_Names'][x]=Table_output['New_Row_Names'][x].replace('%','')
        else:
            continue
            
    Table_output['New_Row_Names']=Table_output['New_Row_Names'].map(Tool_name_map_dict).fillna(Table_output['New_Row_Names'])

    Table_output['New_Row_Names']=Table_output['New_Row_Names']+str('|')+Table_output['Occasions']

    Table_output_final=Table_output[['New_Row_Names','value', 'Weighted_base', 'Unweighted_base']]
    Table_output_final.columns=['Distinct','Percentage_value','WEIGHTED_Base','UNWEIGHTED_Base']
    Table_output_final['Test_Case_number']=table_number    

    
    Table_output_file_data_dict[table_number]=Table_output_final
    
#     data_table_name_table=str('Table')+str(table_number)+str('.csv')
#     Table_output_final.to_csv(file_path+data_table_name_table,index=False)

Table_output_file_data_dict[49]

def find_prefix(name,data_2):
    indent_for_value=0
    return_value=''
    return_value_1=[]
    return_value_2=''    
    for x in range(0, len(data_2.index)):
        if data_2['Row_Names'][x]==name:
            indent_for_value=data_2['Indent'][x]
            if indent_for_value==0:
                return_value=name
            elif indent_for_value==1:
                for i in range(x,-1,-1):
                    if data_2['Indent'][i]==0:
                        return_value=data_2['Row_Names'][i]
                        break
                    else:
                        continue
            elif indent_for_value==2:
                for i in range(x,-1,-1):
                    if data_2['Indent'][i]==2:
                        continue                        
                    elif data_2['Indent'][i]==1:
                        return_value_1.append(data_2['Row_Names'][i])                        
                    elif data_2['Indent'][i]==0:
                        return_value_2=data_2['Row_Names'][i]
                        break
                    else:
                        continue
                return_value=return_value_2+str('|')+return_value_1[0]
    return return_value

# Creating Table Filter
prefix_filter={}

for Table_Number___ in Tables_to_be_checked_first_round:
    data_table_name = 'data_table_Table: '+str(Table_Number___)+str('_')
    data_2=Table_dict[data_table_name]
    filter_used=Filter_used[Table_Number___-1]

    Indent=data_2[['Row_Names','Indent']]
    Indent=data_2[['Row_Names','Indent']]
    Indent.columns=['table_row_name','indent_row_level']

    #Creating the Indent data to find the zero level indented rows for selection

    for i in range(0,len(Indent.index)):
        if (Indent['table_row_name'][i].find('%') != -1):
            Indent=Indent.drop(i)
        else:
            continue
    Indent=Indent.reset_index(drop=True) 

    counter=0

    for i in range(3,len(Indent.index)):
        if ('Total' in Indent['table_row_name'][i]):
            counter=i
            break        
        else:
            continue

    if counter!=0:
        for x in range(counter,len(Indent.index)):
            Indent=Indent.drop(x)
    Indent=Indent.reset_index(drop=True)

    Indent['table_row_name']=Indent['table_row_name'].map(Tool_name_map_dict).fillna(Indent['table_row_name']) 

    temp_row_value=filter_used        

    row_parent_name=''
    row_parent_id=0
    parent_list=[]

    for x in range(0,len(Mapping_for_row_info['Display_Name'])):
        if Mapping_for_row_info['Display_Name'][x]==temp_row_value:
            row_parent_name=Mapping_for_row_info['MetricParentName'][x]
            row_parent_id=Mapping_for_row_info['ParentId'][x]
        else:
            continue

    parent_list.append(row_parent_name)

    while(row_parent_id!=0):
        temp_id=Mapping_for_row_info['ParentId'][Mapping_for_row_info['MetricId']==row_parent_id].values[0]
        parent_list.append(Mapping_for_row_info['MetricParentName'][Mapping_for_row_info['ParentId']==temp_id].values[0])  
        row_parent_id=temp_id

    parent_list.remove(parent_list[len(parent_list)-1])

    Parent_prefix=''
    for x in range(0,len(parent_list)):
        if (x==len(parent_list)-1):
                    Parent_prefix=str('Row')+str('^')+Parent_prefix
                    Parent_prefix=parent_list[x]+str('^')+Parent_prefix
        else:
            Parent_prefix=parent_list[x]+str('^')+Parent_prefix  

    prefix_filter[Table_Number___]=Parent_prefix+filter_used

All_table_info=pd.DataFrame({'row_category':pd.Series(Table_row_category_dict),'row_demog':pd.Series(Table_row_demog_dict),
                             'row_5w':pd.Series(Table_row_5w_dict),'row_syntax':pd.Series(Table_row_syntax_dict),
                             'row_parent':pd.Series(Table_row_parent_prefix_dict),'row_filter':pd.Series(prefix_filter)})

All_table_info.to_csv('All_table_info_round_1_ind_1.csv')

test_table=49
data_table_name = 'data_table_Table: '+str(test_table)+str('_')

test_table_data=Table_dict[data_table_name]

test_table_data

data_2=test_table_data

Indent=data_2[['Row_Names','Indent']]

Indent=data_2[['Row_Names','Indent']]
Indent.columns=['table_row_name','indent_row_level']

#Creating the Indent data to find the zero level indented rows for selection

for i in range(0,len(Indent.index)):
    if (Indent['table_row_name'][i].find('%') != -1):
        Indent=Indent.drop(i)
    else:
        continue
Indent=Indent.reset_index(drop=True) 

counter=0

for i in range(3,len(Indent.index)):
    if ('Total' in Indent['table_row_name'][i]):
        counter=i
        break        
    else:
        continue

if counter!=0:
    for x in range(counter,len(Indent.index)):
        Indent=Indent.drop(x)
Indent=Indent.reset_index(drop=True)

Indent['table_row_name']=Indent['table_row_name'].map(Tool_name_map_dict).fillna(Indent['table_row_name'])

#Finding the row selection for 0 level Indent
indent_selection_all =pd.DataFrame(columns=['table','syntax' ])

key=0
temp_0="Junk"

for x in range(2,len(Indent.index)):    

    if Indent['indent_row_level'][x]==1:
        indent_selection_all.loc[key,'table']='table_number'
        indent_selection_all.loc[key,'syntax']=temp_0        
        key += 1
        temp_0=Indent['table_row_name'][x]
        temp_0 = temp_0+str('|')       

    else:
        continue

indent_selection_all.loc[key,'table']='table_number'
indent_selection_all.loc[key,'syntax']=temp_0 


row_level_syntax=''
row_level_syntax_1=''

for x in indent_selection_all['syntax']:
    row_level_syntax=x
    row_level_syntax_1=row_level_syntax_1+row_level_syntax 

row_level_syntax_1=row_level_syntax_1.replace('Junk','')

row_level_syntax_1=row_level_syntax_1[0:len(row_level_syntax_1)-1]
# Table_row_syntax_dict[table_number]=row_level_syntax_1

# Finding the parent prefix

for x in range(2,len(Indent.index)):   
    temp_row_value=''     
    if Indent['indent_row_level'][x]==1:
        temp_row_value=Indent['table_row_name'][x]
        break
    else:
        continue       

row_parent_name=''
row_parent_id=0
parent_list=[]

for x in range(0,len(Mapping_for_row_info['Display_Name'])):
    if Mapping_for_row_info['Display_Name'][x]==temp_row_value:
        row_parent_name=Mapping_for_row_info['MetricParentName'][x]
        row_parent_id=Mapping_for_row_info['ParentId'][x]
    else:
        continue

parent_list.append(row_parent_name)

while(row_parent_id!=0):
    temp_id=Mapping_for_row_info['ParentId'][Mapping_for_row_info['MetricId']==row_parent_id].values[0]
    parent_list.append(Mapping_for_row_info['MetricParentName'][Mapping_for_row_info['ParentId']==temp_id].values[0])  
    row_parent_id=temp_id

parent_list.remove(parent_list[len(parent_list)-1])

Parent_prefix=''
for x in range(0,len(parent_list)):
    if (x==len(parent_list)-1):
                Parent_prefix=str('Row')+str('^')+Parent_prefix
                Parent_prefix=parent_list[x]+str('^')+Parent_prefix
    else:
        Parent_prefix=parent_list[x]+str('^')+Parent_prefix  

# Table_row_parent_prefix_dict[table_number]=Parent_prefix

# row_parent_id
# len(Mapping_for_row_info['Display_Name'])
# temp_row_value
parent_list,Parent_prefix

for x in range(0,len(Mapping_for_row_info['Display_Name'])):
    if Mapping_for_row_info['Display_Name'][x]==temp_row_value:
#         row_parent_name=Mapping_for_row_info['MetricParentName'][x]
#         row_parent_id=Mapping_for_row_info['ParentId'][x]
          print(temp_row_value)
    else:
        continue

# parent_list.append(row_parent_name)


# Finding the Row for the selection
temp_1_row_value='' 
for x in range(4,len(Indent.index)):
    if Indent['indent_row_level'][x]==1:
        temp_1_row_value=Indent['table_row_name'][x]
        break
    else:
        continue   

temp_1_row_value

for x in range(0,len(Mapping_for_row_info.index)):
    if Mapping_for_row_info['Display_Name'][x]==temp_1_row_value:
        attribute_id=Mapping_for_row_info['AttributetypeId'][x]
    else:
        continue   


Row_name_list=[]
Row_name=''

if attribute_id in [38,39,40]:
    Row_name_list=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_id]['AttributeType']        
    Row_name=Row_name_list[Row_name_list.index[0]]
else:
    if len(parent_list)!=0:
        Row_name=parent_list[len(parent_list)-1]

if Row_name=='Category/Brand/Item' or Row_name=='Item' or Row_name=='Brand' or Row_name=='Category':
    Table_row_category_dict[table_number]=Row_name
elif Row_name=='Demographics':
    Table_row_demog_dict[table_number]=Row_name
elif Row_name=='5Ws':
    Table_row_5w_dict[table_number]=Row_name
else:
    Table_row_category_dict[table_number]='NA'
    Table_row_demog_dict[table_number]='NA'
    Table_row_5w_dict[table_number]='NA'

# Midnight to just before 6:00 AM
    
Table_Number___=43    
data_table_name_1 = 'data_table_Table: '+str(Table_Number___)+str('_')
data_test=Table_dict[data_table_name]
find_prefix('Midnight to just before 6:00 AM',data_test)

# prefix_filter[49]
Row_name

parent_list

Filter_used[13]

Output_table=pd.DataFrame()
for key in Table_output_file_data_dict.keys():
    Output_table=Output_table.append(Table_output_file_data_dict[key])

# Output_table.shape
attribute_id

Output_table.to_csv('Output_table_indent_1.csv')

Table_dict['data_table_Table: 1_']

len(Filter_used),len(Table_dict)

# Filter_used[]

########################### Automation 6 #########################################

import numpy as np 
import pandas as pd 
import openpyxl
from openpyxl import load_workbook

import warnings
warnings.filterwarnings("ignore")

file_path= "C:\\Users\\10920\\Desktop\\Automation\\Total Tables by Occasion - Q2 US.xlsx"
wb = load_workbook(file_path)

Indent_level_all= pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Indent_level_all.xlsx",
                                             sheet_name="Indent"))

Mapping_for_row_info= pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Mapping_for_row_info.xlsx",
                                             sheet_name="Master_Sheet"))

#Display name and tool name mapping Tool to Check 
Tool_name_map = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Tool to Check Table Mapping File 18_09_2019_1.xlsx",
                                             sheet_name="Sheet1"))

#Attribute id and the value for the rows of the selection
Attribute_name_map = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Sample Automation Test Cases with output 19_09_2019.xlsx",
                                             sheet_name="AttributeType"))

#Creating the tool display name and table name map
Tool_name_map_map=Tool_name_map[['Burke Display Name','Display Name']]
Tool_name_map_map.columns=['Burke_Display_Name','Display_Name']

Tool_name_map_map = Tool_name_map_map.dropna()
Tool_name_map_map=Tool_name_map_map.reset_index(drop=True)

Tool_name_map_dict = dict(zip(Tool_name_map_map['Burke_Display_Name'], Tool_name_map_map['Display_Name']))

list_tables=wb.sheetnames
list_tables.remove('Table of Contents')

#To store all the tables
Table_dict={}

# To find:: Table Name, Table header,Base, Filter
Table_Name_used=[]
Table_header=[]
Base_used=[]
Filter_used=[]

for table_number in list_tables:
    data=pd.DataFrame(wb[table_number].values)
#     print(data.shape)
    
    data['Indent']=Indent_level_all[table_number]
    
#     print(data.shape)
    

    Table_Name=data.loc[0][0]
    Table_Name_used.append(Table_Name)

#                 print('Table Name :  ', Table_Name)

    Table_Question=data.loc[1][0]
    Table_header.append(Table_Question)
#                 print('Table header :  ',Table_Question)

    Table_Question=Table_Question.splitlines()
    
    if len(Table_Question)>=3:
        Filter=Table_Question[len(Table_Question)-1]
    else:
        Filter="No Filter"

    Filter_used.append(Filter)
#                 print('Filter Used : ',Filter)

    data_index=data.index.tolist()
    data_column=len(data.columns)

    data_1=data

    for i in data_index:
        for j in range(0,data_column-1):
            if data_1.loc[i,j]=='Client Confidential':
                temp=i
            else:
                continue   
                
    temp,data.shape,data_1.shape

    for i in range(temp-2,len(data_index)):
                data_1=data_1.drop(i)

    data.shape,data_1.shape

    # data_1.head(10)

    for i in range(0,data_1.shape[0]):
        if data_1.iloc[i][1]=='Total':
            j=i
        else:
            continue

    for i in range(0,j):
        data_1=data_1.drop(i)

    data_1=data_1.reset_index(drop=True)
    # data_1

    for i in range(1,len(data_1.index)):
        if type(data_1.iloc[i,0])==type(None):
            data_1.iloc[i,0]=data_1.iloc[i-1,0] +str('%')
        else:
            continue

    # data_1.head(15)

    data_1[0][0]='Row_Names'
    data_1.columns=data_1.loc[0].tolist()
    data_1=data_1.rename(columns = {data_1.columns[len(data_1.columns)-1]:'Indent'})
   

    data_1=data_1.drop(0)
    data_1=data_1.reset_index(drop=True)
    # data_1

    for i in range(0,len(data_1.index)):
        temp=data_1['Row_Names'][i]
        
        if type(temp)==type(None):            
            continue 
        else:
            if (temp.find('Base ') != -1):
                where=i 
            else:
                continue    

    Base=''
    Base=data_1['Row_Names'][where]
    Base=Base.replace('Base - ','',1)

    Base_used.append(Base)
    
    data_table_name = 'data_table'+str('_')+str(Table_Question[0])+str('_')
    
       
    Table_dict[data_table_name]=data_1

data_2=Table_dict['data_table_Table: 597_']

# data_2
# Tool_name_map_dict

Indent=data_2[['Row_Names','Indent']]

Indent=data_2[['Row_Names','Indent']]
Indent.columns=['table_row_name','indent_row_level']

#To find the zero level indented rows for selection

for i in range(0,len(Indent.index)):
    if (Indent['table_row_name'][i].find('%') != -1):
        Indent=Indent.drop(i)
    else:
        continue
Indent=Indent.reset_index(drop=True) 

counter=0

for i in range(3,len(Indent.index)):
    if ('Total' in Indent['table_row_name'][i]):
        counter=i
        break        
    else:
        continue

if counter!=0:
    for x in range(counter,len(Indent.index)):
        Indent=Indent.drop(x)
Indent=Indent.reset_index(drop=True)

# Indent['table_row_name']=Indent.table_row_name.map(Tool_name_map_dict)

# Indent

for x in range(0,len(Indent['table_row_name'])):
    if Indent['table_row_name'][x] in Tool_name_map_dict.keys():
        Indent['table_row_name'][x]=Indent['table_row_name'][x].map(Tool_name_map_dict)
    else:
        continue


indent_selection_all =pd.DataFrame(columns=['table','syntax' ])


key=0
temp_0="Junk"

for x in range(2,len(Indent.index)):    
    
    if Indent['indent_row_level'][x]==0:
        indent_selection_all.loc[key,'table']='table_number'
        indent_selection_all.loc[key,'syntax']=temp_0        
        key += 1
        temp_0=Indent['table_row_name'][x]
        temp_0 = temp_0+str('|')       
    
    else:
        continue

indent_selection_all.loc[key,'table']='table_number'
indent_selection_all.loc[key,'syntax']=temp_0 
        
        
row_level_syntax=''
row_level_syntax_1=''

for x in indent_selection_all['syntax']:
    row_level_syntax=x
    row_level_syntax_1=row_level_syntax_1+row_level_syntax 
#      print(x)

row_level_syntax_1=row_level_syntax_1.replace('Junk','')

row_level_syntax_1=row_level_syntax_1[0:len(row_level_syntax_1)-1]
row_level_syntax_1

indent_selection =pd.DataFrame(columns=['table','syntax' ])

key=0
temp_0="Junk"

for x in range(2,len(Indent.index)):    
    
    if Indent['indent_row_level'][x]==0:
        indent_selection.loc[key,'table']='table_number'
        indent_selection.loc[key,'syntax']=temp_0        
        key += 1
        temp_0=Indent['table_row_name'][x]
        temp_0 = temp_0+str('^')
        
    elif Indent['indent_row_level'][x]==1:        
        
        temp_0 = temp_0+Indent['table_row_name'][x]+str('^')
            
    elif Indent['indent_row_level'][x]==2: 
        temp_0 = temp_0+Indent['table_row_name'][x]+str('|')
    else:
        continue
        
indent_selection.loc[key,'table']='table_number'
indent_selection.loc[key,'syntax']=temp_0 

row_nest_syntax=''
row_nest_syntax_1=''

for x in indent_selection['syntax']:
    
    row_nest_syntax=x[0:len(x)-1]
    row_nest_syntax_1=row_nest_syntax_1+row_nest_syntax+str('^') 
#      print(x)

row_nest_syntax_1=row_nest_syntax_1.replace('Jun','')
row_nest_syntax_1=row_nest_syntax_1[0:len(row_nest_syntax_1)-1]
row_nest_syntax_1=row_nest_syntax_1[1:len(row_nest_syntax_1)+1]
row_nest_syntax_1

Mapping_for_row_info.columns=['MetricId', 'MetricName', 'Display_Name', 'MetricParentName','ParentId', 'AttributetypeId']

# Finding the parent prefix

for x in range(2,len(Indent.index)):   
    temp_row_value=''     
    if Indent['indent_row_level'][x]==0:
        temp_row_value=Indent['table_row_name'][x]
        break
    else:
        continue       

# temp_row_value='Employment Status'

row_parent_name=''
row_parent_id=0
parent_list=[]

for x in range(0,len(Mapping_for_row_info['Display_Name'])):
    if Mapping_for_row_info['Display_Name'][x]==temp_row_value:
        row_parent_name=Mapping_for_row_info['MetricParentName'][x]
        row_parent_id=Mapping_for_row_info['ParentId'][x]
    else:
        continue

parent_list.append(row_parent_name)

while(row_parent_id!=0):
    temp_id=Mapping_for_row_info['ParentId'][Mapping_for_row_info['MetricId']==row_parent_id].values[0]
    parent_list.append(Mapping_for_row_info['MetricParentName'][Mapping_for_row_info['ParentId']==temp_id].values[0])    
    row_parent_id=temp_id

parent_list.remove(parent_list[len(parent_list)-1])
# parent_list

Parent_prefix=''
for x in range(0,len(parent_list)):
    if (x==len(parent_list)-1):
                Parent_prefix=str('Row')+str('^')+Parent_prefix
                Parent_prefix=parent_list[x]+str('^')+Parent_prefix
    else:
        Parent_prefix=parent_list[x]+str('^')+Parent_prefix  

# parent_list
temp_row_value

# Finding the Row for the selection
temp_1_row_value='' 
for x in range(4,len(Indent.index)):
    if Indent['indent_row_level'][x]==0:
        temp_1_row_value=Indent['table_row_name'][x]
        break
    else:
        continue   

temp_1_row_value

for x in range(0,len(Mapping_for_row_info.index)):
    if Mapping_for_row_info['Display_Name'][x]==temp_1_row_value:
        attribute_id=Mapping_for_row_info['AttributetypeId'][x]
    else:
        continue   

        
Row_name_list=[]
Row_name=''

if attribute_id in [38,39,40]:
    Row_name_list=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_id]['AttributeType']
    Row_name=Row_name_list[Row_name_list.index[0]]
else:
    if len(parent_list)!=0:
        Row_name=parent_list[len(parent_list)-1]

print(Row_name)

# Finding the Row Nesting value for the selection
    # Finding the parent list

temp_2_row_value='' 
for x in range(2,len(Indent.index)):
    if Indent['indent_row_level'][x]==1:
        temp_2_row_value=Indent['table_row_name'][x]
        break
    else:
        continue   
        
temp_2_row_value

row_parent_name_nest=''
row_parent_nest_id=0
parent__nest_list=[]

for x in range(0,len(Mapping_for_row_info['Display_Name'])):
    if Mapping_for_row_info['Display_Name'][x]==temp_2_row_value:
        row_parent_name_nest=Mapping_for_row_info['MetricParentName'][x]
        row_parent_nest_id=Mapping_for_row_info['ParentId'][x]
    else:
        continue

parent__nest_list.append(row_parent_name_nest)

while(row_parent_nest_id!=0):
    temp_id=Mapping_for_row_info['ParentId'][Mapping_for_row_info['MetricId']==row_parent_nest_id].values[0]
    parent__nest_list.append(Mapping_for_row_info['MetricParentName'][Mapping_for_row_info['ParentId']==temp_id].values[0])
    row_parent_nest_id=temp_id

parent__nest_list.remove(parent__nest_list[len(parent__nest_list)-1])


for x in range(0,len(Mapping_for_row_info.index)):
    if Mapping_for_row_info['Display_Name'][x]==temp_2_row_value:
        attribute_id_1=Mapping_for_row_info['AttributetypeId'][x]
    else:
        continue   

        
Row_nest_list=[]
Row_nest_name=''

if attribute_id in [38,39,40]:
    Row_nest_list=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_id_1]['AttributeType']
    Row_nest_name=Row_nest_list[Row_nest_list.index[0]]
else:
    if len(parent__nest_list)!=0:
        Row_nest_name=parent__nest_list[len(parent__nest_list)-1]

# temp_2_row_value
Row_nest_name

#generating the output files
data_for_output_result=data_2

for x in range(4,len(data_for_output_result.index)):
    if (data_for_output_result['Row_Names'][x].find('%') != -1):
        continue
    else:
        data_for_output_result=data_for_output_result.drop(x)

Unweighted_base=data_for_output_result[:1]

Unweighted_base=Unweighted_base.melt(id_vars =['Row_Names'], value_vars =['Total', 'Early Morning Bite', 
                                                 'Breakfast For One','Family Breakfast', 
                                                 'Breakfast @ Work / School', 'Mid Morning Snack','Lunch', 
                                                 'Lunch Alternative', 'Afternoon Snack','After Work / School Bite', 
                                                 'Dinner', 'Dinner Alternative','Evening Me', 'Evening We',
                                                 'Bedtime / Late Night Snack'],var_name ='Occasions')

Weighted_base_nummber=data_for_output_result[2:3]

Weighted_base_nummber=Weighted_base_nummber.melt(id_vars =['Row_Names'], value_vars =['Total', 'Early Morning Bite', 
                                                 'Breakfast For One','Family Breakfast', 
                                                 'Breakfast @ Work / School', 'Mid Morning Snack','Lunch', 
                                                 'Lunch Alternative', 'Afternoon Snack','After Work / School Bite', 
                                                 'Dinner', 'Dinner Alternative','Evening Me', 'Evening We',
                                                 'Bedtime / Late Night Snack'],var_name ='Occasions')

Weighted_base_percentage=data_for_output_result[3:4]

Weighted_base_percentage=Weighted_base_percentage.melt(id_vars =['Row_Names'], value_vars =['Total', 'Early Morning Bite', 
                                                 'Breakfast For One','Family Breakfast', 
                                                 'Breakfast @ Work / School', 'Mid Morning Snack','Lunch', 
                                                 'Lunch Alternative', 'Afternoon Snack','After Work / School Bite', 
                                                 'Dinner', 'Dinner Alternative','Evening Me', 'Evening We',
                                                 'Bedtime / Late Night Snack'],var_name ='Occasions')

rest_of_table=data_for_output_result[4:].melt(id_vars =['Row_Names'], value_vars =['Total', 'Early Morning Bite', 
                                                 'Breakfast For One','Family Breakfast', 
                                                 'Breakfast @ Work / School', 'Mid Morning Snack','Lunch', 
                                                 'Lunch Alternative', 'Afternoon Snack','After Work / School Bite', 
                                                 'Dinner', 'Dinner Alternative','Evening Me', 'Evening We',
                                                 'Bedtime / Late Night Snack'],var_name ='Occasions')

Unweighted_base_dict = dict(zip(Unweighted_base['Occasions'], Unweighted_base['value']))
Weighted_base_nummber_dict = dict(zip(Weighted_base_nummber['Occasions'], Weighted_base_nummber['value']))

rest_of_table['Unweighted_base']=rest_of_table['Occasions']
rest_of_table['Unweighted_base']=rest_of_table.Occasions.map(Unweighted_base_dict)

rest_of_table['Weighted_base']=rest_of_table['Occasions']
rest_of_table['Weighted_base']=rest_of_table.Occasions.map(Weighted_base_nummber_dict)
rest_of_table

# Weighted_base_percentage
Weighted_base_percentage['Unweighted_base']=Weighted_base_percentage['Occasions']
Weighted_base_percentage['Unweighted_base']=Weighted_base_percentage.Occasions.map(Unweighted_base_dict)

Weighted_base_percentage['Weighted_base']=Weighted_base_percentage['Occasions']
Weighted_base_percentage['Weighted_base']=Weighted_base_percentage.Occasions.map(Weighted_base_nummber_dict)

Table_output=Weighted_base_percentage.append(rest_of_table)

Table_output=Table_output.reset_index(drop=True)

uper_level_name=[]
y=''
for x in Table_output['Row_Names']:
    y=find_prefix(x)
    uper_level_name.append(y)

Table_output['New_Row_Names']=uper_level_name

for x in range(0,len(Table_output.index)):    
    if (Table_output['New_Row_Names'][x].find('Base ') != -1):
        Table_output['New_Row_Names'][x]='Base'
    else:
        continue

for x in range(0,len(Table_output.index)):    
    if (Table_output['New_Row_Names'][x].find('%') != -1):
        Table_output['New_Row_Names'][x]=Table_output['New_Row_Names'][x].replace('%','')
    else:
        continue

Table_output['New_Row_Names']=Table_output['New_Row_Names']+str('|')+Table_output['Occasions']

Table_output_final=Table_output[['New_Row_Names','value', 'Weighted_base', 'Unweighted_base']]
Table_output_final.columns=['Distinct','Percentage_value','WEIGHTED_Base','UNWEIGHTED_Base']

Table_output_final

def find_prefix(name):
    indent_for_value=0
    return_value=''
    return_value_1=[]
    return_value_2=''    
    for x in range(0, len(data_2.index)):
        if data_2['Row_Names'][x]==name:
            indent_for_value=data_2['Indent'][x]
            if indent_for_value==0:
                return_value=name
            elif indent_for_value==1:
                for i in range(x,-1,-1):
                    if data_2['Indent'][i]==0:
                        return_value=data_2['Row_Names'][i]
                        break
                    else:
                        continue
            elif indent_for_value==2:
                for i in range(x,-1,-1):
                    if data_2['Indent'][i]==2:
                        continue                        
                    elif data_2['Indent'][i]==1:
                        return_value_1.append(data_2['Row_Names'][i])                        
                    elif data_2['Indent'][i]==0:
                        return_value_2=data_2['Row_Names'][i]
                        break
                    else:
                        continue
                return_value=return_value_2+str('|')+return_value_1[0]
    return return_value

Table_output_final.to_csv('Table_output_final.csv',index=False)

# Test_round_1=[Table_Name_used,Table_header,Base_used,Filter_used]

# Test_round_1 = pd.DataFrame(list(zip(Table_Name_used,Table_header,Base_used,Filter_used)),
#                             columns =['Table_Name_used','Table_header','Base_used','Filter_used'])

# Test_round_1.shape

# Test_round_1.to_csv('Test_round_1.csv')

Table_output_final

############################ Automation Final ###############################################

import numpy as np 
import pandas as pd 
import openpyxl
from openpyxl import load_workbook

import warnings
warnings.filterwarnings("ignore")

# 1. Change the File paths in the box below as per your PC for Left pannel and Burke name mapping

#Left Panel mapping file for parent prefix
Mapping_for_row_info= pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\LeftPanel_Hierarchy 10112019 (wo OSP).xlsx",
                                             sheet_name="LeftPanel_Hierarchy 10112019 (w"))

#Display name and tool name mapping Tool to Check 
Tool_name_map = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Burke to Tool Mapping File 09272019.xlsx",
                                             sheet_name="In Tool"))

#Attribute id and the value for the rows of the selection
Attribute_name_map = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Sample Automation Test Cases with output 19_09_2019.xlsx",
                                             sheet_name="AttributeType"))

# 2. Read the Market file  and the Indent for same file to be tested, change the file path in box below

#Read Tables
file_path_US_Q2= "C:\\Users\\10920\\Desktop\\Automation\\Total Tables by Occasion - Q3 US.xlsx"
wb_us_q2 = load_workbook(file_path_US_Q2)

wb=wb_us_q2

#read Indent Level for files
Indent_level_us_q2= pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Indent_level_all.xlsx",
                                             sheet_name="Indent_US"))
Indent_level_all=Indent_level_us_q2

Creating mappings

Mapping_for_row_info.columns=['MetricId', 'MetricName', 'Display_Name', 'MetricParentName',
                               'ParentId', 'IsSelectable', 'AttributetypeId', 'AttributeId',
                               'IsItemLevel', 'IsLastLevel', 'ToolOrderby', 'IsSnapshot',
                               'SnapshotLastLevel', 'IsAllCountry', 'US', 'UK', 'France', 'Brazil',
                               'Mexico', 'Australia']

#Creating the tool display name and table name map
Tool_name_map_map=Tool_name_map[['Burke Display Name','Display Name']]
Tool_name_map_map.columns=['Burke_Display_Name','Display_Name']

Tool_name_map_map = Tool_name_map_map.dropna()
Tool_name_map_map=Tool_name_map_map.reset_index(drop=True)

Tool_name_map_dict = dict(zip(Tool_name_map_map['Burke_Display_Name'], Tool_name_map_map['Display_Name']))

Tool_name_map.columns=['MetricId', 'MetricName', 'Display_Name', 'Burke_Display_Name']

Reading Check tables

list_tables=wb.sheetnames
list_tables.remove('Table of Contents')
# list_tables.remove('Indent')

#To store all the tables
Table_dict={}

# To find:: Table Name, Table header,Base, Filter
Table_Name_used=[]
Table_header=[]
Base_used=[]
Filter_used={}

for table_number in list_tables:
    data=pd.DataFrame(wb[table_number].values)
    
    data['Indent']=Indent_level_all[table_number]   

    Table_Name=data.loc[0][0]
    Table_Name_used.append(Table_Name)

    Table_Question=data.loc[1][0]
    Table_header.append(Table_Question)

    Table_Question=Table_Question.splitlines()
    
    if len(Table_Question)>=3:
        Filter=Table_Question[len(Table_Question)-1]
    else:
        Filter="No Filter"

    Filter_used[table_number]=Filter

    data_index=data.index.tolist()
    data_column=len(data.columns)

    data_1=data

    for i in data_index:
        for j in range(0,data_column-1):
            if data_1.loc[i,j]=='Client Confidential':
                temp=i
            else:
                continue            

    for i in range(temp-2,len(data_index)):
                data_1=data_1.drop(i)

    for i in range(0,data_1.shape[0]):
        if data_1.iloc[i][1]=='Total':
            j=i
        else:
            continue

    for i in range(0,j):
        data_1=data_1.drop(i)

    data_1=data_1.reset_index(drop=True)

#Filling the blank rows for merged cells
    for i in range(1,len(data_1.index)):
        if type(data_1.iloc[i,0])==type(None):
            data_1.iloc[i,0]=data_1.iloc[i-1,0] +str('%')
        else:
            continue

    data_1[0][0]='Row_Names'
    data_1.columns=data_1.loc[0].tolist()
    data_1=data_1.rename(columns = {data_1.columns[len(data_1.columns)-1]:'Indent'})   

    data_1=data_1.drop(0)
    data_1=data_1.reset_index(drop=True)

    for i in range(0,len(data_1.index)):
        temp=data_1['Row_Names'][i]
        
        if type(temp)==type(None):            
            continue 
        else:
            if (temp.find('Base ') != -1):
                where=i 
            else:
                continue    

#Using Burk's Mapping to convert row names to Display Names    
    data_1['Row_Names']=data_1['Row_Names'].map(Tool_name_map_dict).fillna(data_1['Row_Names'])
    
    Base=''
    Base=data_1['Row_Names'][where]
    Base=Base.replace('Base - ','',1)

    Base_used.append(Base)
    
    data_table_name = 'data_table'+str('_')+str(Table_Question[0])+str('_')
    
       
    Table_dict[data_table_name]=data_1

list_tables=['Table2']

for table_number in list_tables:
    data=pd.DataFrame(wb[table_number].values)

data

Manupulations needed for the data

for key in Table_dict.keys():
    Table_dict[key].columns=['Row_Names','Total','Early Morning Bite','Breakfast For One','Family Breakfast',
                        'Breakfast at Work/School','Mid Morning Snack','Lunch','Lunch Alternative','Afternoon Snack',
                         'After Work/School Bite','Dinner','Dinner Alternative','Evening Me','Evening We',
                         'Bedtime/Late Night Snack','Indent']

Filter_used = { k.replace('Table', ''): v for k, v in Filter_used.items() }    
dictlist_key=[]
dictlist_value=[]
for key, value in Filter_used.items():
    temp_value = [value]
    temp_key = [key]
    dictlist_value.append(temp_value[0])
    dictlist_key.append(temp_key[0])
    
dictlist_df=pd.DataFrame([dictlist_key,dictlist_value])
fffilter_used=dictlist_df.transpose()[1].map(Tool_name_map_dict).fillna(dictlist_df.transpose()[1])
filter_dictionary = dict(zip(dictlist_df.transpose()[0], fffilter_used))

Functions

#Finding the parent prefix for the row entries 

def find_parent_prefix(name):    
    
    metric_id=0
    for x in range(0,len(Tool_name_map.index)):
        if Tool_name_map['Display_Name'][x]==name:
            metric_id=Tool_name_map['MetricId'][x]
            break
        else:
            continue

    row_parent_name=''
    row_parent_iid=0
    parent_list=[]

    for x in range(0,len(Mapping_for_row_info['Display_Name'])):        
        if Mapping_for_row_info['MetricId'][x]==metric_id:
            row_parent_iid=Mapping_for_row_info['ParentId'][x]
            row_parent_metric_name=Mapping_for_row_info['MetricParentName'][x]
            row_parent_name=Mapping_for_row_info['Display_Name'][Mapping_for_row_info['MetricName']==row_parent_metric_name].values[0]
            break
        else:
            continue

    parent_list.append(row_parent_name)  

    while(row_parent_iid!=0):
        temp_iid=Mapping_for_row_info.loc[Mapping_for_row_info['MetricId']==row_parent_iid,'ParentId'].iloc[0]
        if temp_iid==0:
            break
        else:
            row_parent_metric_name_1=Mapping_for_row_info[Mapping_for_row_info['ParentId']==temp_iid]['MetricParentName'].iloc[0]
            row_parent_name_1=Mapping_for_row_info[Mapping_for_row_info['MetricName']==row_parent_metric_name_1]['Display_Name'].iloc[0]
        row_parent_iid=temp_iid
        
        parent_list.append(row_parent_name_1)            

    Parent_prefix=''
    for x in range(0,len(parent_list)):
        if (x==len(parent_list)-1):
                    Parent_prefix=str('Row')+str('^')+Parent_prefix
                    Parent_prefix=parent_list[x]+str('^')+Parent_prefix
        else:
            Parent_prefix=parent_list[x]+str('^')+Parent_prefix 
    return Parent_prefix , parent_list


#For output tables : Row names for selection

def find_prefix(name,data):
    indent_for_value=0
    return_value=''
    return_value_1=[]
    return_value_2=''    
    for x in range(0, len(data.index)):
        if data['Row_Names'][x]==name:
            indent_for_value=data['Indent'][x]
            if indent_for_value==0:
                return_value=name
            elif indent_for_value==1:
                for i in range(x,-1,-1):
                    if data['Indent'][i]==0:
                        return_value=data['Row_Names'][i]+str('|')+data['Row_Names'][x]
                        break
                    else:
                        continue
            elif indent_for_value==2:
                for i in range(x,-1,-1):
                    if data['Indent'][i]==2:
                        continue                        
                    elif data['Indent'][i]==1:
                        return_value_1.append(data['Row_Names'][i])                        
                    elif data['Indent'][i]==0:
                        return_value_2=data['Row_Names'][i]
                        break
                    else:
                        continue
                return_value=return_value_2+str('|')+return_value_1[0]
    return return_value

# Input the Tables numbers to be checked

Tables_to_be_checked_first_round=[2,3,4,6,8,10,11,12,13,40,41,42,43,44,45,46,47,48,49,50,51,108,109,110,111,112,114,115,
                                  116,117,119,120,121,122,124,125,126,127,129,130,131,132,134,135,136,137,139,140,141,142,
                                  144,145,146,147,149,150,151,152,154,155,156,157,159,160,161,162,164,165,166,167,169,170,
                                  171,172,174,175,176,177,179,180,181,182,184,185,186,187,189,190,191,192,195,197,199,200,
                                  201,202,203,204,205,206,207,212,213,215]

Finding the filter used in the table

# Creating Table Filter
prefix_filter={}

for Table_Number___ in Tables_to_be_checked_first_round:
    data_table_name = 'data_table_Table: '+str(Table_Number___)+str('_')
    data_2=Table_dict[data_table_name]
    filter_used=filter_dictionary[str(Table_Number___)]
#     print(filter_used)

    Indent=data_2[['Row_Names','Indent']]
    Indent=data_2[['Row_Names','Indent']]
    Indent.columns=['table_row_name','indent_row_level']

    #Creating the Indent data to find the zero level indented rows for selection

    for i in range(0,len(Indent.index)):
        if (Indent['table_row_name'][i].find('%') != -1):
            Indent=Indent.drop(i)
        else:
            continue
    Indent=Indent.reset_index(drop=True) 

    counter=0

    for i in range(3,len(Indent.index)):
        if ('Total' in Indent['table_row_name'][i]):
            counter=i
            break        
        else:
            continue

    if counter!=0:
        for x in range(counter,len(Indent.index)):
            Indent=Indent.drop(x)
    Indent=Indent.reset_index(drop=True)

    Indent['table_row_name']=Indent['table_row_name'].map(Tool_name_map_dict).fillna(Indent['table_row_name']) 

    temp_row_value=filter_used
    
    metric_iid=0
    for x in range(0,len(Tool_name_map['Display_Name'])):
        if Tool_name_map['Display_Name'][x]==temp_row_value:
            metric_iid=Tool_name_map['MetricId'][x]
        else:
            continue       
            
            
    attribute_iid=0
    for x in range(0,len(Mapping_for_row_info.index)): 
        if Mapping_for_row_info['MetricId'][x]==metric_iid:
            attribute_iid=Mapping_for_row_info['AttributetypeId'][x]
        else:
            continue  
            
#     print(metric_iid)
#     print(attribute_iid)

    row_parent_name=''
    row_parent_id=0
    parent_list=[]

    for x in range(0,len(Mapping_for_row_info['Display_Name'])):
        if Mapping_for_row_info['MetricId'][x]==metric_iid:
            row_parent_name=Mapping_for_row_info['MetricParentName'][x]
            row_parent_id=Mapping_for_row_info['ParentId'][x]
        else:
            continue

    parent_list.append(row_parent_name)   
    
    Row_name_list=[]
    Row_name=''

    if attribute_iid in [38,39,40]:
        Row_name_list=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_iid]['AttributeType']        
        Row_name=Row_name_list[Row_name_list.index[0]]
    else:
#         if len(parent_list)!=0:
        Row_name=''

    while(row_parent_id!=0):
        temp_id=Mapping_for_row_info['ParentId'][Mapping_for_row_info['MetricId']==row_parent_id].values[0]
        parent_list.append(Mapping_for_row_info['MetricParentName'][Mapping_for_row_info['ParentId']==temp_id].values[0])  
        row_parent_id=temp_id

    parent_list.remove(parent_list[len(parent_list)-1])

    Parent_prefix=''
    for x in range(0,len(parent_list)):
        if (x==len(parent_list)-1):
                    Parent_prefix=Row_name+str('^')+Parent_prefix
                    Parent_prefix=parent_list[x]+str('^')+Parent_prefix
        else:
            Parent_prefix=parent_list[x]+str('^')+Parent_prefix  
    filter_temp=Parent_prefix+filter_used
    filter_temp=filter_temp.replace('^^','^',1)

    prefix_filter[Table_Number___]=filter_temp

Row level syntax and table outputs

# Finding the syntax for each row and generating the output in the asked format for the same
Column_dict={}
Row_Nesting_dict={}
Time_Period_dict={}
Market_dict={}
Occasions_dict={}
Benchmark_dict={}
Respondent_Type_dict={}
Output_Table_dict={}
row_parent_all_row={}
row_parent_list_all_row={}
row_category_dict={}
row_demog_dict={}
row_5w_dict={}
rows_dict={}
filter_for_row={}
Parent_prefix_for_row=''

for table_number in Tables_to_be_checked_first_round:
    data_table_name = 'data_table_Table: '+str(table_number)+str('_')
    filter_for_row_temp=''
    filter_for_row_temp=prefix_filter[table_number]
    Test_table=Table_dict[data_table_name]

    id_vars =['Row_Names']
    value_vars =['Total','Early Morning Bite','Breakfast For One','Family Breakfast','Breakfast at Work/School',
                 'Mid Morning Snack','Lunch','Lunch Alternative','Afternoon Snack','After Work/School Bite',
                 'Dinner','Dinner Alternative','Evening Me','Evening We','Bedtime/Late Night Snack']

    var_name =['Occasions']

    Unweighted_base=Test_table[:1]
    Unweighted_base=Unweighted_base.melt(id_vars, value_vars, var_name)
    Unweighted_base_dict = dict(zip(Unweighted_base['Occasions'], Unweighted_base['value']))


    Weight_test_table=pd.DataFrame()
    percentage_table=pd.DataFrame()

    Weight_test_table=Test_table[2:]
    percentage_table=Test_table[2:]
    Weight_test_table=Weight_test_table.reset_index(drop=True)
    percentage_table=percentage_table.reset_index(drop=True)

    # Creating the Weight Table
    for i in range(0,len(Weight_test_table.index)):
        if (Weight_test_table['Row_Names'][i].find('%') != -1):
            Weight_test_table=Weight_test_table.drop(i)
        else:
            continue
    Weight_test_table=Weight_test_table.reset_index(drop=True)
    #removing the last Total row from weight table
    counter_1=0
    for i in range(3,len(Weight_test_table.index)):
        if ('Total' in Weight_test_table['Row_Names'][i]):
            counter_1=i
            break        
        else:
            continue
            
    if counter_1!=0:
        for x in range(counter_1,len(Weight_test_table.index)):
            Weight_test_table=Weight_test_table.drop(x)
    Weight_test_table=Weight_test_table.reset_index(drop=True)
    Weight_test_table['Row_Names']=Weight_test_table['Row_Names'].map(Tool_name_map_dict).fillna(Weight_test_table['Row_Names'])
    Weight_test_table=Weight_test_table.drop(['Indent'], axis=1)       
   # Creating the percentage table
    for i in range(0,len(percentage_table.index)):
        if (percentage_table['Row_Names'][i].find('%') == -1):
            percentage_table=percentage_table.drop(i)
        else:
            continue
    percentage_table=percentage_table.reset_index(drop=True)
    for x in range(0,len(percentage_table.index)):
        row_name=percentage_table['Row_Names'][x]
        percentage_table['Row_Names'][x]=row_name[0:len(row_name)-1]
    
    #removing the last Total row from percentage table        
    counter_2=0
    for i in range(3,len(percentage_table.index)):
        if ('Total' in percentage_table['Row_Names'][i]):
            counter_2=i
            break        
        else:
            continue

    if counter_2!=0:
        for x in range(counter_2,len(percentage_table.index)):
            percentage_table=percentage_table.drop(x)
    percentage_table=percentage_table.reset_index(drop=True)
    percentage_table['Row_Names']=percentage_table['Row_Names'].map(Tool_name_map_dict).fillna(percentage_table['Row_Names'])
    percentage_table=percentage_table.drop(['Indent'], axis=1)
    
        #for row syntax  
    
    
    Indent=Test_table[['Row_Names','Indent']]

    Indent=Test_table[['Row_Names','Indent']]
    Indent.columns=['table_row_name','indent_row_level']
    
    
    for i in range(0,len(Indent.index)):
        if (Indent['table_row_name'][i].find('%') != -1):
            Indent=Indent.drop(i)
        else:
            continue
    Indent=Indent.reset_index(drop=True) 

    counter=0
    for i in range(3,len(Indent.index)):
        if ('Total' in Indent['table_row_name'][i]):
            counter=i
            break        
        else:
            continue

    if counter!=0:
        for x in range(counter,len(Indent.index)):
            Indent=Indent.drop(x)
    Indent=Indent.reset_index(drop=True)
    
    Indent = Indent.reindex(Indent.index.drop(0)).reset_index(drop=True)
    Indent['table_row_name']=Indent['table_row_name'].map(Tool_name_map_dict).fillna(Indent['table_row_name'])
    
    Table_Base_weight=Weight_test_table[:1]
    Table_Base_percent=percentage_table[:1]
    
    Table_Base_weight=Table_Base_weight.melt(id_vars , value_vars ,var_name )
    Table_Base_percent=Table_Base_percent.melt(id_vars , value_vars ,var_name )
    
    Table_Base_output = pd.merge(Table_Base_weight,Table_Base_percent,  how='left', left_on=['Row_Names','Occasions'],
                              right_on = ['Row_Names','Occasions'])
    
    for x in range(1,len(Indent.index)):
        
        row_parent_prefix_temp=''
        row_parent_list_temp=[]
        row_parent_prefix_temp,row_parent_list_temp=find_parent_prefix(Indent['table_row_name'][x])        
        if row_parent_prefix_temp=='^Row^':
            row_parent_prefix_temp,row_parent_list_temp=find_parent_prefix(Indent['table_row_name'][x].title())
        row_key=str('row_')+str(table_number)+str('_')+str(x)+str('_')+str(Indent['table_row_name'][x])     
        row_parent_all_row[row_key]=row_parent_prefix_temp+str(Indent['table_row_name'][x])
        row_parent_list_all_row[row_key]=row_parent_list_temp
        
        Test_table_row_weight=Weight_test_table[x:x+1]
        Test_table_row_percent=percentage_table[x:x+1]
        
        Test_table_row_weight=Test_table_row_weight.melt(id_vars , value_vars ,var_name )
        Test_table_row_percent=Test_table_row_percent.melt(id_vars , value_vars ,var_name )
    
        Table_row_output = pd.merge(Test_table_row_weight,Test_table_row_percent,  how='left', left_on=['Row_Names','Occasions'],
                              right_on = ['Row_Names','Occasions'])
        
        Output_table=pd.DataFrame()        
        Output_table=Table_Base_output.append(Table_row_output)
        Output_table['Kye']=row_key
        Output_table=Output_table.reset_index(drop=True)        
        
        for y in range(0,len(Output_table.index)):
            Output_table['Row_Names'][y]=Output_table['Row_Names'][y].replace('Don’t','Don\'t',1)
            if (Output_table['Row_Names'][y].find('Base ') != -1):
                Output_table['Row_Names'][y]='Base'                
            else:
                continue
                
        Output_table['Distinct']=Output_table['Row_Names']+str('|')+Output_table['Occasions']
        Output_table = Output_table[['Kye','Row_Names','Occasions','Distinct','value_y','value_x']]
        Output_table.columns=['Kye','Row_Names','Occasions','Distinct','Percentage value','WEIGHTED']
        Output_Table_dict[row_key]=Output_table
        
# Finding the Row for the selection
        
        temp_1_row_value=Indent['table_row_name'][x]
        
        Parent_prefix_for_row=''
        parent_list=[]
        Parent_prefix_for_row, parent_list=find_parent_prefix(temp_1_row_value)
        
        metric_id=0
        for x in range(0,len(Tool_name_map.index)):
            if Tool_name_map['Display_Name'][x]==temp_1_row_value:
                metric_id=Tool_name_map['MetricId'][x]
            else:
                continue   

        attribute_id=0
        for x in range(0,len(Mapping_for_row_info.index)):
            if Mapping_for_row_info['MetricId'][x]==metric_id:
                attribute_id=Mapping_for_row_info['AttributetypeId'][x]
            else:
                continue 

        Row_name_list=[]
        Row_name=''

        if attribute_id in [38,39,40]:
            Row_name_list=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_id]['AttributeType']        
            Row_name=Row_name_list[Row_name_list.index[0]]
        else:
            if len(parent_list)!=0:
                Row_name=parent_list[len(parent_list)-1]    

        if Row_name=='Item':
            rows_dict[row_key]='ROW^Category/Item/Brand^Item'
            row_category_dict[row_key]=row_parent_all_row[row_key].replace('Category/Item/Brand','CATEGORY/ITEM/BRAND',1)
            row_demog_dict[row_key]='NA'
            row_5w_dict[row_key]='NA'
            
        elif Row_name=='Brand':
            rows_dict[row_key]='ROW^Category/Item/Brand^Brand'
            row_category_dict[row_key]=row_parent_all_row[row_key].replace('Category/Item/Brand','CATEGORY/ITEM/BRAND',1)            
            row_demog_dict[row_key]='NA'
            row_5w_dict[row_key]='NA'
            
        elif Row_name=='Category':
            rows_dict[row_key]='ROW^Category/Item/Brand^Category'
            row_category_dict[row_key]=row_parent_all_row[row_key].replace('Category/Item/Brand','CATEGORY/ITEM/BRAND',1)
            row_demog_dict[row_key]='NA'
            row_5w_dict[row_key]='NA'
            
        elif Row_name=='Demographics':
            rows_dict[row_key]='ROW^Demographics'
            row_category_dict[row_key]='NA'
            row_demog_dict[row_key]=row_parent_all_row[row_key].replace('Demographics','DEMOGRAPHICS',1)
            row_5w_dict[row_key]='NA'
            
            
        elif Row_name=='5Ws':
            rows_dict[row_key]='ROW^5Ws'
            row_category_dict[row_key]='NA'
            row_demog_dict[row_key]='NA'
            row_5w_dict[row_key]=row_parent_all_row[row_key]
            
        else:
            row_category_dict[row_key]='NA'
            row_demog_dict[row_key]='NA'
            row_5w_dict[row_key]='NA'
            
            
            
        #generating all the columns
        filter_for_row[row_key]=str('ADDITIONAL FILTERS^')+filter_for_row_temp        
        Column_dict[row_key]='COLUMN^Occasion'
        Row_Nesting_dict[row_key]='NA'
        Time_Period_dict[row_key]='TIME PERIOD^Quarter^Q2 2019'
        Market_dict[row_key]='MARKETS^North America^US'
        Occasions_dict[row_key]='OCCASION^Early Morning Bite|Breakfast For One|Family Breakfast|Breakfast at Work/School|Mid Morning Snack|Lunch|Lunch Alternative|Afternoon Snack|After Work/School Bite|Dinner|Dinner Alternative|Evening Me|Evening We|Bedtime/Late Night Snack'
        Benchmark_dict[row_key]='NA'
        Respondent_Type_dict[row_key]='RESPONDENT TYPE^Total'

# Selection Sheet Output

All_table_row_info=pd.DataFrame({'Column':pd.Series(Column_dict),'Rows':pd.Series(rows_dict),
                                 'Row Nesting':pd.Series(Row_Nesting_dict),'Time Period':pd.Series(Time_Period_dict),
                                 'Market':pd.Series(Market_dict),'Occasions':pd.Series(Occasions_dict),
                                 'Category/ Item/Brand':pd.Series(row_category_dict),
                                 'Demographic':pd.Series(row_demog_dict),'5ws':pd.Series(row_5w_dict),
                                 'Additional Filter':pd.Series(filter_for_row),
                                 'Benchmark':pd.Series(Benchmark_dict),
                                 'Respondent Type':pd.Series(Respondent_Type_dict)})

All_table_row_info.to_csv('All_table_row_parent_info_us_test_round_1.csv')

# Output Sheet output

#Storing all the tables in a single dataframe
Output_all_table=pd.DataFrame()
for key in Output_Table_dict.keys():
    Output_all_table=Output_all_table.append(Output_Table_dict[key])

#Saving the table outputs in the appended format
Output_all_table.to_csv('Output_all_table_test_round_1.csv')

########################## Automation final 2 ##################################################

import numpy as np 
import pandas as pd 
import openpyxl
from openpyxl import load_workbook

import warnings
warnings.filterwarnings("ignore")

# 1. Change the File paths in the box below as per your PC for Left pannel and Burke name mapping

#Left Panel mapping file for parent prefix
Mapping_for_row_info= pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Final Files\\LeftPanel_Hierarchy 12042019.xlsx",
                                             sheet_name="Master_Sheet"))



#Display name and tool name mapping Tool to Check 
Tool_name_map = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Burke to Tool Mapping File 09272019.xlsx",
                                             sheet_name="In Tool"))

#Attribute id and the value for the rows of the selection
Attribute_name_map = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Sample Automation Test Cases with output 19_09_2019.xlsx",
                                             sheet_name="AttributeType"))

Mapping_for_row_info_1=Mapping_for_row_info[(Mapping_for_row_info['IsCrosstab']==1) & (Mapping_for_row_info['US']==1) ]
Mapping_for_row_info_1=Mapping_for_row_info_1.reset_index(drop=True)

Mapping_for_row_info=Mapping_for_row_info_1

# 2. Read the Market file  and the Indent for same file to be tested, change the file path in box below

#Read Tables
file_path_US_Q2= "C:\\Users\\10920\\Desktop\\Automation\\Final Files\\Total Tables by Occasion - Q3 US.xlsx"
wb_us_q2 = load_workbook(file_path_US_Q2)

wb=wb_us_q2

#read Indent Level for files
Indent_level_us_q2= pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\Automation\\Indent_level_all.xlsx",
                                             sheet_name="Indent_US_Q3"))
Indent_level_all=Indent_level_us_q2

Creating mappings

Mapping_for_row_info.columns= ['MetricId', 'MetricName', 'Display_Name', 'MetricParentName','ParentId', 'IsSelectable', 
                               'AttributetypeId', 'AttributeId','IsItemLevel', 'ToolOrderby', 'IsCrosstab', 
                               'CrosstabLastLevel','IsSnapshot', 'SnapshotLastLevel', 'IsOSP', 'OSPLastLevel',
                               'IsAllCountry', 'US', 'UK', 'France', 'Brazil', 'Mexico', 'Australia']

#Creating the tool display name and table name map
Tool_name_map_map=Tool_name_map[['Burke Display Name','Display Name']]
Tool_name_map_map.columns=['Burke_Display_Name','Display_Name']

Tool_name_map_map = Tool_name_map_map.dropna()
Tool_name_map_map=Tool_name_map_map.reset_index(drop=True)

Tool_name_map_dict = dict(zip(Tool_name_map_map['Burke_Display_Name'], Tool_name_map_map['Display_Name']))

Tool_name_map.columns=['MetricId', 'MetricName', 'Display_Name', 'Burke_Display_Name']

Reading Check tables

list_tables=wb.sheetnames
list_tables.remove('Table of Contents')
# list_tables.remove('Table20')
# list_tables.remove('Table21')

#To store all the tables
Table_dict={}

# To find:: Table Name, Table header,Base, Filter
Table_Name_used=[]
Table_header=[]
Base_used=[]
Filter_used={}

for table_number in list_tables:
    data=pd.DataFrame(wb[table_number].values)
    
    data['Indent']=Indent_level_all[table_number]   

    Table_Name=data.loc[0][0]
    Table_Name_used.append(Table_Name)

    Table_Question=data.iloc[1][0]

    Table_header.append(Table_Question)

    Table_Question=Table_Question.splitlines()
    
    if len(Table_Question)>=3:
        Filter=Table_Question[len(Table_Question)-1]
    else:
        Filter="No Filter"

    Filter_used[table_number]=Filter
    
    data_index=data.index.tolist()
    data_column=len(data.columns)
     
    data_1=data

    for i in data_index:
        for j in range(0,data_column-1):
            if data_1.loc[i,j]=='Client Confidential':
                temp=i
            else:
                continue            
                
    for i in range(temp-2,len(data_index)):
                data_1=data_1.drop(i)

    data_1=data_1.reset_index(drop=True) 
    
      
    for i in range(0,data_1.shape[0]):
        if data_1.iloc[i][0]=='Unweighted Base':
            j=i
        else:
            continue

    for i in range(0,j-1):
        data_1=data_1.drop(i)

    data_1=data_1.reset_index(drop=True)
    
    data_1.columns=['Row_Names','Total','Early Morning Bite','Breakfast For One','Family Breakfast','Breakfast @ Work / School',
                'Mid Morning Snack','Lunch','Lunch Alternative','Afternoon Snack','After Work / School Bite', 'Dinner', 
                'Dinner Alternative','Evening Me','Evening We','Bedtime / Late Night Snack','Indent']

#Filling the blank rows for merged cells
    for i in range(1,len(data_1.index)):
        if type(data_1['Row_Names'][i])==type(None):
            data_1['Row_Names'][i]=data_1['Row_Names'][i-1] +str('%')
        else:
            continue

    data_1=data_1.drop(0)
    data_1=data_1.reset_index(drop=True)

    for i in range(0,len(data_1.index)):
        temp=data_1['Row_Names'][i]
        
        if type(temp)==type(None):            
            continue 
        else:
            if (temp.find('Base ') != -1):
                where=i 
            else:
                continue    

#Using Burk's Mapping to convert row names to Display Names    
    data_1['Row_Names']=data_1['Row_Names'].map(Tool_name_map_dict).fillna(data_1['Row_Names'])
    
    Base=''
    Base=data_1['Row_Names'][where]
    Base=Base.replace('Base - ','',1)

    Base_used.append(Base)
    
    data_table_name = 'data_table'+str('_')+str(Table_Question[0])+str('_')
    
       
    Table_dict[data_table_name]=data_1

Manupulations needed for the data

# test_table=pd.DataFrame()
# cols=[16,17]
# for key in Table_dict.keys():
#     test_table=Table_dict[key].drop(Table_dict[key].columns[cols], axis=1) 
#     Table_dict[key]=test_table
    
for key in Table_dict.keys():
    Table_dict[key].columns=['Row_Names','Total','Early Morning Bite','Breakfast For One','Family Breakfast',
                        'Breakfast at Work/School','Mid Morning Snack','Lunch','Lunch Alternative','Afternoon Snack',
                         'After Work/School Bite','Dinner','Dinner Alternative','Evening Me','Evening We',
                         'Bedtime/Late Night Snack','Indent']

Filter_used = { k.replace('Table', ''): v for k, v in Filter_used.items() }    
dictlist_key=[]
dictlist_value=[]
for key, value in Filter_used.items():
    temp_value = [value]
    temp_key = [key]
    dictlist_value.append(temp_value[0])
    dictlist_key.append(temp_key[0])
    
dictlist_df=pd.DataFrame([dictlist_key,dictlist_value])
fffilter_used=dictlist_df.transpose()[1].map(Tool_name_map_dict).fillna(dictlist_df.transpose()[1])
filter_dictionary = dict(zip(dictlist_df.transpose()[0], fffilter_used))

Functions

#Finding the parent prefix for the row entries 

def find_parent_prefix(name):    
    
    metric_id=0
    for x in range(0,len(Tool_name_map.index)):
        if Tool_name_map['Display_Name'][x]==name:
            metric_id=Tool_name_map['MetricId'][x]
            break
        else:
            continue

    row_parent_name=''
    row_parent_iid=0
    parent_list=[]

    for x in range(0,len(Mapping_for_row_info['Display_Name'])):        
        if Mapping_for_row_info['MetricId'][x]==metric_id:
            row_parent_iid=Mapping_for_row_info['ParentId'][x]
            row_parent_metric_name=Mapping_for_row_info['MetricParentName'][x]
            row_parent_name=Mapping_for_row_info['Display_Name'][Mapping_for_row_info['MetricName']==row_parent_metric_name].values[0]
            break
        else:
            continue

    parent_list.append(row_parent_name)  

    while(row_parent_iid!=0):
        temp_iid=Mapping_for_row_info.loc[Mapping_for_row_info['MetricId']==row_parent_iid,'ParentId'].iloc[0]
        if temp_iid==0:
            break
        else:
            row_parent_metric_name_1=Mapping_for_row_info[Mapping_for_row_info['ParentId']==temp_iid]['MetricParentName'].iloc[0]
            row_parent_name_1=Mapping_for_row_info[Mapping_for_row_info['MetricName']==row_parent_metric_name_1]['Display_Name'].iloc[0]
        row_parent_iid=temp_iid
        
        parent_list.append(row_parent_name_1)            

    Parent_prefix=''
    for x in range(0,len(parent_list)):
        if (x==len(parent_list)-1):
                    Parent_prefix=str('Row')+str('^')+Parent_prefix
                    Parent_prefix=parent_list[x]+str('^')+Parent_prefix
        else:
            Parent_prefix=parent_list[x]+str('^')+Parent_prefix 
    return Parent_prefix , parent_list


#For output tables : Row names for selection

def find_prefix(name,data):
    indent_for_value=0
    return_value=''
    return_value_1=[]
    return_value_2=''    
    for x in range(0, len(data.index)):
        if data['Row_Names'][x]==name:
            indent_for_value=data['Indent'][x]
            if indent_for_value==0:
                return_value=name
            elif indent_for_value==1:
                for i in range(x,-1,-1):
                    if data['Indent'][i]==0:
                        return_value=data['Row_Names'][i]+str('|')+data['Row_Names'][x]
                        break
                    else:
                        continue
            elif indent_for_value==2:
                for i in range(x,-1,-1):
                    if data['Indent'][i]==2:
                        continue                        
                    elif data['Indent'][i]==1:
                        return_value_1.append(data['Row_Names'][i])                        
                    elif data['Indent'][i]==0:
                        return_value_2=data['Row_Names'][i]
                        break
                    else:
                        continue
                return_value=return_value_2+str('|')+return_value_1[0]
    return return_value

# Input the Tables numbers to be checked

Tables_to_be_checked_first_round=[2,3,6,8,10,11,12,13,40,41,42,43,44,45,46,47,48,49,119,122,123,125,128,130,133,135,138,140,
                                  143,145,148,150,153,155,158,160,163,165,168,170,173,175,178,180,183,185,188,190,193,195,
                                  198,200,203,205,206,208,210,211,212,213,214,215,216,217,218]

Finding the filter used in the table

# Creating Table Filter
prefix_filter={}

for Table_Number___ in Tables_to_be_checked_first_round:
    data_table_name = 'data_table_Table: '+str(Table_Number___)+str('_')
    data_2=Table_dict[data_table_name]
    filter_used=filter_dictionary[str(Table_Number___)]
#     print(filter_used)

    Indent=data_2[['Row_Names','Indent']]
    Indent=data_2[['Row_Names','Indent']]
    Indent.columns=['table_row_name','indent_row_level']

    #Creating the Indent data to find the zero level indented rows for selection

    for i in range(0,len(Indent.index)):
        if (Indent['table_row_name'][i].find('%') != -1):
            Indent=Indent.drop(i)
        else:
            continue
    Indent=Indent.reset_index(drop=True) 

    counter=0

    for i in range(3,len(Indent.index)):
        if ('Total' in Indent['table_row_name'][i]):
            counter=i
            break        
        else:
            continue

    if counter!=0:
        for x in range(counter,len(Indent.index)):
            Indent=Indent.drop(x)
    Indent=Indent.reset_index(drop=True)

    Indent['table_row_name']=Indent['table_row_name'].map(Tool_name_map_dict).fillna(Indent['table_row_name']) 

    temp_row_value=filter_used
    
#     print("table number")
#     print(Table_Number___)
    
    metric_iid=0
    for x in range(0,len(Tool_name_map['Display_Name'])):
        if Tool_name_map['Display_Name'][x]==temp_row_value:
            metric_iid=Tool_name_map['MetricId'][x]
        else:
            continue       
            
#     print(temp_row_value)
#     print("metric_iid")
#     print(metric_iid)    
    
    attribute_iid=0
#     print(len(Mapping_for_row_info.index))
    for x in range(0,len(Mapping_for_row_info.index)):
        if Mapping_for_row_info['MetricId'][x]==metric_iid:
#             print(x)
            attribute_iid=Mapping_for_row_info['AttributetypeId'][x]
        else:
            continue  
            
#     print("attribute_iid")
#     print(attribute_iid)
    row_parent_name=''
    row_parent_id=0
    parent_list=[]

    for x in range(0,len(Mapping_for_row_info['Display_Name'])):
        if Mapping_for_row_info['MetricId'][x]==metric_iid:
            row_parent_name=Mapping_for_row_info['MetricParentName'][x]
            row_parent_id=Mapping_for_row_info['ParentId'][x]
        else:
            continue

    parent_list.append(row_parent_name)   
    
    Row_name_list=[]
    Row_name=''

    if attribute_iid in [38,39,40]:
        Row_name_list=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_iid]['AttributeType']        
        Row_name=Row_name_list[Row_name_list.index[0]]
    else:
#         if len(parent_list)!=0:
        Row_name=''

    while(row_parent_id!=0):
        temp_id=Mapping_for_row_info['ParentId'][Mapping_for_row_info['MetricId']==row_parent_id].values[0]
        parent_list.append(Mapping_for_row_info['MetricParentName'][Mapping_for_row_info['ParentId']==temp_id].values[0])  
        row_parent_id=temp_id

    parent_list.remove(parent_list[len(parent_list)-1])

    Parent_prefix=''
    for x in range(0,len(parent_list)):
        if (x==len(parent_list)-1):
                    Parent_prefix=Row_name+str('^')+Parent_prefix
                    Parent_prefix=parent_list[x]+str('^')+Parent_prefix
        else:
            Parent_prefix=parent_list[x]+str('^')+Parent_prefix  
    filter_temp=Parent_prefix+filter_used
    filter_temp=filter_temp.replace('^^','^',1)

    prefix_filter[Table_Number___]=filter_temp

Row level syntax and table outputs

# Finding the syntax for each row and generating the output in the asked format for the same
Column_dict={}
Row_Nesting_dict={}
Time_Period_dict={}
Market_dict={}
Occasions_dict={}
Benchmark_dict={}
Respondent_Type_dict={}
Output_Table_dict={}
row_parent_all_row={}
row_parent_list_all_row={}
row_category_dict={}
row_demog_dict={}
row_5w_dict={}
rows_dict={}
filter_for_row={}
Parent_prefix_for_row=''

for table_number in Tables_to_be_checked_first_round:
    data_table_name = 'data_table_Table: '+str(table_number)+str('_')
    filter_for_row_temp=''
    filter_for_row_temp=prefix_filter[table_number]
    Test_table=Table_dict[data_table_name]

    id_vars =['Row_Names']
    value_vars =['Total','Early Morning Bite','Breakfast For One','Family Breakfast','Breakfast at Work/School',
                 'Mid Morning Snack','Lunch','Lunch Alternative','Afternoon Snack','After Work/School Bite',
                 'Dinner','Dinner Alternative','Evening Me','Evening We','Bedtime/Late Night Snack']

    var_name =['Occasions']

    Unweighted_base=Test_table[:1]
    Unweighted_base=Unweighted_base.melt(id_vars, value_vars, var_name)
    Unweighted_base_dict = dict(zip(Unweighted_base['Occasions'], Unweighted_base['value']))


    Weight_test_table=pd.DataFrame()
    percentage_table=pd.DataFrame()

    Weight_test_table=Test_table[2:]
    percentage_table=Test_table[2:]
    Weight_test_table=Weight_test_table.reset_index(drop=True)
    percentage_table=percentage_table.reset_index(drop=True)

    # Creating the Weight Table
    for i in range(0,len(Weight_test_table.index)):
        if (Weight_test_table['Row_Names'][i].find('%') != -1):
            Weight_test_table=Weight_test_table.drop(i)
        else:
            continue
    Weight_test_table=Weight_test_table.reset_index(drop=True)
    #removing the last Total row from weight table
    counter_1=0
    for i in range(3,len(Weight_test_table.index)):
        if ('Total' in Weight_test_table['Row_Names'][i]):
            counter_1=i
            break        
        else:
            continue
            
    if counter_1!=0:
        for x in range(counter_1,len(Weight_test_table.index)):
            Weight_test_table=Weight_test_table.drop(x)
    Weight_test_table=Weight_test_table.reset_index(drop=True)
    Weight_test_table['Row_Names']=Weight_test_table['Row_Names'].map(Tool_name_map_dict).fillna(Weight_test_table['Row_Names'])
    Weight_test_table=Weight_test_table.drop(['Indent'], axis=1)       
   # Creating the percentage table
    for i in range(0,len(percentage_table.index)):
        if (percentage_table['Row_Names'][i].find('%') == -1):
            percentage_table=percentage_table.drop(i)
        else:
            continue
    percentage_table=percentage_table.reset_index(drop=True)
    for x in range(0,len(percentage_table.index)):
        row_name=percentage_table['Row_Names'][x]
        percentage_table['Row_Names'][x]=row_name[0:len(row_name)-1]
    
    #removing the last Total row from percentage table        
    counter_2=0
    for i in range(3,len(percentage_table.index)):
        if ('Total' in percentage_table['Row_Names'][i]):
            counter_2=i
            break        
        else:
            continue

    if counter_2!=0:
        for x in range(counter_2,len(percentage_table.index)):
            percentage_table=percentage_table.drop(x)
    percentage_table=percentage_table.reset_index(drop=True)
    percentage_table['Row_Names']=percentage_table['Row_Names'].map(Tool_name_map_dict).fillna(percentage_table['Row_Names'])
    percentage_table=percentage_table.drop(['Indent'], axis=1)
    
        #for row syntax  
    
    
    Indent=Test_table[['Row_Names','Indent']]

    Indent=Test_table[['Row_Names','Indent']]
    Indent.columns=['table_row_name','indent_row_level']
    
    
    for i in range(0,len(Indent.index)):
        if (Indent['table_row_name'][i].find('%') != -1):
            Indent=Indent.drop(i)
        else:
            continue
    Indent=Indent.reset_index(drop=True) 

    counter=0
    for i in range(3,len(Indent.index)):
        if ('Total' in Indent['table_row_name'][i]):
            counter=i
            break        
        else:
            continue

    if counter!=0:
        for x in range(counter,len(Indent.index)):
            Indent=Indent.drop(x)
    Indent=Indent.reset_index(drop=True)
    
    Indent = Indent.reindex(Indent.index.drop(0)).reset_index(drop=True)
    Indent['table_row_name']=Indent['table_row_name'].map(Tool_name_map_dict).fillna(Indent['table_row_name'])
    
    Table_Base_weight=Weight_test_table[:1]
    Table_Base_percent=percentage_table[:1]
    
    Table_Base_weight=Table_Base_weight.melt(id_vars , value_vars ,var_name )
    Table_Base_percent=Table_Base_percent.melt(id_vars , value_vars ,var_name )
    
    Table_Base_output = pd.merge(Table_Base_weight,Table_Base_percent,  how='left', left_on=['Row_Names','Occasions'],
                              right_on = ['Row_Names','Occasions'])
    
    for x in range(1,len(Indent.index)):
        
        row_parent_prefix_temp=''
        row_parent_list_temp=[]
        print(Indent['table_row_name'][x],x,table_number)
        row_parent_prefix_temp,row_parent_list_temp=find_parent_prefix(Indent['table_row_name'][x])        
        if row_parent_prefix_temp=='^Row^':
            row_parent_prefix_temp,row_parent_list_temp=find_parent_prefix(Indent['table_row_name'][x].title())
        row_key=str('row_')+str(table_number)+str('_')+str(x)+str('_')+str(Indent['table_row_name'][x])     
        row_parent_all_row[row_key]=row_parent_prefix_temp+str(Indent['table_row_name'][x])
        row_parent_list_all_row[row_key]=row_parent_list_temp
        
        Test_table_row_weight=Weight_test_table[x:x+1]
        Test_table_row_percent=percentage_table[x:x+1]
        
        Test_table_row_weight=Test_table_row_weight.melt(id_vars , value_vars ,var_name )
        Test_table_row_percent=Test_table_row_percent.melt(id_vars , value_vars ,var_name )
    
        Table_row_output = pd.merge(Test_table_row_weight,Test_table_row_percent,  how='left', left_on=['Row_Names','Occasions'],
                              right_on = ['Row_Names','Occasions'])
        
        Output_table=pd.DataFrame()        
        Output_table=Table_Base_output.append(Table_row_output)
        Output_table['Kye']=row_key
        Output_table=Output_table.reset_index(drop=True)        
        
        for y in range(0,len(Output_table.index)):
            Output_table['Row_Names'][y]=Output_table['Row_Names'][y].replace('Don’t','Don\'t',1)
            if (Output_table['Row_Names'][y].find('Base ') != -1):
                Output_table['Row_Names'][y]='Base'                
            else:
                continue
                
        Output_table['Distinct']=Output_table['Row_Names']+str('|')+Output_table['Occasions']
        Output_table = Output_table[['Kye','Row_Names','Occasions','Distinct','value_y','value_x']]
        Output_table.columns=['Kye','Row_Names','Occasions','Distinct','Percentage value','WEIGHTED']
        Output_Table_dict[row_key]=Output_table
        
# Finding the Row for the selection
        
        temp_1_row_value=Indent['table_row_name'][x]
        
        Parent_prefix_for_row=''
        parent_list=[]
        Parent_prefix_for_row, parent_list=find_parent_prefix(temp_1_row_value)
        
        metric_id=0
        for x in range(0,len(Tool_name_map.index)):
            if Tool_name_map['Display_Name'][x]==temp_1_row_value:
                metric_id=Tool_name_map['MetricId'][x]
            else:
                continue   

        attribute_id=0
        for x in range(0,len(Mapping_for_row_info.index)):
            if Mapping_for_row_info['MetricId'][x]==metric_id:
                attribute_id=Mapping_for_row_info['AttributetypeId'][x]
            else:
                continue 
#         print(temp_1_row_value,"_m_",metric_id,"__a_",attribute_id)

        Row_name_list=[]
        Row_name=''

        if attribute_id in [38,39,40]:
            Row_name_list=Attribute_name_map[Attribute_name_map.AttributeTypeId==attribute_id]['AttributeType']        
            Row_name=Row_name_list[Row_name_list.index[0]]
        else:
            if len(parent_list)!=0:
                Row_name=parent_list[len(parent_list)-1]    

        if Row_name=='Item':
            rows_dict[row_key]='ROW^Category/Item/Brand^Item'
            row_category_dict[row_key]=row_parent_all_row[row_key].replace('Category/Item/Brand','CATEGORY/ITEM/BRAND',1)
            row_demog_dict[row_key]='NA'
            row_5w_dict[row_key]='NA'
            
        elif Row_name=='Brand':
            rows_dict[row_key]='ROW^Category/Item/Brand^Brand'
            row_category_dict[row_key]=row_parent_all_row[row_key].replace('Category/Item/Brand','CATEGORY/ITEM/BRAND',1)            
            row_demog_dict[row_key]='NA'
            row_5w_dict[row_key]='NA'
            
        elif Row_name=='Category':
            rows_dict[row_key]='ROW^Category/Item/Brand^Category'
            row_category_dict[row_key]=row_parent_all_row[row_key].replace('Category/Item/Brand','CATEGORY/ITEM/BRAND',1)
            row_demog_dict[row_key]='NA'
            row_5w_dict[row_key]='NA'
            
        elif Row_name=='Demographics':
            rows_dict[row_key]='ROW^Demographics'
            row_category_dict[row_key]='NA'
            row_demog_dict[row_key]=row_parent_all_row[row_key].replace('Demographics','DEMOGRAPHICS',1)
            row_5w_dict[row_key]='NA'
            
            
        elif Row_name=='5Ws':
            rows_dict[row_key]='ROW^5Ws'
            row_category_dict[row_key]='NA'
            row_demog_dict[row_key]='NA'
            row_5w_dict[row_key]=row_parent_all_row[row_key]
            
        else:
            row_category_dict[row_key]='NA'
            row_demog_dict[row_key]='NA'
            row_5w_dict[row_key]='NA'
            
            
            
        #generating all the columns
        filter_for_row[row_key]=str('ADDITIONAL FILTERS^')+filter_for_row_temp        
        Column_dict[row_key]='COLUMN^Occasion'
        Row_Nesting_dict[row_key]='NA'
        Time_Period_dict[row_key]='TIME PERIOD^Quarter^Q2 2019'
        Market_dict[row_key]='MARKETS^North America^US'
        Occasions_dict[row_key]='OCCASION^Early Morning Bite|Breakfast For One|Family Breakfast|Breakfast at Work/School|Mid Morning Snack|Lunch|Lunch Alternative|Afternoon Snack|After Work/School Bite|Dinner|Dinner Alternative|Evening Me|Evening We|Bedtime/Late Night Snack'
        Benchmark_dict[row_key]='NA'
        Respondent_Type_dict[row_key]='RESPONDENT TYPE^Total'

# Selection Sheet Output

All_table_row_info=pd.DataFrame({'Column':pd.Series(Column_dict),'Rows':pd.Series(rows_dict),
                                 'Row Nesting':pd.Series(Row_Nesting_dict),'Time Period':pd.Series(Time_Period_dict),
                                 'Market':pd.Series(Market_dict),'Occasions':pd.Series(Occasions_dict),
                                 'Category/ Item/Brand':pd.Series(row_category_dict),
                                 'Demographic':pd.Series(row_demog_dict),'5ws':pd.Series(row_5w_dict),
                                 'Additional Filter':pd.Series(filter_for_row),
                                 'Benchmark':pd.Series(Benchmark_dict),
                                 'Respondent Type':pd.Series(Respondent_Type_dict)})

All_table_row_info.to_csv('All_table_row_parent_info_us_test_round_Q3.csv')

# Output Sheet output

#Storing all the tables in a single dataframe
Output_all_table=pd.DataFrame()
for key in Output_Table_dict.keys():
    Output_all_table=Output_all_table.append(Output_Table_dict[key])

#Saving the table outputs in the appended format
Output_all_table.to_csv('Output_all_table_test_round_Q3.csv')

def find_parent_prefix_test(name):    
    
    metric_id=0
    for x in range(0,len(Tool_name_map.index)):
        if Tool_name_map['Display_Name'][x]==name:
            metric_id=Tool_name_map['MetricId'][x]
            break
        else:
            continue

    row_parent_name=''
    row_parent_iid=0
    parent_list=[]
    list_default=[]

    for x in range(0,len(Mapping_for_row_info['Display_Name'])):        
        if Mapping_for_row_info['MetricId'][x]==metric_id:
            row_parent_iid=Mapping_for_row_info['ParentId'][x]
            row_parent_metric_name=Mapping_for_row_info['MetricParentName'][x]
            print(row_parent_metric_name)
            row_parent_name=Mapping_for_row_info['Display_Name'][Mapping_for_row_info['MetricName']==row_parent_metric_name].values[0]
            break
        else:
            continue

    parent_list.append(row_parent_name)  

    while(row_parent_iid!=0):
        temp_iid=Mapping_for_row_info[Mapping_for_row_info['MetricId']==row_parent_iid,'ParentId'].iloc[0]
        if temp_iid==0:
            break
        else:
            row_parent_metric_name_1=Mapping_for_row_info[Mapping_for_row_info['ParentId']==temp_iid]['MetricParentName'].iloc[0]
            row_parent_name_1=Mapping_for_row_info[Mapping_for_row_info['MetricName']==row_parent_metric_name_1]['Display_Name'].iloc[0]
        row_parent_iid=temp_iid
        
        parent_list.append(row_parent_name_1)            

    Parent_prefix=''
    for x in range(0,len(parent_list)):
        if (x==len(parent_list)-1):
                    Parent_prefix=str('Row')+str('^')+Parent_prefix
                    Parent_prefix=parent_list[x]+str('^')+Parent_prefix
        else:
            Parent_prefix=parent_list[x]+str('^')+Parent_prefix 
    return Parent_prefix , parent_list



find_parent_prefix_test('Cheez-It')

########################## Data Table##############################################

import pandas as pd
import numpy as np

msa = (
    pd.read_excel(
        "./Source Data/COL_extracted_31 July 2019.xlsx",
        sheet_name="Sheet1",
    )
    .dropna(subset=["MSA Code"])
    .assign(CBSA=lambda x: x['MSA Code'].astype('int'))
    .drop(['Name of area, COL Index Data', 'MSA Code', 'MSA DESCRIPTION'], axis=1)
    .set_index('CBSA')
    .div(100)
    .reset_index()
)

msa.head()

#read in Zip Code CBSA mapping file
zcta = pd.read_csv('Source Data/zcta_cbsa_rel_10.txt', usecols=['ZCTA5', 'CBSA'])

zcta.head()

col_by_zipcode = pd.merge(zcta, msa, on='CBSA').rename(mapper={'ZCTA5':'Zipcode'}, axis=1)

col_by_zipcode.head()

cbl = pd.read_excel('Source Data/CBL Respondent Data.xlsx', sheet_name='Variables')

cbl.head()

output = pd.merge(cbl, col_by_zipcode, on='Zipcode')

output['Income'] = output['Income'].map({1:12500, 2:37500, 3:62500, 4:87500, 5:125000})

output.head()

#output.to_excel('output.xlsx')

output.to_csv('output.csv')

############################### Tree 2 #############################################

import numpy as np 
import pandas as pd 
from sklearn.metrics import confusion_matrix 
from sklearn.cross_validation import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report

# import os
# os.getcwd()

# Function importing Dataset 
def importdata(): 
    
    Tree_data_15 = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\USA_DT\\Vikas_USA_2015.xlsx",sheet_name="Sheet1"))
    Tree_data_16 = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\USA_DT\\Vikas_USA_2016.xlsx",sheet_name="Sheet1"))
    Tree_data_17 = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\USA_DT\\Vikas_USA_2017.xlsx",sheet_name="Sheet1"))
      
    frames = [Tree_data_15, Tree_data_16, Tree_data_17]

    Tree_data = pd.concat(frames)
    
    # Printing the dataswet shape 
    print ("Dataset Length: ", len(Tree_data)) 
    print ("Dataset Shape: ", Tree_data.shape) 
      
    # Printing the dataset obseravtions 
    print ("Dataset: ",Tree_data.head()) 
    return Tree_data 

# data.columns[data.isnull().any()].tolist()
# y=dict()
# for x in columns:
#     y[x]=data[x].isnull().sum(axis = 0)

#sorted(y.items(), key=lambda x:x[1])
#data.info()
#data.isnull().sum()
# len(data.index)-data.count()
# z=y.index.tolist()
# for x in range(len(y)):
#     if y[x]==0:
#         continue
#     else:
#         print(z[x],y[x])

# data[data['OccasionID']==614049]['Trademark']

# data = data.applymap(lambda x: x.strip() if isinstance(x, str) else x)

# Function to split the dataset 
def splitdataset(Tree_data): 
  
    # Seperating the target variable 
    X = Tree_data['Category'] 
    Y = Tree_data.drop(columns=['Category','RespId','OccasionID'])
  
    # Spliting the dataset into train and test 
    X_train, X_test, y_train, y_test = train_test_split(  
    X, Y, test_size = 0.3, random_state = 100) 
      
    return X, Y, X_train, X_test, y_train, y_test

# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def tarin_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy 

# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred)) 

# Driver code 
def main(): 
      
    # Building Phase 
    data = importdata() 
    X, Y, X_train, X_test, y_train, y_test = splitdataset(data) 
    clf_gini = train_using_gini(X_train, X_test, y_train) 
    clf_entropy = tarin_using_entropy(X_train, X_test, y_train) 
      
    # Operational Phase 
    print("Results Using Gini Index:") 
      
    # Prediction using gini 
    y_pred_gini = prediction(X_test, clf_gini) 
    cal_accuracy(y_test, y_pred_gini) 
      
    print("Results Using Entropy:") 
    # Prediction using entropy 
    y_pred_entropy = prediction(X_test, clf_entropy) 
    cal_accuracy(y_test, y_pred_entropy) 
      
      
# Calling main function 
if __name__=="__main__":main() 

# data['Category'],class_names = pd.factorize(data['Category'])

#print(class_names)

# list_all=data.columns.tolist()

# a=['OccasionID','RespId','Category','AUC','Booster_Wt','RetailValue']

# for x in a:
#     list_all.remove(x)
   

# print(len(list_all))

# for x in list_all:
#     data[x],_ = pd.factorize(data[x])

data.head()

############################ Catboost ##############################################

import numpy as np 
import pandas as pd 
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report

from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

# Function importing Dataset 
def importdata(): 
    
    #Tree_data_15 = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\USA_DT\\Vikas_USA_2015.xlsx",sheet_name="Sheet1"))
#     Tree_data_16 = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\USA_DT\\Vikas_USA_2016.xlsx",sheet_name="Sheet1"))
    Tree_data_17 = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\USA_DT\\Vikas_USA_2017.xlsx",sheet_name="Sheet1"))
      
    frames = [ Tree_data_17]

    Tree_data = pd.concat(frames)
    
    # Printing the dataswet shape 
    print ("Dataset Length: ", len(Tree_data)) 
    print ("Dataset Shape: ", Tree_data.shape) 
      
    # Printing the dataset obseravtions 
    print ("Dataset: ",Tree_data.head()) 
    return Tree_data

data = importdata()

categorical_features=data.columns.tolist()

not_for_tree= ['AUC', 'Area_Type', 'Booster_Wt', 'Brands', 'Category','City', 'CommercialType','Consumption_Type', 'Container_size', 'Flavour', 
                  'Global_DM','HH_Size', 'Local_DM', 'Motivation', 'OccasionID', 'Occasion_IsFood', 'Occasion_IsHome', 
                  'Occasion_Net', 'Occasion_Subnet','PackType', 'Pur_location', 'RespId', 'RetailValue', 'SEL', 'Shopper', 
                  'TCCC', 'Trademarks', 'Weekday_Weekend','Year']

for x in not_for_tree:
    categorical_features.remove(x)

len(categorical_features)

Y=data['Category']
X=data[categorical_features]
Y.shape , X.shape

X = X.astype(str)
Y = Y.astype(str)

encoded_x = pd.get_dummies(X, columns=['Gender', 'Region', 'Marital_Status', 'Emp_status', 
                                       'Education', 'Race','Location_Consumed', 'Activity_Net', 'Day_Part',
                                       'Day', 'Purify or cleanse my body', 'Wake me up',
                                       'Help me grow stronger and healthier', 'Reward or indulge myself',
                                       'Quench my thirst', 'Ensure I drink enough each day',
                                       'Help me unwind or relax', 'Go well with my food',
                                       'Make me Feel Healthy', 'Renew my energy', 'Give me a flavor I enjoy',
                                       'Give my body the nutrients that it needs', 'Celebrate with others',
                                       'Help me stay in shape', 'Keep up with my regular routine',
                                       'Wash down food', 'Replenish lost fluids', 'Refresh me mentally',
                                       'Comfort me', 'Age_Group'], 
        prefix = ['Gender', 'Region', 'Marital_Status', 'Emp_status', 'Education', 'Race', 'Location_Consumed', 
                  'Activity_Net', 'Day_Part', 'Day', 'Purify_or_cleanse_my_body', 'Wake_me_up',
                  'Help_me_grow_stronger_and_healthier', 'Reward_or_indulge_myself', 'Quench_my_thirst',
                  'Ensure_I_drink_enough_each_day', 'Help_me_unwind_or_relax', 'Go_well_with_my_food',
                  'Make_me_Feel_Healthy', 'Renew_my_energy', 'Give_me_a_flavor_I_enjoy', 
                  'Give_my_body_the_nutrients_that_it_needs','Celebrate_with_others', 'Help_me_stay_in_shape',
                  'Keep_up_with_my_regular_routine', 'Wash_down_food','Replenish_lost_fluids','Refresh_me_mentally',
                  'Comfort_me','Age_Group'])

print(encoded_x.shape)

label_encoder = LabelEncoder()
label_encoder = label_encoder.fit(Y)
label_encoded_y = label_encoder.transform(Y)

seed = 7
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(encoded_x, label_encoded_y, test_size=test_size, random_state=seed)
# fit model no training data
# model = XGBClassifier()

# # Saving feature names for later use
feature_list = list(encoded_x.columns)
# # Convert to numpy array
# encoded_x_features = np.array(encoded_x)
# label_encoded_y_feature = np.array(label_encoded_y)

import catboost as cb
from catboost import CatBoostRegressor

model=CatBoostRegressor(iterations=1000, depth=3, learning_rate=0.1, loss_function='RMSE')
%time result=model.fit(X_train, y_train,cat_features=feature_list,eval_set=(X_test, y_test))

y_pred=model.predict(X_test)
predictions = [round(value) for value in y_pred]
# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

# Get numerical feature importances
importances = list(result.feature_importances_)
# List of tuples with variable and importance
feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]
# Sort the feature importances by most important first
feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)
# Print out the feature and importances 
[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]

model.get_feature_names()

preds_proba = model.predict_proba(X_test)

################################# Random Forest ############################################

import numpy as np 
import pandas as pd 
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report

from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

# Function importing Dataset 
def importdata(): 
    
    #Tree_data_15 = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\USA_DT\\Vikas_USA_2015.xlsx",sheet_name="Sheet1"))
#     Tree_data_16 = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\USA_DT\\Vikas_USA_2016.xlsx",sheet_name="Sheet1"))
    Tree_data_17 = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\USA_DT\\Vikas_USA_2017.xlsx",sheet_name="Sheet1"))
      
    frames = [ Tree_data_17]

    Tree_data = pd.concat(frames)
    
    # Printing the dataswet shape 
    print ("Dataset Length: ", len(Tree_data)) 
    print ("Dataset Shape: ", Tree_data.shape) 
      
    # Printing the dataset obseravtions 
#     print ("Dataset: ",Tree_data.head()) 
    return Tree_data

data = importdata()

data_sample_1 = data.sample(frac=0.2,random_state =9)
print(data_sample_1.shape)

month_data=pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\USA_DT\\Month_dummyd.xlsx",sheet_name="Month_dummyd"))

month_data_time=month_data[['OccasionID','WaveDummy','QuarterDummy']]
data_sample_1=pd.merge(data_sample_1,month_data_time, on =['OccasionID'])
data_sample_1.head()
# data_sample_1['Area_Type'].unique()

data_sample_1['WaveDummy']=data_sample_1['WaveDummy'].map({28:'January',29:'February',30:'March',31:'April',32:'May',
                                                           33:'June',34:'July',35:'August',36:'September',37:'October',
                                                           38:'November',39:'December'})
data_sample_1['QuarterDummy']=data_sample_1['QuarterDummy'].map({10:'Q1',11:'Q2',12:'Q3',13:'Q4'})

print(data_sample_1['WaveDummy'].unique())
print(data_sample_1['QuarterDummy'].unique())

col_map=data_sample_1.columns.tolist()
col_map_1=[]
for x in col_map:
    y=x.replace(" ","_")
    col_map_1.append(y)
# print(col_map_1)
data_sample_1.columns=col_map_1
print(data_sample_1.columns)

categorical_features=data_sample_1.columns.tolist()

not_for_tree= ['AUC', 'Area_Type', 'Booster_Wt', 'Brands', 'Category','City', 'CommercialType','Consumption_Type', 'Container_size', 'Flavour', 
                  'Global_DM','HH_Size', 'Local_DM', 'Motivation', 'OccasionID', 'Occasion_IsFood', 'Occasion_IsHome', 
                  'Occasion_Net', 'Occasion_Subnet','PackType', 'Pur_location', 'RespId', 'RetailValue', 'SEL', 'Shopper', 
                  'TCCC', 'Trademarks', 'Weekday_Weekend','Year','QuarterDummy']

for x in not_for_tree:
    categorical_features.remove(x)

len(categorical_features)

Y=data_sample_1['Category']
X=data_sample_1[categorical_features]
       
X = X.astype(str)
Y = Y.astype(str)

Y.shape , X.shape

X.columns

encoded_x = pd.get_dummies(X, columns=['Gender', 'Region', 'Marital_Status', 'Emp_status', 'Education', 'Race',
                                       'Location_Consumed', 'Activity_Net', 'Day_Part', 'Day',
                                       'Purify_or_cleanse_my_body', 'Wake_me_up',
                                       'Help_me_grow_stronger_and_healthier', 'Reward_or_indulge_myself',
                                       'Quench_my_thirst', 'Ensure_I_drink_enough_each_day',
                                       'Help_me_unwind_or_relax', 'Go_well_with_my_food',
                                       'Make_me_Feel_Healthy', 'Renew_my_energy', 'Give_me_a_flavor_I_enjoy',
                                       'Give_my_body_the_nutrients_that_it_needs', 'Celebrate_with_others',
                                       'Help_me_stay_in_shape', 'Keep_up_with_my_regular_routine',
                                       'Wash_down_food', 'Replenish_lost_fluids', 'Refresh_me_mentally',
                                       'Comfort_me', 'Age_Group', 'WaveDummy'], 
        prefix = ['Gender', 'Region', 'Marital_Status', 'Emp_status', 'Education', 'Race',
                   'Location_Consumed', 'Activity_Net', 'Day_Part', 'Day',
                   'Purify_or_cleanse_my_body', 'Wake_me_up',
                   'Help_me_grow_stronger_and_healthier', 'Reward_or_indulge_myself',
                   'Quench_my_thirst', 'Ensure_I_drink_enough_each_day',
                   'Help_me_unwind_or_relax', 'Go_well_with_my_food',
                   'Make_me_Feel_Healthy', 'Renew_my_energy', 'Give_me_a_flavor_I_enjoy',
                   'Give_my_body_the_nutrients_that_it_needs', 'Celebrate_with_others',
                   'Help_me_stay_in_shape', 'Keep_up_with_my_regular_routine',
                   'Wash_down_food', 'Replenish_lost_fluids', 'Refresh_me_mentally',
                   'Comfort_me', 'Age_Group', 'WaveDummy'])
print(encoded_x.shape)

encoded_y=pd.DataFrame()
label_encoder = LabelEncoder()
label_encoder = label_encoder.fit(Y)
encoded_y['Category'] = label_encoder.transform(Y)

# Saving feature names for later use
feature_list = list(encoded_x.columns)
# # Convert to numpy array
# encoded_x_features = np.array(encoded_x)
# label_encoded_y_feature = np.array(label_encoded_y)

seed = 7
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(encoded_x, encoded_y, test_size=test_size, random_state=seed)

# Import the model
from sklearn.ensemble import RandomForestRegressor
# Instantiate model with 1000 decision trees
rf = RandomForestRegressor(n_estimators = 200, random_state = 42)
# Train the model on training data
# %time result=rf.fit(X_train, y_train)

from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
from sklearn.metrics import roc_auc_score

param_grid = { 
                'n_estimators':  [50, 100, 200,300,400,500],
                 'max_depth' : [5, 10, 20],
                'min_samples_leaf': [1, 2, 3, 4, 5, 10, 20]
              }


CV_rf = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)

CV_rf.fit(X_train, y_train)

# CV_rf.best_params_

# rfc1=RandomForestClassifier(random_state=42,  n_estimators= 50, max_depth=5, criterion='gini')
# rfc1.fit(X_train, y_train)





from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

CV_rf

rf_predictions = CV_rf.predict(X_test)

# Probabilities for each class
from sklearn.metrics import accuracy_score
accuracy_score(y_test, rf_predictions.round())

from sklearn.metrics import confusion_matrix
conf_mat = confusion_matrix(y_test, rf_predictions.round())
# print(conf_mat)
# Visualize it as a heatmap
import seaborn
seaborn.heatmap(conf_mat)

rf_predictions.round() ,y_test

# # Get numerical feature importances
# importances = list(rf.feature_importances_)
# # List of tuples with variable and importance
# feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]
# # Sort the feature importances by most important first
# feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)
# # Print out the feature and importances 
# [print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]


# from sklearn import tree
# tree.export_graphviz(rf.estimators_[0], out_file='tree_from_forest.dot')
# (graph,) = pydot.graph_from_dot_file('tree_from_forest.dot')
# graph.write_png('tree_from_forest.png')

CV_rf.best_params_

import lime
import lime.lime_tabular

import lightgbm as lgb

lgb_params = {
    'task': 'train',
    'num_class' : 17,
    'boosting_type': 'goss',
    'objective': 'multiclass',
    'metric':'multi_logloss',    
    'num_leaves': 50,
    'learning_rate': 0.1,
    'feature_fraction': 0.8,
    'bagging_fraction': 0.8,
    'verbose': None,
    'num_iteration':100,
    'num_threads':7,
    'max_depth':12,
    'min_data_in_leaf':100,
    'alpha':0.5}

# def lgb_model(X_train,y_train,X_test,y_test,lgb_params):
# create dataset for lightgbm
lgb_train = lgb.Dataset(X_train, y_train)
lgb_eval = lgb.Dataset(X_test, y_test)

X_test.shape, y_test.shape

len(y_train['Category'].unique())

# training the lightgbm model
model = lgb.train(lgb_params,lgb_train,num_boost_round=20,valid_sets=lgb_eval,early_stopping_rounds=5)

# this is required as LIME requires class probabilities in case of classification example
# LightGBM directly returns probability for class 1 by default 

def prob(data):
    return np.array(list(zip(1-model.predict(data).flatten(),model.predict(data).flatten())))

# model.predict(encoded_x.loc[1][feature_list].astype(int).values)

xplainer = lime.lime_tabular.LimeTabularExplainer(encoded_x[feature_list].astype(int).values,  
mode='classification',training_labels=encoded_y['Category'],feature_names=model.feature_name())

# asking for explanation for LIME model
i = 1
# exp = xplainer.explain_instance(encoded_x.loc[i,feature_list].astype(int).values,prob)

y_pred_lgbm=model.predict(X_test).round()

y_pred_lgbm

accuracy_score(y_test['Category'], y_pred_lgbm)

########################## XGB ############################################

import numpy as np 
import pandas as pd 
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report

from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

# Function importing Dataset 
def importdata(): 
    
    #Tree_data_15 = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\USA_DT\\Vikas_USA_2015.xlsx",sheet_name="Sheet1"))
#     Tree_data_16 = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\USA_DT\\Vikas_USA_2016.xlsx",sheet_name="Sheet1"))
    Tree_data_17 = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\USA_DT\\Vikas_USA_2017.xlsx",sheet_name="Sheet1"))
      
    frames = [ Tree_data_17]

    Tree_data = pd.concat(frames)
    
    # Printing the dataswet shape 
    print ("Dataset Length: ", len(Tree_data)) 
    print ("Dataset Shape: ", Tree_data.shape) 
      
    # Printing the dataset obseravtions 
#     print ("Dataset: ",Tree_data.head()) 
    return Tree_data

data = importdata()

data_sample_1 = data.sample(frac=0.2,random_state =7)
print(data_sample_1.shape)

month_data=pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\USA_DT\\Month_dummyd.xlsx",sheet_name="Month_dummyd"))

month_data_time=month_data[['OccasionID','WaveDummy','QuarterDummy']]
data_sample_1=pd.merge(data_sample_1,month_data_time, on =['OccasionID'])
data_sample_1.head()
# data_sample_1['Area_Type'].unique()

data_sample_1['WaveDummy']=data_sample_1['WaveDummy'].map({28:'January',29:'February',30:'March',31:'April',32:'May',
                                                           33:'June',34:'July',35:'August',36:'September',37:'October',
                                                           38:'November',39:'December'})
data_sample_1['QuarterDummy']=data_sample_1['QuarterDummy'].map({10:'Q1',11:'Q2',12:'Q3',13:'Q4'})

print(data_sample_1['WaveDummy'].unique())
print(data_sample_1['QuarterDummy'].unique())

col_map=data_sample_1.columns.tolist()
col_map_1=[]
for x in col_map:
    y=x.replace(" ","_")
    col_map_1.append(y)
# print(col_map_1)
data_sample_1.columns=col_map_1
print(data_sample_1.columns)

data_sample_1=data_sample_1.replace(" ","_")

categorical_features=data_sample_1.columns.tolist()

not_for_tree= ['AUC','Booster_Wt', 'Brands', 'Category', 'CommercialType','Consumption_Type', 'Container_size', 'Flavour', 
                  'Global_DM','HH_Size', 'Local_DM', 'Motivation', 'OccasionID', 'Occasion_IsFood', 'Occasion_IsHome', 
                  'Occasion_Net', 'Occasion_Subnet','PackType', 'Pur_location', 'RespId', 'RetailValue', 'Shopper', 
                  'TCCC', 'Trademarks', 'Weekday_Weekend','Year']
for x in not_for_tree:
    categorical_features.remove(x)

print(categorical_features,len(categorical_features))

# encode string class values as integers
label_encoded_data_sample_x=pd.DataFrame()

for x in categorical_features:
                label_encoder = LabelEncoder()
                label_encoder = label_encoder.fit(data_sample_1[x])
                label_encoded_data_sample_x[x] = label_encoder.transform(data_sample_1[x])
    
# # # Saving feature names for later use
feature_list_incoded = list(label_encoded_data_sample_x.columns)
# print(feature_list)
len(label_encoded_data_sample_x.columns)

label_encoded_data_sample_y=pd.DataFrame()
label_encoder = LabelEncoder()
label_encoder = label_encoder.fit(data_sample_1['Category'])
label_encoded_data_sample_y['Category'] = label_encoder.transform(data_sample_1['Category'])

label_encoded_data_sample_x.columns

import math
from collections import Counter
import seaborn as sns
import pandas as pd
import scipy.stats as ss
import matplotlib.pyplot as plt
import sklearn.preprocessing as sp


def conditional_entropy(x,y):
    # entropy of x given y
    y_counter = Counter(y)
    xy_counter = Counter(list(zip(x,y)))
    total_occurrences = sum(y_counter.values())
    entropy = 0
    for xy in xy_counter.keys():
        p_xy = xy_counter[xy] / total_occurrences
        p_y = y_counter[xy[1]] / total_occurrences
        entropy += p_xy * math.log(p_y/p_xy)
    return entropy

def theil_u(x,y):
    s_xy = conditional_entropy(x,y)
    x_counter = Counter(x)
    total_occurrences = sum(x_counter.values())
    p_x = list(map(lambda n: n/total_occurrences, x_counter.values()))
    s_x = ss.entropy(p_x)
    if s_x == 0:
        return 1
    else:
        return (s_x - s_xy) / s_x

theilu = pd.DataFrame(index=label_encoded_data_sample_x.columns,columns=label_encoded_data_sample_x.columns)
columns = label_encoded_data_sample_x.columns

for x in columns:
    for j in range(0,len(columns)):
            u = theil_u(label_encoded_data_sample_x[x].tolist(),label_encoded_data_sample_x[columns[j]].tolist())
            theilu.loc[[x],columns[j]] = u

theilu.fillna(value=np.nan,inplace=True)
plt.figure(figsize=(30,30))
sns.heatmap(theilu,annot=True,fmt='.2f')
plt.show()

# # theilu
# y_counter = Counter(list(zip(label_encoded_data_sample_x['Emp_status'],label_encoded_data_sample_x['City'])))
# print(y_counter)
theilu_y = pd.DataFrame(index=['Category'],columns=label_encoded_data_sample_x.columns)
columns = label_encoded_data_sample_x.columns


for j in range(0,len(columns)):
        u = theil_u(label_encoded_data_sample_x[columns[j]].tolist(),label_encoded_data_sample_y['Category'].tolist())
        theilu_y.loc[:,columns[j]] = u

            
theilu_y.to_csv('theilu_y.csv')            
theilu_y.fillna(value=np.nan,inplace=True)
plt.figure(figsize=(30,1))
sns.heatmap(theilu_y,annot=True,fmt='.2f')
plt.show()

# theilu.to_csv(header=True)
# theilu.to_csv('theilu.csv')

encoded_x = pd.get_dummies(data_sample_1[categorical_features], columns=['Gender', 'Region', 'Marital_Status', 'SEL', 'Emp_status', 'Education', 'Race', 'Location_Consumed', 'Activity_Net', 'Day_Part', 'Day', 'Purify_or_cleanse_my_body', 'Wake_me_up', 'Help_me_grow_stronger_and_healthier', 'Reward_or_indulge_myself', 'Quench_my_thirst', 'Ensure_I_drink_enough_each_day', 'Help_me_unwind_or_relax', 'Go_well_with_my_food', 'Make_me_Feel_Healthy', 'Renew_my_energy', 'Give_me_a_flavor_I_enjoy', 'Give_my_body_the_nutrients_that_it_needs', 'Celebrate_with_others', 'Help_me_stay_in_shape', 'Keep_up_with_my_regular_routine', 'Wash_down_food', 'Replenish_lost_fluids', 'Refresh_me_mentally', 'Comfort_me', 'Area_Type', 'City', 'Age_Group', 'WaveDummy', 'QuarterDummy'], 
                                          prefix = ['Gender', 'Region', 'Marital_Status', 'SEL', 'Emp_status', 'Education', 'Race', 'Location_Consumed', 'Activity_Net', 'Day_Part', 'Day', 'Purify_or_cleanse_my_body', 'Wake_me_up', 'Help_me_grow_stronger_and_healthier', 'Reward_or_indulge_myself', 'Quench_my_thirst', 'Ensure_I_drink_enough_each_day', 'Help_me_unwind_or_relax', 'Go_well_with_my_food', 'Make_me_Feel_Healthy', 'Renew_my_energy', 'Give_me_a_flavor_I_enjoy', 'Give_my_body_the_nutrients_that_it_needs', 'Celebrate_with_others', 'Help_me_stay_in_shape', 'Keep_up_with_my_regular_routine', 'Wash_down_food', 'Replenish_lost_fluids', 'Refresh_me_mentally', 'Comfort_me', 'Area_Type', 'City', 'Age_Group', 'WaveDummy', 'QuarterDummy'])
print(encoded_x.shape)

feature_list=encoded_x.columns.tolist()

encoded_y=pd.DataFrame()

label_encoder = LabelEncoder()
label_encoder = label_encoder.fit(data_sample_1['Category'])
encoded_y['Category'] = label_encoder.transform(data_sample_1['Category'])

seed = 7
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(encoded_x, encoded_y, test_size=test_size, random_state=seed)
# fit model no training data
# model = XGBClassifier(max_depth=10,n_estimators=200)
# model.fit(X_train, y_train)
# print(model)
# # make predictions for test data
# y_pred = model.predict(X_test)
# predictions = [round(value) for value in y_pred]
# # evaluate predictions
# accuracy = accuracy_score(y_test, predictions)
# print("Accuracy: %.2f%%" % (accuracy * 100.0))

X_train.shape, X_test.shape, y_train.shape, y_test.shape

import xgboost as xgb

# X_train_mat = xgb.DMatrix(X_train,lable=y_train,feature_names=X_train.columns.tolist())
# X_test_mat = xgb.DMatrix(X_test,lable=y_test,feature_names=X_test.columns.tolist())

# y_train_mat = xgb.DMatrix(y_train,feature_names=y_train.columns.tolist())
# y_test_mat = xgb.DMatrix(y_test,feature_names=y_test.columns.tolist())

X_train_mat?

# model = XGBClassifier()
# # eval_set = [(X_train_mat, y_train_mat),(X_test_mat, y_test_mat)]
# # eval_metric = ["mlogloss","merror"]
# %time results= model.fit(X_train, y_train, verbose=False)

results

# A parameter grid for XGBoost
params = {
        'min_child_weight': [1, 5, 10],
        'gamma': [0.5, 1, 1.5, 2, 5],
        
        'colsample_bytree': [0.6, 0.8, 1.0],
        'max_depth': [3, 4, 5]
        }

xgb_model = XGBClassifier(learning_rate=0.01, n_estimators=200,silent=True, objective='multi:softprob', nthread=1)

from datetime import datetime
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
from sklearn.metrics import roc_auc_score
# from sklearn.model_selection import StratifiedKFold

folds = 5
param_comb = 5

skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)
random_search = RandomizedSearchCV(xgb_model, param_distributions=params, n_iter=param_comb, n_jobs=4, 
                                   cv=skf.split(X_train,y_train), verbose=0, random_state=101 )
%time result_random_search=random_search.fit(X_train, y_train)

result_random_search

result_random_search.best_params_

y_pred = model.predict(X_test)
predictions = [round(value) for value in y_pred]
# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

results_1 = result_random_search.e
# print(results)

from matplotlib import pyplot
import matplotlib.pyplot as plt


fig, ax = pyplot.subplots(figsize=(12,12))
epochs = len(results_1['validation_0']['merror'])
x_axis = range(0, epochs)
ax.plot(x_axis, results_1['validation_0']['merror'], label='Train')
ax.plot(x_axis, results_1['validation_1']['merror'], label='Test')
ax.legend()

pyplot.ylabel('Classification Error')
pyplot.title('XGBoost Classification Error')
pyplot.show()

ax.plot()
pyplot.show()

pyplot.bar(range(len(results.feature_importances_)), results.feature_importances_)



# fig, ax = pyplot.subplots(figsize=(12,12))
# epochs = len(results_1['validation_0']['merror'])
# x_axis = range(0, epochs)
# ax.plot(x_axis, results_1['validation_0']['merror'], label='Train')
# ax.plot(x_axis, results_1['validation_1']['merror'], label='Test')
# ax.legend()

# pyplot.ylabel('Classification Error')
# pyplot.title('XGBoost Classification Error')
pyplot.show()

# ax.plot()
# pyplot.show()

from xgboost import plot_importance

import matplotlib.pyplot as plt

plt.rcParams["figure.figsize"] = (22, 30)

plot_importance(model)
pyplot.show()

import os
os.environ["PATH"] += os.pathsep+'C:/Users/10920/AppData/Local/Continuum/anaconda3/Library/bin/graphviz/'

from xgboost import plot_tree


fig, ax = plt.subplots(figsize=(50, 20))

plot_tree(model,ax=ax)
plt.show()

results

fig = plt.figure(figsize = (20, 20))
title = fig.suptitle("Native Feature Importances from XGBoost", fontsize=14)

ax1 = fig.add_subplot(2, 2, 1)
plot_importance(model, importance_type='weight', ax=ax1, color='red')
ax1.set_title("Feature Importance with Feature Weight");

ax2 = fig.add_subplot(2, 2, 2)
plot_importance(model, importance_type='cover', ax=ax2, color='red')
ax2.set_title("Feature Importance with Sample Coverage");

ax3 = fig.add_subplot(2, 2, 3)
plot_importance(model, importance_type='gain', ax=ax3, color='red')
ax3.set_title("Feature Importance with Split Mean Gain");

import eli5
from eli5.sklearn import PermutationImportance

eli5.show_weights(model.get_booster())

print('Reference:', y_test[115])
print('Predicted:', y_pred[115])
eli5.show_prediction(model.get_booster(), X_test[115],feature_names=feature_list, show_feature_values=True)

A=[Y,label_encoded_y]

mylist = list(dict.fromkeys(label_encoded_y))
print(mylist)

Y.unique()

feature_input_list=['f0','f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14','f15','f16','f17','f18',
                    'f19','f20','f21','f22','f23','f24','f25','f26','f27','f28','f29','f30','f31','f32','f33','f34','f35','f36',
                    'f37','f38','f39','f40','f41','f42','f43','f44','f45','f46','f47','f48','f49','f50','f51','f52','f53',
                    'f54','f55','f56','f57','f58','f59','f60','f61','f62','f63','f64','f65','f66','f67','f68','f69',
                    'f70','f71','f72','f73','f74','f75','f76','f77','f78','f79','f80','f81','f82','f83','f84','f85','f86',
                    'f87','f88','f89','f90','f91','f92','f93','f94','f95','f96','f97','f98','f99','f100','f101','f102',
                    'f103','f104','f105','f106','f107','f108','f109','f110','f111','f112','f113','f114','f115','f116',
                    'f117','f118','f119','f120','f121','f122','f123','f124','f125','f126','f127','f128','f129','f130',
                    'f131','f132','f133','f134','f135','f136','f137','f138','f139','f140','f141','f142','f143','f144',
                    'f145','f146','f147','f148','f149','f150','f151','f152','f153','f154','f155','f156','f157','f158',
                    'f159','f160','f161','f162','f163','f164','f165','f166','f167','f168','f169','f170','f171','f172',
                    'f173','f174','f175','f176','f177','f178','f179','f180','f181','f182','f183','f184','f185','f186',
                    'f187','f188','f189','f190']                    

X_test_df=pd.DataFrame(X_test,columns=feature_input_list)

# pip install pdpbox
from pdpbox import pdp, get_dataset, info_plots

def plot_pdp(model, df, feature, cluster_flag=False, nb_clusters=None, lines_flag=False):
    
    # Create the data that we will plot
    pdp_goals = pdp.pdp_isolate(model=model, dataset=df, model_features=df.columns.tolist(), feature=feature)

    # plot it
    pdp.pdp_plot(pdp_goals, feature, cluster=cluster_flag, n_cluster_centers=nb_clusters, plot_lines=lines_flag)
    plt.show()

# plot the PD univariate plot
plot_pdp(model,X_test_df,'f177')

from skater.core.explanations import Interpretation
from skater.model import InMemoryModel

# A reminder for referencing the originals feature names 
# since these names are not kept in the surrogate tree
l=pd.DataFrame([('f'+str(idx), feature) for (idx, feature) in enumerate(feature_list)])
# for i in range(0,190):
print(l[1][159])

from eli5 import show_weights
weight=show_weights(model)
weight?

eli5.show_prediction(model,X_test_df.iloc[[115]],show_feature_values=True,feature_names=feature_list)



# # Save the best model to disk so you can use it again whenever you like (e.g. in another notebook etc)
# import pickle
# filename = 'final_model.sav'
# pickle.dump(best_rf, open(filename, 'wb'))
  
# # This is how you would load the model again
# model = pickle.load(open(filename, 'rb'))

Sample_table_1 = pd.DataFrame(pd.read_excel("C:\\Users\\10920\\Desktop\\USA_DT\\check_trail_1.xlsx",sheet_name="Sheet1"))

# Sample_table_1

for rows in Sample_table_1.iterrows():
    if pd.isnull(Sample_table_1.loc[[rows],[1]])
    print(Sample_table_1.loc[[rows],[0]])

############################## XGB 2 #####################################

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Check this gist for xgboost wrapper: https://gist.github.com/slaypni/b95cb69fd1c82ca4c2ff
 
import sys
import math
 
import numpy as np
from datetime import datetime
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import StratifiedKFold
 
sys.path.append('xgboost/wrapper/')
import xgboost as xgb

class XGBoostClassifier():
    def __init__(self, num_boost_round=10, **params):
        self.clf = None
        self.num_boost_round = num_boost_round
        self.params = params
        self.params.update({'objective': 'multi:softprob'})
 
    def fit(self, X, y, num_boost_round=None):
        num_boost_round = num_boost_round or self.num_boost_round
        self.label2num = {label: i for i, label in enumerate(sorted(set(y)))}
        dtrain = xgb.DMatrix(X, label=[self.label2num[label] for label in y])
        self.clf = xgb.train(params=self.params, dtrain=dtrain, num_boost_round=num_boost_round)
 
    def predict(self, X):
        num2label = {i: label for label, i in self.label2num.items()}
        Y = self.predict_proba(X)
        y = np.argmax(Y, axis=1)
        return np.array([num2label[i] for i in y])
 
    def predict_proba(self, X):
        dtest = xgb.DMatrix(X)
        return self.clf.predict(dtest)
 
    def score(self, X, y):
        Y = self.predict_proba(X)
        return 1 / logloss(y, Y)
 
    def get_params(self, deep=True):
        return self.params
 
    def set_params(self, **params):
        if 'num_boost_round' in params:
            self.num_boost_round = params.pop('num_boost_round')
        if 'objective' in params:
            del params['objective']
        self.params.update(params)
        return self


def logloss(y_true, Y_pred):
    label2num = dict((name, i) for i, name in enumerate(sorted(set(y_true))))
    return -1 * sum(math.log(y[label2num[label]]) if y[label2num[label]] > 0 else -np.inf for y, label in zip(Y_pred, y_true)) / len(Y_pred)

def main():
    clf = XGBoostClassifier(
        eval_metric = 'auc',
        num_class = 2,
        nthread = 4,
        silent = 1,
        )
    parameters = {
        'num_boost_round': [100, 250, 500],
        'eta': [0.05, 0.1, 0.3],
        'max_depth': [6, 9, 12],
        'subsample': [0.9, 1.0],
        'colsample_bytree': [0.9, 1.0],
    }
    clf = GridSearchCV(clf, parameters, n_jobs=1, cv=2)
    
    clf.fit([[1,2], [3,4], [2,1], [4,3], [1,0], [4,5]], ['a', 'b', 'a', 'b', 'a', 'b'])
#     best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])
#     print('score:', score)
#     for param_name in sorted(best_parameters.keys()):
#         print("%s: %r" % (param_name, best_parameters[param_name]))
#     print('predicted:', clf.predict([[1,1]]))


if __name__ == '__main__':
    main()

################################## Charts ##############################################

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.sankey import Sankey
import seaborn as sns

#load in some example data and rename
tips = sns.load_dataset("tips")

tips['KOhort'] = tips['day'].map({'Sun':'Survivors', 'Sat':'Aspirers', 
                                 'Thur':'Givers', 'Fri':'Providers'})
tips['KOhort Percentage'] = tips['KOhort']

tips.loc[
    (tips["sex"] == "Female") & (tips["time"] == "Dinner"),
    "KOhort Percentage",
] = "Survivors"
tips.loc[
    (tips["sex"] == "Female") & (tips["time"] == "Lunch"),
    "KOhort Percentage",
] = "Aspirers"
tips.loc[
    (tips["sex"] == "Male") & (tips["time"] == "Dinner"),
    "KOhort Percentage",
] = "Givers"
tips.loc[
    (tips["sex"] == "Male") & (tips["time"] == "Lunch"),
    "KOhort Percentage",
] = "Providers"
tips['Percentage of Sample'] = tips['total_bill']

df = tips

df

# first graph to explore where the cutoffs are
g = sns.FacetGrid(
    df, col="KOhort Percentage", row="KOhort"
)
g = (
    g.map(plt.hist, "total_bill")
    .set_titles(
        row_template="{row_name}", col_template="{col_name}"
    )
    .set_ylabels("% Sample")
    .set_xlabels("% Probability")
)
g.savefig('histogram.svg')

# second graph to show from where an enlarged group would source from
KOhorts = [
    "Survivors",
    "Aspirers",
    "Givers",
    "Providers",
    "Age-Defiers",
    "Change Makers",
    "Seekers",
    "Givers +"
]

KOhort_flows = np.array([0.03, 0.02, 0.8, 0.01, 0.1, 0.07, 0.1])

KOhort_flows

KOhort_flows = np.append(KOhort_flows, -1*KOhort_flows.sum())

fig = plt.figure(figsize=(16*0.8, 9*0.8))#
ax = fig.add_subplot(1, 1, 1, xticks=[], yticks=[])
ax.axis('off')
sankey = Sankey(
    ax=ax,
    unit=None,
    shoulder=0.1,
)
sankey.add(
    flows=KOhort_flows,
    orientations=[1, 1, 0, 1, 1, 1, 1, 0],
    labels=KOhorts,
    color='#17becf',
    #edgecolor=None,
    facecolor='#17becf',
).finish()
fig.savefig("output.svg", transparent=True)

########################## Charts 2 ############################################

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.sankey import Sankey
import seaborn as sns

%%javascript
IPython.OutputArea.prototype._should_scroll = function(lines) {
    return false;
}

data_round_1 = pd.read_excel('Data_for_histo.xlsx', sheet_name='Data_name_order_1', index_col=0, dtype={'All Kohorts':'category', 'Assigned Kohort':'category'})

kohort_dict = {'AD':'Age-Defiers', 'ASP':'Aspirers', 'CM':'Change Makers', 'GIV':'Givers', 'PRO':'Providers', 'SEE':'Seekers', 'SUR':'Survivors'}
data_round_1['All Kohorts'] = data_round_1['All Kohorts'].cat.rename_categories(kohort_dict)
data_round_1['Assigned Kohort'] = data_round_1['Assigned Kohort'].cat.rename_categories(kohort_dict)

data_round_1.head()

# data_for_histo_1 = pd.read_excel('Data_from_tool.xlsx', sheet_name='Output_typing_tool')

# data_for_histo_1.head()

# df_22=data_for_histo_1.melt(id_vars=['Case ID'],value_vars=['  Aspirers', '  Providers', '  Age-Defiers',
#        '  Change Makers', '  Givers', '  Survivors', '  Seekers'],var_name ='Prob %').sort_values('Case ID')

# df_22.reset_index(drop=True,inplace=True)

# data_for_histo_1.set_index('Case ID')
# data_histo_new=pd.DataFrame
# data_histo_new=data_for_histo_1.loc[data_for_histo_1.index.repeat(7)]
# #data_histo_new.columns
# data_histo_new=data_histo_new.drop(['  Aspirers', '  Providers', '  Age-Defiers',
#        '  Change Makers', '  Givers', '  Survivors', '  Seekers',
#        'Segment Name'],axis=1)

# name=['Aspirers', 'Providers', 'Age-Defiers','Change Makers', 'Givers', 'Survivors', 'Seekers']
# data_histo_new['All KOhorts']=name*data_histo_new['Case ID'].nunique()
# df_11=pd.merge(data_for_histo_1,data_histo_new)
# df_11=df_11.drop(['  Aspirers', '  Providers', '  Age-Defiers','  Change Makers', '  Givers', '  Survivors', '  Seekers'],axis=1)

# df_33=pd.merge(df_11,df_22)

# df_33

# Individual KOhorts

threshold = 0.2
kohort = 'Age-Defiers'

# first graph to explore where the cutoffs are
# select just aspirers
g = sns.FacetGrid(
    data_round_1[data_round_1['Assigned Kohort'] == kohort], 
    col='All Kohorts', 
    col_wrap=4
)
g = (
    g.map(plt.hist, "Kohort prob %",color="#0EADC3")
    .set_titles(
        row_template="{row_name}", col_template="{col_name}"
    )
    .set_ylabels("Count of Respondents")
    .set_xlabels("KOhort Probability")
    
)


#have x labels for all axes
for ax in g.axes.flatten():
    ax.tick_params(labelbottom=True)
    
    
g.savefig('Age-Defiers.svg')

# Summary Table

kohort_plus = data_round_1[(data_round_1['Kohort prob %'] > threshold) & (data_round_1['All Kohorts'] == kohort )]['Assigned Kohort']
pd.DataFrame(kohort_plus.value_counts() / kohort_plus.value_counts().sum()).style.format("{:.0%}")

def calculate_new_percentages(kohort):
    """This function takes a short Kohort name and returns a dataframe
    with the percentages for the kohort+ group, based on the global variable threshold"""
    kohort_plus = data_round_1[(data_round_1['Kohort prob %'] > threshold) & (data_round_1['All Kohorts'] == kohort )]['Assigned Kohort']
    return pd.DataFrame(kohort_plus.value_counts(sort=False) / kohort_plus.value_counts().sum())

list_of_kohorts = data_round_1['All Kohorts'].unique()
list_of_dataframes = [calculate_new_percentages(kohort) for kohort in list_of_kohorts]

summary_table = pd.concat(list_of_dataframes, axis=1)
summary_table.columns = list_of_kohorts
summary_table.style.format("{:.2%}")

#summary_table.to_csv('summary_table.csv')

# Sankey Charts

kohort = 'Survivors'

kohort_dict_1 = {'Age-Defiers':'AD', 'Aspirers':'ASP', 'Change Makers':'CM', 'Givers':'GIV', 'Providers':'PRO', 'Seekers':'SEE', 'Survivors':'SUR'}
kohort_1=kohort_dict_1.get(kohort)
KOhorts=pd.DataFrame()
KOhorts['Kohort'] = ["AD","ASP","CM","GIV","PRO","SEE","SUR",kohort_1+"+"]
KOhorts['Kohort_name']=KOhorts.Kohort.astype('category').cat.rename_categories(kohort_dict)
KOhorts['arrow_flow']=[1,1,1,1,1,1,1,0]
KOhorts.loc[KOhorts['Kohort'] == kohort_1, ['arrow_flow']] = 0

# second graph to show from where an enlarged group would source from
KOhort_flows = np.array(summary_table[kohort]*100)
KOhort_flows = np.append(KOhort_flows, -1*KOhort_flows.sum())

fig = plt.figure(figsize=(16*0.8, 9*0.8))#
ax = fig.add_subplot(1, 1, 1, xticks=[], yticks=[])
ax.axis('off')
sankey = Sankey( ax=ax, shoulder=0.1, scale=0.01, offset=0.2,format='%.2f',unit='%')
sankey.add(
    flows=KOhort_flows,
    orientations=KOhorts['arrow_flow'],
    labels=KOhorts['Kohort'].tolist(),
    color='#0EADC3',
    edgecolor=None,
    facecolor='#0EADC3',
).finish()
fig.savefig("Survivors+.svg", transparent=True)

# Demo Segmentation Typing Tool Calculations

data_round_2 = pd.read_excel('Data_for_histo.xlsx', sheet_name='Data_name_order_demog', index_col=0, dtype={'All Kohorts':'category', 'Assigned Kohort':'category'})

data_round_2['All Kohorts'] = data_round_2['All Kohorts'].cat.rename_categories(kohort_dict)
data_round_2['Assigned Kohort'] = data_round_2['Assigned Kohort'].cat.rename_categories(kohort_dict)

# Individual KOhorts

 # Age-Defiers,  Aspirers  Change Makers  Givers  Providers  Seekers  Survivors

threshold = 0.2
kohort = 'Survivors'

# first graph to explore where the cutoffs are
# select just aspirers
g = sns.FacetGrid(
    data_round_2[data_round_2['Assigned Kohort'] == kohort], 
    col='All Kohorts', 
    col_wrap=4
)
g = (
    g.map(plt.hist, "Kohort prob %",color="#E60D7F")
    .set_titles(
        row_template="{row_name}", col_template="{col_name}"
    )
    .set_ylabels("Count of Respondents")
    .set_xlabels("KOhort Probability")
    
)


#have x labels for all axes
for ax in g.axes.flatten():
    ax.tick_params(labelbottom=True)
    
    
g.savefig('Survivors.svg')

# Summary Table

kohort_plus_2 = data_round_2[(data_round_2['Kohort prob %'] > threshold) & (data_round_2['All Kohorts'] == kohort )]['Assigned Kohort']
pd.DataFrame(kohort_plus_2.value_counts() / kohort_plus_2.value_counts().sum()).style.format("{:.3%}")

def calculate_new_percentages_demog(kohort):
    """This function takes a short Kohort name and returns a dataframe
    with the percentages for the kohort+ group, based on the global variable threshold"""
    kohort_plus = data_round_2[(data_round_2['Kohort prob %'] > threshold) & (data_round_2['All Kohorts'] == kohort )]['Assigned Kohort']
    return pd.DataFrame(kohort_plus.value_counts(sort=False) / kohort_plus.value_counts().sum())

list_of_kohorts = data_round_2['All Kohorts'].unique()
list_of_dataframes = [calculate_new_percentages_demog(kohort) for kohort in list_of_kohorts]

summary_table_demog = pd.concat(list_of_dataframes, axis=1)
summary_table_demog.columns = list_of_kohorts
summary_table_demog.style.format("{:.0%}")

summary_table_demog.to_csv('summary_table_demog.csv')

# Sankey Charts

 # Age-Defiers,  Aspirers  Change Makers  Givers  Providers  Seekers  Survivors


kohort = 'Aspirers'

kohort_dict_1 = {'Age-Defiers':'AD', 'Aspirers':'ASP', 'Change Makers':'CM', 'Givers':'GIV', 'Providers':'PRO', 'Seekers':'SEE', 'Survivors':'SUR'}
kohort_1=kohort_dict_1.get(kohort)
KOhorts=pd.DataFrame()
KOhorts['Kohort'] = ["AD","ASP","CM","GIV","PRO","SEE","SUR",kohort_1+"+"]
KOhorts['Kohort_name']=KOhorts.Kohort.astype('category').cat.rename_categories(kohort_dict)
KOhorts['arrow_flow']=[1,1,1,1,1,1,1,0]
KOhorts.loc[KOhorts['Kohort'] == kohort_1, ['arrow_flow']] = 0
# second graph to show from where an enlarged group would source from
KOhort_flows = np.array(summary_table_demog[kohort]*100)
KOhort_flows = np.append(KOhort_flows, -1*KOhort_flows.sum())
KOhorts['Kohort_%']=KOhort_flows
KOhorts.loc[KOhorts['Kohort_%'] == 0, ['arrow_flow']] = 0

fig = plt.figure(figsize=(16*0.8, 9*0.8))#
ax = fig.add_subplot(1, 1, 1, xticks=[], yticks=[])
ax.axis('off')
sankey = Sankey( ax=ax, shoulder=0.1, scale=0.01, offset=0.2,format='%.2f',unit='%')
sankey.add(
    flows=KOhort_flows,
    orientations=KOhorts['arrow_flow'],
    labels=KOhorts['Kohort'].tolist(),
    color='#E60D7F',
    edgecolor=None,
    facecolor='#E60D7F',
).finish()
#fig.savefig("Survivors+.svg", transparent=True)

df_44=df_22.reset_index()

df_44.columns=['Case ID', 'All KOhort', 'Prob %']


df_44=df_44.sort_values(by=["Case ID","All KOhort"],axis=0).reset_index()

df_44=df_44.drop(['index'],axis=1)
df_44



